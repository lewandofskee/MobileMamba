2024/10/27 23:32:26 - mmengine - INFO - 
------------------------------------------------------------
System environment:
    sys.platform: linux
    Python: 3.9.5 (default, Jun  4 2021, 12:28:51) [GCC 7.5.0]
    CUDA available: True
    MUSA available: False
    numpy_random_seed: 1630442107
    GPU 0,1,2,3: A100-SXM4-40GB
    CUDA_HOME: /usr/local/cuda
    NVCC: Cuda compilation tools, release 11.8, V11.8.89
    GCC: gcc (GCC) 7.3.1 20180303 (Red Hat 7.3.1-5)
    PyTorch: 2.1.2+cu118
    PyTorch compiling details: PyTorch built with:
  - GCC 9.3
  - C++ Version: 201703
  - Intel(R) oneAPI Math Kernel Library Version 2022.2-Product Build 20220804 for Intel(R) 64 architecture applications
  - Intel(R) MKL-DNN v3.1.1 (Git Hash 64f6bcbcbab628e96f33a62c3e975f8535a7bde4)
  - OpenMP 201511 (a.k.a. OpenMP 4.5)
  - LAPACK is enabled (usually provided by MKL)
  - NNPACK is enabled
  - CPU capability usage: AVX2
  - CUDA Runtime 11.8
  - NVCC architecture flags: -gencode;arch=compute_50,code=sm_50;-gencode;arch=compute_60,code=sm_60;-gencode;arch=compute_70,code=sm_70;-gencode;arch=compute_75,code=sm_75;-gencode;arch=compute_80,code=sm_80;-gencode;arch=compute_86,code=sm_86;-gencode;arch=compute_37,code=sm_37;-gencode;arch=compute_90,code=sm_90
  - CuDNN 8.7
  - Magma 2.6.1
  - Build settings: BLAS_INFO=mkl, BUILD_TYPE=Release, CUDA_VERSION=11.8, CUDNN_VERSION=8.7.0, CXX_COMPILER=/opt/rh/devtoolset-9/root/usr/bin/c++, CXX_FLAGS= -D_GLIBCXX_USE_CXX11_ABI=0 -fabi-version=11 -fvisibility-inlines-hidden -DUSE_PTHREADPOOL -DNDEBUG -DUSE_KINETO -DLIBKINETO_NOROCTRACER -DUSE_FBGEMM -DUSE_QNNPACK -DUSE_PYTORCH_QNNPACK -DUSE_XNNPACK -DSYMBOLICATE_MOBILE_DEBUG_HANDLE -O2 -fPIC -Wall -Wextra -Werror=return-type -Werror=non-virtual-dtor -Werror=bool-operation -Wnarrowing -Wno-missing-field-initializers -Wno-type-limits -Wno-array-bounds -Wno-unknown-pragmas -Wno-unused-parameter -Wno-unused-function -Wno-unused-result -Wno-strict-overflow -Wno-strict-aliasing -Wno-stringop-overflow -Wno-psabi -Wno-error=pedantic -Wno-error=old-style-cast -Wno-invalid-partial-specialization -Wno-unused-private-field -Wno-aligned-allocation-unavailable -Wno-missing-braces -fdiagnostics-color=always -faligned-new -Wno-unused-but-set-variable -Wno-maybe-uninitialized -fno-math-errno -fno-trapping-math -Werror=format -Werror=cast-function-type -Wno-stringop-overflow, LAPACK_INFO=mkl, PERF_WITH_AVX=1, PERF_WITH_AVX2=1, PERF_WITH_AVX512=1, TORCH_DISABLE_GPU_ASSERTS=ON, TORCH_VERSION=2.1.2, USE_CUDA=ON, USE_CUDNN=ON, USE_EXCEPTION_PTR=1, USE_GFLAGS=OFF, USE_GLOG=OFF, USE_MKL=ON, USE_MKLDNN=ON, USE_MPI=OFF, USE_NCCL=1, USE_NNPACK=ON, USE_OPENMP=ON, USE_ROCM=OFF, 

    TorchVision: 0.16.2+cu118
    OpenCV: 4.9.0
    MMEngine: 0.10.5

Runtime environment:
    cudnn_benchmark: True
    mp_cfg: {'mp_start_method': 'fork', 'opencv_num_threads': 0}
    dist_cfg: {'backend': 'nccl'}
    seed: 1630442107
    Distributed launcher: pytorch
    Distributed training: True
    GPU number: 4
------------------------------------------------------------

2024/10/27 23:32:27 - mmengine - INFO - Config:
bs_ratio = 4
crop_size = (
    512,
    512,
)
data_preprocessor = dict(
    bgr_to_rgb=True,
    mean=[
        123.675,
        116.28,
        103.53,
    ],
    pad_val=0,
    seg_pad_val=255,
    size=(
        512,
        512,
    ),
    std=[
        58.395,
        57.12,
        57.375,
    ],
    type='SegDataPreProcessor')
data_root = 'data/ade/ADEChallengeData2016'
dataset_type = 'ADE20KDataset'
default_hooks = dict(
    checkpoint=dict(by_epoch=False, interval=8000, type='CheckpointHook'),
    logger=dict(interval=50, log_metric_by_epoch=False, type='LoggerHook'),
    param_scheduler=dict(type='ParamSchedulerHook'),
    sampler_seed=dict(type='DistSamplerSeedHook'),
    timer=dict(type='IterTimerHook'),
    visualization=dict(type='SegVisualizationHook'))
default_scope = 'mmseg'
env_cfg = dict(
    cudnn_benchmark=True,
    dist_cfg=dict(backend='nccl'),
    mp_cfg=dict(mp_start_method='fork', opencv_num_threads=0))
img_ratios = [
    0.5,
    0.75,
    1.0,
    1.25,
    1.5,
    1.75,
]
launcher = 'pytorch'
load_from = None
log_level = 'INFO'
log_processor = dict(by_epoch=False)
max_iters = 80000
model = dict(
    auxiliary_head=dict(
        align_corners=False,
        channels=256,
        concat_input=False,
        dropout_ratio=0.1,
        in_channels=376,
        in_index=1,
        loss_decode=dict(
            loss_weight=0.4, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        num_convs=1,
        type='FCNHead'),
    backbone=dict(
        depth=[
            2,
            3,
            2,
        ],
        distillation=False,
        down_ops=[
            [
                'subsample',
                2,
            ],
            [
                'subsample',
                2,
            ],
            [
                '',
            ],
        ],
        drop_path=0.03,
        embed_dim=[
            200,
            376,
            448,
        ],
        forward_type='v052d',
        frozen_stages=-1,
        global_ratio=[
            0.8,
            0.7,
            0.6,
        ],
        img_size=224,
        in_chans=3,
        kernels=[
            7,
            5,
            3,
        ],
        local_ratio=[
            0.2,
            0.2,
            0.3,
        ],
        norm_eval=False,
        num_classes=80,
        num_heads=[
            4,
            4,
            4,
        ],
        out_indices=(
            1,
            2,
            3,
        ),
        patch_size=16,
        pretrained=
        '../../weights/MobileMamba_B4/mobilemamba_b4.pth',
        ssm_ratio=2,
        stages=[
            's',
            's',
            's',
        ],
        sync_bn=False,
        type='MobileMamba',
        window_size=[
            7,
            7,
            7,
        ]),
    data_preprocessor=dict(
        bgr_to_rgb=True,
        mean=[
            123.675,
            116.28,
            103.53,
        ],
        pad_val=0,
        seg_pad_val=255,
        size=(
            512,
            512,
        ),
        std=[
            58.395,
            57.12,
            57.375,
        ],
        type='SegDataPreProcessor'),
    decode_head=dict(
        align_corners=False,
        channels=256,
        dropout_ratio=0.1,
        in_channels=448,
        in_index=2,
        loss_decode=dict(
            loss_weight=1.0, type='CrossEntropyLoss', use_sigmoid=False),
        norm_cfg=dict(requires_grad=True, type='SyncBN'),
        num_classes=150,
        pool_scales=(
            1,
            2,
            3,
            6,
        ),
        type='PSPHead'),
    pretrained=None,
    test_cfg=dict(mode='whole'),
    train_cfg=dict(),
    type='EncoderDecoder')
norm_cfg = dict(requires_grad=True, type='SyncBN')
optim_wrapper = dict(
    clip_grad=dict(max_norm=0.1, norm_type=2),
    optimizer=dict(
        betas=(
            0.9,
            0.999,
        ), lr=0.00012, type='AdamW', weight_decay=0.05),
    paramwise_cfg=dict(
        custom_keys=dict(
            absolute_pos_embed=dict(decay_mult=0.0),
            norm=dict(decay_mult=0.0),
            relative_position_bias_table=dict(decay_mult=0.0))),
    type='OptimWrapper')
optimizer = dict(lr=0.01, momentum=0.9, type='SGD', weight_decay=0.0005)
param_scheduler = [
    dict(
        begin=0, by_epoch=False, end=500, start_factor=1e-05, type='LinearLR'),
    dict(
        T_max=40000,
        begin=40000,
        by_epoch=False,
        end=80000,
        eta_min=0,
        type='CosineAnnealingLR'),
]
ratio = 1
resume = True
test_cfg = dict(type='TestLoop')
test_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(
            img_path='images/validation',
            seg_map_path='annotations/validation'),
        data_root='data/ade/ADEChallengeData2016',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(reduce_zero_label=True, type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='ADE20KDataset'),
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
test_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
test_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(keep_ratio=True, scale=(
        2048,
        512,
    ), type='Resize'),
    dict(reduce_zero_label=True, type='LoadAnnotations'),
    dict(type='PackSegInputs'),
]
train_cfg = dict(max_iters=80000, type='IterBasedTrainLoop', val_interval=8000)
train_dataloader = dict(
    batch_size=8,
    dataset=dict(
        data_prefix=dict(
            img_path='images/training', seg_map_path='annotations/training'),
        data_root='data/ade/ADEChallengeData2016',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(reduce_zero_label=True, type='LoadAnnotations'),
            dict(
                keep_ratio=True,
                ratio_range=(
                    0.5,
                    2.0,
                ),
                scale=(
                    2048,
                    512,
                ),
                type='RandomResize'),
            dict(
                cat_max_ratio=0.75, crop_size=(
                    512,
                    512,
                ), type='RandomCrop'),
            dict(prob=0.5, type='RandomFlip'),
            dict(type='PhotoMetricDistortion'),
            dict(type='PackSegInputs'),
        ],
        type='ADE20KDataset'),
    num_workers=8,
    persistent_workers=True,
    sampler=dict(shuffle=True, type='InfiniteSampler'))
train_pipeline = [
    dict(type='LoadImageFromFile'),
    dict(reduce_zero_label=True, type='LoadAnnotations'),
    dict(
        keep_ratio=True,
        ratio_range=(
            0.5,
            2.0,
        ),
        scale=(
            2048,
            512,
        ),
        type='RandomResize'),
    dict(cat_max_ratio=0.75, crop_size=(
        512,
        512,
    ), type='RandomCrop'),
    dict(prob=0.5, type='RandomFlip'),
    dict(type='PhotoMetricDistortion'),
    dict(type='PackSegInputs'),
]
tta_model = dict(type='SegTTAModel')
tta_pipeline = [
    dict(backend_args=None, type='LoadImageFromFile'),
    dict(
        transforms=[
            [
                dict(keep_ratio=True, scale_factor=0.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=0.75, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.0, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.25, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.5, type='Resize'),
                dict(keep_ratio=True, scale_factor=1.75, type='Resize'),
            ],
            [
                dict(direction='horizontal', prob=0.0, type='RandomFlip'),
                dict(direction='horizontal', prob=1.0, type='RandomFlip'),
            ],
            [
                dict(type='LoadAnnotations'),
            ],
            [
                dict(type='PackSegInputs'),
            ],
        ],
        type='TestTimeAug'),
]
val_cfg = dict(type='ValLoop')
val_dataloader = dict(
    batch_size=1,
    dataset=dict(
        data_prefix=dict(
            img_path='images/validation',
            seg_map_path='annotations/validation'),
        data_root='data/ade/ADEChallengeData2016',
        pipeline=[
            dict(type='LoadImageFromFile'),
            dict(keep_ratio=True, scale=(
                2048,
                512,
            ), type='Resize'),
            dict(reduce_zero_label=True, type='LoadAnnotations'),
            dict(type='PackSegInputs'),
        ],
        type='ADE20KDataset'),
    num_workers=2,
    persistent_workers=True,
    sampler=dict(shuffle=False, type='DefaultSampler'))
val_evaluator = dict(
    iou_metrics=[
        'mIoU',
    ], type='IoUMetric')
vis_backends = [
    dict(type='LocalVisBackend'),
]
visualizer = dict(
    name='visualizer',
    type='SegLocalVisualizer',
    vis_backends=[
        dict(type='LocalVisBackend'),
    ])
work_dir = './work_dirs/pspnet_mobilemamba_B4P-80k_ade20k-512x512'

2024/10/27 23:32:46 - mmengine - INFO - Hooks will be executed in the following order:
before_run:
(VERY_HIGH   ) RuntimeInfoHook                    
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
before_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_train_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) DistSamplerSeedHook                
 -------------------- 
before_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_train_iter:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_train_epoch:
(NORMAL      ) IterTimerHook                      
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_val_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_val_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_val_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_val_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
(LOW         ) ParamSchedulerHook                 
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
after_val:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_train:
(VERY_HIGH   ) RuntimeInfoHook                    
(VERY_LOW    ) CheckpointHook                     
 -------------------- 
before_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
before_test_epoch:
(NORMAL      ) IterTimerHook                      
 -------------------- 
before_test_iter:
(NORMAL      ) IterTimerHook                      
 -------------------- 
after_test_iter:
(NORMAL      ) IterTimerHook                      
(NORMAL      ) SegVisualizationHook               
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test_epoch:
(VERY_HIGH   ) RuntimeInfoHook                    
(NORMAL      ) IterTimerHook                      
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
after_test:
(VERY_HIGH   ) RuntimeInfoHook                    
 -------------------- 
after_run:
(BELOW_NORMAL) LoggerHook                         
 -------------------- 
2024/10/27 23:32:47 - mmengine - WARNING - backbone.blocks1.0.mixer.m.attn.global_op.wt_filter is skipped since its requires_grad=False
2024/10/27 23:32:47 - mmengine - WARNING - backbone.blocks1.0.mixer.m.attn.global_op.iwt_filter is skipped since its requires_grad=False
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks1.0.mixer.m.attn.global_op.global_atten.out_norm.weight:lr=0.00012
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks1.0.mixer.m.attn.global_op.global_atten.out_norm.weight:weight_decay=0.0
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks1.0.mixer.m.attn.global_op.global_atten.out_norm.weight:decay_mult=0.0
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks1.0.mixer.m.attn.global_op.global_atten.out_norm.bias:lr=0.00012
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks1.0.mixer.m.attn.global_op.global_atten.out_norm.bias:weight_decay=0.0
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks1.0.mixer.m.attn.global_op.global_atten.out_norm.bias:decay_mult=0.0
2024/10/27 23:32:47 - mmengine - WARNING - backbone.blocks1.1.mixer.m.attn.global_op.wt_filter is skipped since its requires_grad=False
2024/10/27 23:32:47 - mmengine - WARNING - backbone.blocks1.1.mixer.m.attn.global_op.iwt_filter is skipped since its requires_grad=False
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks1.1.mixer.m.attn.global_op.global_atten.out_norm.weight:lr=0.00012
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks1.1.mixer.m.attn.global_op.global_atten.out_norm.weight:weight_decay=0.0
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks1.1.mixer.m.attn.global_op.global_atten.out_norm.weight:decay_mult=0.0
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks1.1.mixer.m.attn.global_op.global_atten.out_norm.bias:lr=0.00012
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks1.1.mixer.m.attn.global_op.global_atten.out_norm.bias:weight_decay=0.0
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks1.1.mixer.m.attn.global_op.global_atten.out_norm.bias:decay_mult=0.0
2024/10/27 23:32:47 - mmengine - WARNING - backbone.blocks2.3.mixer.m.attn.global_op.wt_filter is skipped since its requires_grad=False
2024/10/27 23:32:47 - mmengine - WARNING - backbone.blocks2.3.mixer.m.attn.global_op.iwt_filter is skipped since its requires_grad=False
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks2.3.mixer.m.attn.global_op.global_atten.out_norm.weight:lr=0.00012
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks2.3.mixer.m.attn.global_op.global_atten.out_norm.weight:weight_decay=0.0
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks2.3.mixer.m.attn.global_op.global_atten.out_norm.weight:decay_mult=0.0
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks2.3.mixer.m.attn.global_op.global_atten.out_norm.bias:lr=0.00012
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks2.3.mixer.m.attn.global_op.global_atten.out_norm.bias:weight_decay=0.0
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks2.3.mixer.m.attn.global_op.global_atten.out_norm.bias:decay_mult=0.0
2024/10/27 23:32:47 - mmengine - WARNING - backbone.blocks2.4.mixer.m.attn.global_op.wt_filter is skipped since its requires_grad=False
2024/10/27 23:32:47 - mmengine - WARNING - backbone.blocks2.4.mixer.m.attn.global_op.iwt_filter is skipped since its requires_grad=False
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks2.4.mixer.m.attn.global_op.global_atten.out_norm.weight:lr=0.00012
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks2.4.mixer.m.attn.global_op.global_atten.out_norm.weight:weight_decay=0.0
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks2.4.mixer.m.attn.global_op.global_atten.out_norm.weight:decay_mult=0.0
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks2.4.mixer.m.attn.global_op.global_atten.out_norm.bias:lr=0.00012
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks2.4.mixer.m.attn.global_op.global_atten.out_norm.bias:weight_decay=0.0
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks2.4.mixer.m.attn.global_op.global_atten.out_norm.bias:decay_mult=0.0
2024/10/27 23:32:47 - mmengine - WARNING - backbone.blocks2.5.mixer.m.attn.global_op.wt_filter is skipped since its requires_grad=False
2024/10/27 23:32:47 - mmengine - WARNING - backbone.blocks2.5.mixer.m.attn.global_op.iwt_filter is skipped since its requires_grad=False
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks2.5.mixer.m.attn.global_op.global_atten.out_norm.weight:lr=0.00012
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks2.5.mixer.m.attn.global_op.global_atten.out_norm.weight:weight_decay=0.0
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks2.5.mixer.m.attn.global_op.global_atten.out_norm.weight:decay_mult=0.0
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks2.5.mixer.m.attn.global_op.global_atten.out_norm.bias:lr=0.00012
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks2.5.mixer.m.attn.global_op.global_atten.out_norm.bias:weight_decay=0.0
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks2.5.mixer.m.attn.global_op.global_atten.out_norm.bias:decay_mult=0.0
2024/10/27 23:32:47 - mmengine - WARNING - backbone.blocks3.3.mixer.m.attn.global_op.wt_filter is skipped since its requires_grad=False
2024/10/27 23:32:47 - mmengine - WARNING - backbone.blocks3.3.mixer.m.attn.global_op.iwt_filter is skipped since its requires_grad=False
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks3.3.mixer.m.attn.global_op.global_atten.out_norm.weight:lr=0.00012
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks3.3.mixer.m.attn.global_op.global_atten.out_norm.weight:weight_decay=0.0
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks3.3.mixer.m.attn.global_op.global_atten.out_norm.weight:decay_mult=0.0
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks3.3.mixer.m.attn.global_op.global_atten.out_norm.bias:lr=0.00012
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks3.3.mixer.m.attn.global_op.global_atten.out_norm.bias:weight_decay=0.0
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks3.3.mixer.m.attn.global_op.global_atten.out_norm.bias:decay_mult=0.0
2024/10/27 23:32:47 - mmengine - WARNING - backbone.blocks3.4.mixer.m.attn.global_op.wt_filter is skipped since its requires_grad=False
2024/10/27 23:32:47 - mmengine - WARNING - backbone.blocks3.4.mixer.m.attn.global_op.iwt_filter is skipped since its requires_grad=False
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks3.4.mixer.m.attn.global_op.global_atten.out_norm.weight:lr=0.00012
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks3.4.mixer.m.attn.global_op.global_atten.out_norm.weight:weight_decay=0.0
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks3.4.mixer.m.attn.global_op.global_atten.out_norm.weight:decay_mult=0.0
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks3.4.mixer.m.attn.global_op.global_atten.out_norm.bias:lr=0.00012
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks3.4.mixer.m.attn.global_op.global_atten.out_norm.bias:weight_decay=0.0
2024/10/27 23:32:47 - mmengine - INFO - paramwise_options -- backbone.blocks3.4.mixer.m.attn.global_op.global_atten.out_norm.bias:decay_mult=0.0
2024/10/27 23:32:48 - mmengine - WARNING - The prefix is not set in metric class IoUMetric.
Name of parameter - Initialization information

backbone.patch_embed.0.c.weight - torch.Size([25, 3, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed.0.bn.weight - torch.Size([25]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed.0.bn.bias - torch.Size([25]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed.2.c.weight - torch.Size([50, 25, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed.2.bn.weight - torch.Size([50]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed.2.bn.bias - torch.Size([50]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed.4.c.weight - torch.Size([100, 50, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed.4.bn.weight - torch.Size([100]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed.4.bn.bias - torch.Size([100]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed.6.c.weight - torch.Size([200, 100, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed.6.bn.weight - torch.Size([200]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.patch_embed.6.bn.bias - torch.Size([200]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.dw0.m.c.weight - torch.Size([200, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.dw0.m.bn.weight - torch.Size([200]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.dw0.m.bn.bias - torch.Size([200]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.ffn0.m.pw1.c.weight - torch.Size([400, 200, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.ffn0.m.pw1.bn.weight - torch.Size([400]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.ffn0.m.pw1.bn.bias - torch.Size([400]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.ffn0.m.pw2.c.weight - torch.Size([200, 400, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.ffn0.m.pw2.bn.weight - torch.Size([200]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.ffn0.m.pw2.bn.bias - torch.Size([200]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.local_op.dwconv3x3.weight - torch.Size([40, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.local_op.bn1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.local_op.bn1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.local_op.dwconv1x1.weight - torch.Size([40, 1, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.local_op.bn2.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.local_op.bn2.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.global_op.wt_filter - torch.Size([640, 1, 2, 2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.global_op.iwt_filter - torch.Size([640, 1, 2, 2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.global_op.global_atten.x_proj_weight - torch.Size([2, 12, 320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.global_op.global_atten.Ds - torch.Size([640]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.global_op.global_atten.A_logs - torch.Size([640, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.global_op.global_atten.dt_projs_weight - torch.Size([2, 320, 10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.global_op.global_atten.dt_projs_bias - torch.Size([2, 320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.global_op.global_atten.out_norm.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.global_op.global_atten.out_norm.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.global_op.global_atten.in_proj.c.weight - torch.Size([640, 160, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.global_op.global_atten.in_proj.bn.weight - torch.Size([640]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.global_op.global_atten.in_proj.bn.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.global_op.global_atten.conv2d.weight - torch.Size([320, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.global_op.global_atten.conv2d.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.global_op.global_atten.out_proj.c.weight - torch.Size([160, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.global_op.global_atten.out_proj.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.global_op.global_atten.out_proj.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.global_op.base_scale.weight - torch.Size([1, 160, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.global_op.wavelet_convs.0.weight - torch.Size([640, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.global_op.wavelet_scale.0.weight - torch.Size([1, 640, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.proj.1.c.weight - torch.Size([200, 200, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.proj.1.bn.weight - torch.Size([200]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.mixer.m.attn.proj.1.bn.bias - torch.Size([200]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.dw1.m.c.weight - torch.Size([200, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.dw1.m.bn.weight - torch.Size([200]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.dw1.m.bn.bias - torch.Size([200]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.ffn1.m.pw1.c.weight - torch.Size([400, 200, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.ffn1.m.pw1.bn.weight - torch.Size([400]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.ffn1.m.pw1.bn.bias - torch.Size([400]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.ffn1.m.pw2.c.weight - torch.Size([200, 400, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.ffn1.m.pw2.bn.weight - torch.Size([200]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.0.ffn1.m.pw2.bn.bias - torch.Size([200]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.dw0.m.c.weight - torch.Size([200, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.dw0.m.bn.weight - torch.Size([200]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.dw0.m.bn.bias - torch.Size([200]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.ffn0.m.pw1.c.weight - torch.Size([400, 200, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.ffn0.m.pw1.bn.weight - torch.Size([400]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.ffn0.m.pw1.bn.bias - torch.Size([400]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.ffn0.m.pw2.c.weight - torch.Size([200, 400, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.ffn0.m.pw2.bn.weight - torch.Size([200]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.ffn0.m.pw2.bn.bias - torch.Size([200]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.local_op.dwconv3x3.weight - torch.Size([40, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.local_op.bn1.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.local_op.bn1.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.local_op.dwconv1x1.weight - torch.Size([40, 1, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.local_op.bn2.weight - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.local_op.bn2.bias - torch.Size([40]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.global_op.wt_filter - torch.Size([640, 1, 2, 2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.global_op.iwt_filter - torch.Size([640, 1, 2, 2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.global_op.global_atten.x_proj_weight - torch.Size([2, 12, 320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.global_op.global_atten.Ds - torch.Size([640]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.global_op.global_atten.A_logs - torch.Size([640, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.global_op.global_atten.dt_projs_weight - torch.Size([2, 320, 10]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.global_op.global_atten.dt_projs_bias - torch.Size([2, 320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.global_op.global_atten.out_norm.weight - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.global_op.global_atten.out_norm.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.global_op.global_atten.in_proj.c.weight - torch.Size([640, 160, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.global_op.global_atten.in_proj.bn.weight - torch.Size([640]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.global_op.global_atten.in_proj.bn.bias - torch.Size([640]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.global_op.global_atten.conv2d.weight - torch.Size([320, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.global_op.global_atten.conv2d.bias - torch.Size([320]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.global_op.global_atten.out_proj.c.weight - torch.Size([160, 320, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.global_op.global_atten.out_proj.bn.weight - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.global_op.global_atten.out_proj.bn.bias - torch.Size([160]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.global_op.base_scale.weight - torch.Size([1, 160, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.global_op.wavelet_convs.0.weight - torch.Size([640, 1, 7, 7]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.global_op.wavelet_scale.0.weight - torch.Size([1, 640, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.proj.1.c.weight - torch.Size([200, 200, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.proj.1.bn.weight - torch.Size([200]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.mixer.m.attn.proj.1.bn.bias - torch.Size([200]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.dw1.m.c.weight - torch.Size([200, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.dw1.m.bn.weight - torch.Size([200]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.dw1.m.bn.bias - torch.Size([200]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.ffn1.m.pw1.c.weight - torch.Size([400, 200, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.ffn1.m.pw1.bn.weight - torch.Size([400]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.ffn1.m.pw1.bn.bias - torch.Size([400]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.ffn1.m.pw2.c.weight - torch.Size([200, 400, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.ffn1.m.pw2.bn.weight - torch.Size([200]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks1.1.ffn1.m.pw2.bn.bias - torch.Size([200]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.0.0.m.c.weight - torch.Size([200, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.0.0.m.bn.weight - torch.Size([200]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.0.0.m.bn.bias - torch.Size([200]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.0.1.m.pw1.c.weight - torch.Size([400, 200, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.0.1.m.pw1.bn.weight - torch.Size([400]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.0.1.m.pw1.bn.bias - torch.Size([400]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.0.1.m.pw2.c.weight - torch.Size([200, 400, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.0.1.m.pw2.bn.weight - torch.Size([200]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.0.1.m.pw2.bn.bias - torch.Size([200]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.1.conv1.c.weight - torch.Size([800, 200, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.1.conv1.bn.weight - torch.Size([800]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.1.conv1.bn.bias - torch.Size([800]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.1.conv2.c.weight - torch.Size([800, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.1.conv2.bn.weight - torch.Size([800]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.1.conv2.bn.bias - torch.Size([800]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.1.se.fc1.weight - torch.Size([200, 800, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.1.se.fc1.bias - torch.Size([200]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.1.se.fc2.weight - torch.Size([800, 200, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.1.se.fc2.bias - torch.Size([800]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.1.conv3.c.weight - torch.Size([376, 800, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.1.conv3.bn.weight - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.1.conv3.bn.bias - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.2.0.m.c.weight - torch.Size([376, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.2.0.m.bn.weight - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.2.0.m.bn.bias - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.2.1.m.pw1.c.weight - torch.Size([752, 376, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.2.1.m.pw1.bn.weight - torch.Size([752]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.2.1.m.pw1.bn.bias - torch.Size([752]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.2.1.m.pw2.c.weight - torch.Size([376, 752, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.2.1.m.pw2.bn.weight - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.2.1.m.pw2.bn.bias - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.dw0.m.c.weight - torch.Size([376, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.dw0.m.bn.weight - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.dw0.m.bn.bias - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.ffn0.m.pw1.c.weight - torch.Size([752, 376, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.ffn0.m.pw1.bn.weight - torch.Size([752]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.ffn0.m.pw1.bn.bias - torch.Size([752]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.ffn0.m.pw2.c.weight - torch.Size([376, 752, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.ffn0.m.pw2.bn.weight - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.ffn0.m.pw2.bn.bias - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.local_op.dwconv3x3.weight - torch.Size([75, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.local_op.bn1.weight - torch.Size([75]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.local_op.bn1.bias - torch.Size([75]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.local_op.dwconv1x1.weight - torch.Size([75, 1, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.local_op.bn2.weight - torch.Size([75]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.local_op.bn2.bias - torch.Size([75]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.global_op.wt_filter - torch.Size([1024, 1, 2, 2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.global_op.iwt_filter - torch.Size([1024, 1, 2, 2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.global_op.global_atten.x_proj_weight - torch.Size([2, 18, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.global_op.global_atten.Ds - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.global_op.global_atten.A_logs - torch.Size([1024, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.global_op.global_atten.dt_projs_weight - torch.Size([2, 512, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.global_op.global_atten.dt_projs_bias - torch.Size([2, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.global_op.global_atten.out_norm.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.global_op.global_atten.out_norm.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.global_op.global_atten.in_proj.c.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.global_op.global_atten.in_proj.bn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.global_op.global_atten.in_proj.bn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.global_op.global_atten.conv2d.weight - torch.Size([512, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.global_op.global_atten.conv2d.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.global_op.global_atten.out_proj.c.weight - torch.Size([256, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.global_op.global_atten.out_proj.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.global_op.global_atten.out_proj.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.global_op.base_scale.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.global_op.wavelet_convs.0.weight - torch.Size([1024, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.global_op.wavelet_scale.0.weight - torch.Size([1, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.proj.1.c.weight - torch.Size([376, 376, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.proj.1.bn.weight - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.mixer.m.attn.proj.1.bn.bias - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.dw1.m.c.weight - torch.Size([376, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.dw1.m.bn.weight - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.dw1.m.bn.bias - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.ffn1.m.pw1.c.weight - torch.Size([752, 376, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.ffn1.m.pw1.bn.weight - torch.Size([752]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.ffn1.m.pw1.bn.bias - torch.Size([752]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.ffn1.m.pw2.c.weight - torch.Size([376, 752, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.ffn1.m.pw2.bn.weight - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.3.ffn1.m.pw2.bn.bias - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.dw0.m.c.weight - torch.Size([376, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.dw0.m.bn.weight - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.dw0.m.bn.bias - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.ffn0.m.pw1.c.weight - torch.Size([752, 376, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.ffn0.m.pw1.bn.weight - torch.Size([752]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.ffn0.m.pw1.bn.bias - torch.Size([752]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.ffn0.m.pw2.c.weight - torch.Size([376, 752, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.ffn0.m.pw2.bn.weight - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.ffn0.m.pw2.bn.bias - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.local_op.dwconv3x3.weight - torch.Size([75, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.local_op.bn1.weight - torch.Size([75]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.local_op.bn1.bias - torch.Size([75]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.local_op.dwconv1x1.weight - torch.Size([75, 1, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.local_op.bn2.weight - torch.Size([75]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.local_op.bn2.bias - torch.Size([75]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.global_op.wt_filter - torch.Size([1024, 1, 2, 2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.global_op.iwt_filter - torch.Size([1024, 1, 2, 2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.global_op.global_atten.x_proj_weight - torch.Size([2, 18, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.global_op.global_atten.Ds - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.global_op.global_atten.A_logs - torch.Size([1024, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.global_op.global_atten.dt_projs_weight - torch.Size([2, 512, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.global_op.global_atten.dt_projs_bias - torch.Size([2, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.global_op.global_atten.out_norm.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.global_op.global_atten.out_norm.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.global_op.global_atten.in_proj.c.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.global_op.global_atten.in_proj.bn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.global_op.global_atten.in_proj.bn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.global_op.global_atten.conv2d.weight - torch.Size([512, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.global_op.global_atten.conv2d.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.global_op.global_atten.out_proj.c.weight - torch.Size([256, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.global_op.global_atten.out_proj.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.global_op.global_atten.out_proj.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.global_op.base_scale.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.global_op.wavelet_convs.0.weight - torch.Size([1024, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.global_op.wavelet_scale.0.weight - torch.Size([1, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.proj.1.c.weight - torch.Size([376, 376, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.proj.1.bn.weight - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.mixer.m.attn.proj.1.bn.bias - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.dw1.m.c.weight - torch.Size([376, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.dw1.m.bn.weight - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.dw1.m.bn.bias - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.ffn1.m.pw1.c.weight - torch.Size([752, 376, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.ffn1.m.pw1.bn.weight - torch.Size([752]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.ffn1.m.pw1.bn.bias - torch.Size([752]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.ffn1.m.pw2.c.weight - torch.Size([376, 752, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.ffn1.m.pw2.bn.weight - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.4.ffn1.m.pw2.bn.bias - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.dw0.m.c.weight - torch.Size([376, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.dw0.m.bn.weight - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.dw0.m.bn.bias - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.ffn0.m.pw1.c.weight - torch.Size([752, 376, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.ffn0.m.pw1.bn.weight - torch.Size([752]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.ffn0.m.pw1.bn.bias - torch.Size([752]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.ffn0.m.pw2.c.weight - torch.Size([376, 752, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.ffn0.m.pw2.bn.weight - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.ffn0.m.pw2.bn.bias - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.local_op.dwconv3x3.weight - torch.Size([75, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.local_op.bn1.weight - torch.Size([75]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.local_op.bn1.bias - torch.Size([75]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.local_op.dwconv1x1.weight - torch.Size([75, 1, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.local_op.bn2.weight - torch.Size([75]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.local_op.bn2.bias - torch.Size([75]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.global_op.wt_filter - torch.Size([1024, 1, 2, 2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.global_op.iwt_filter - torch.Size([1024, 1, 2, 2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.global_op.global_atten.x_proj_weight - torch.Size([2, 18, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.global_op.global_atten.Ds - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.global_op.global_atten.A_logs - torch.Size([1024, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.global_op.global_atten.dt_projs_weight - torch.Size([2, 512, 16]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.global_op.global_atten.dt_projs_bias - torch.Size([2, 512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.global_op.global_atten.out_norm.weight - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.global_op.global_atten.out_norm.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.global_op.global_atten.in_proj.c.weight - torch.Size([1024, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.global_op.global_atten.in_proj.bn.weight - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.global_op.global_atten.in_proj.bn.bias - torch.Size([1024]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.global_op.global_atten.conv2d.weight - torch.Size([512, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.global_op.global_atten.conv2d.bias - torch.Size([512]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.global_op.global_atten.out_proj.c.weight - torch.Size([256, 512, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.global_op.global_atten.out_proj.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.global_op.global_atten.out_proj.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.global_op.base_scale.weight - torch.Size([1, 256, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.global_op.wavelet_convs.0.weight - torch.Size([1024, 1, 5, 5]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.global_op.wavelet_scale.0.weight - torch.Size([1, 1024, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.proj.1.c.weight - torch.Size([376, 376, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.proj.1.bn.weight - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.mixer.m.attn.proj.1.bn.bias - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.dw1.m.c.weight - torch.Size([376, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.dw1.m.bn.weight - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.dw1.m.bn.bias - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.ffn1.m.pw1.c.weight - torch.Size([752, 376, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.ffn1.m.pw1.bn.weight - torch.Size([752]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.ffn1.m.pw1.bn.bias - torch.Size([752]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.ffn1.m.pw2.c.weight - torch.Size([376, 752, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.ffn1.m.pw2.bn.weight - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks2.5.ffn1.m.pw2.bn.bias - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.0.0.m.c.weight - torch.Size([376, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.0.0.m.bn.weight - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.0.0.m.bn.bias - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.0.1.m.pw1.c.weight - torch.Size([752, 376, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.0.1.m.pw1.bn.weight - torch.Size([752]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.0.1.m.pw1.bn.bias - torch.Size([752]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.0.1.m.pw2.c.weight - torch.Size([376, 752, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.0.1.m.pw2.bn.weight - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.0.1.m.pw2.bn.bias - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.1.conv1.c.weight - torch.Size([1504, 376, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.1.conv1.bn.weight - torch.Size([1504]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.1.conv1.bn.bias - torch.Size([1504]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.1.conv2.c.weight - torch.Size([1504, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.1.conv2.bn.weight - torch.Size([1504]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.1.conv2.bn.bias - torch.Size([1504]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.1.se.fc1.weight - torch.Size([376, 1504, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.1.se.fc1.bias - torch.Size([376]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.1.se.fc2.weight - torch.Size([1504, 376, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.1.se.fc2.bias - torch.Size([1504]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.1.conv3.c.weight - torch.Size([448, 1504, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.1.conv3.bn.weight - torch.Size([448]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.1.conv3.bn.bias - torch.Size([448]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.2.0.m.c.weight - torch.Size([448, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.2.0.m.bn.weight - torch.Size([448]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.2.0.m.bn.bias - torch.Size([448]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.2.1.m.pw1.c.weight - torch.Size([896, 448, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.2.1.m.pw1.bn.weight - torch.Size([896]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.2.1.m.pw1.bn.bias - torch.Size([896]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.2.1.m.pw2.c.weight - torch.Size([448, 896, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.2.1.m.pw2.bn.weight - torch.Size([448]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.2.1.m.pw2.bn.bias - torch.Size([448]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.dw0.m.c.weight - torch.Size([448, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.dw0.m.bn.weight - torch.Size([448]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.dw0.m.bn.bias - torch.Size([448]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.ffn0.m.pw1.c.weight - torch.Size([896, 448, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.ffn0.m.pw1.bn.weight - torch.Size([896]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.ffn0.m.pw1.bn.bias - torch.Size([896]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.ffn0.m.pw2.c.weight - torch.Size([448, 896, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.ffn0.m.pw2.bn.weight - torch.Size([448]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.ffn0.m.pw2.bn.bias - torch.Size([448]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.local_op.dwconv3x3.weight - torch.Size([134, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.local_op.bn1.weight - torch.Size([134]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.local_op.bn1.bias - torch.Size([134]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.local_op.dwconv1x1.weight - torch.Size([134, 1, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.local_op.bn2.weight - torch.Size([134]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.local_op.bn2.bias - torch.Size([134]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.global_op.wt_filter - torch.Size([1088, 1, 2, 2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.global_op.iwt_filter - torch.Size([1088, 1, 2, 2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.global_op.global_atten.x_proj_weight - torch.Size([2, 19, 544]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.global_op.global_atten.Ds - torch.Size([1088]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.global_op.global_atten.A_logs - torch.Size([1088, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.global_op.global_atten.dt_projs_weight - torch.Size([2, 544, 17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.global_op.global_atten.dt_projs_bias - torch.Size([2, 544]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.global_op.global_atten.out_norm.weight - torch.Size([544]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.global_op.global_atten.out_norm.bias - torch.Size([544]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.global_op.global_atten.in_proj.c.weight - torch.Size([1088, 272, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.global_op.global_atten.in_proj.bn.weight - torch.Size([1088]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.global_op.global_atten.in_proj.bn.bias - torch.Size([1088]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.global_op.global_atten.conv2d.weight - torch.Size([544, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.global_op.global_atten.conv2d.bias - torch.Size([544]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.global_op.global_atten.out_proj.c.weight - torch.Size([272, 544, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.global_op.global_atten.out_proj.bn.weight - torch.Size([272]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.global_op.global_atten.out_proj.bn.bias - torch.Size([272]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.global_op.base_scale.weight - torch.Size([1, 272, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.global_op.wavelet_convs.0.weight - torch.Size([1088, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.global_op.wavelet_scale.0.weight - torch.Size([1, 1088, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.proj.1.c.weight - torch.Size([448, 448, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.proj.1.bn.weight - torch.Size([448]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.mixer.m.attn.proj.1.bn.bias - torch.Size([448]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.dw1.m.c.weight - torch.Size([448, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.dw1.m.bn.weight - torch.Size([448]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.dw1.m.bn.bias - torch.Size([448]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.ffn1.m.pw1.c.weight - torch.Size([896, 448, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.ffn1.m.pw1.bn.weight - torch.Size([896]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.ffn1.m.pw1.bn.bias - torch.Size([896]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.ffn1.m.pw2.c.weight - torch.Size([448, 896, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.ffn1.m.pw2.bn.weight - torch.Size([448]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.3.ffn1.m.pw2.bn.bias - torch.Size([448]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.dw0.m.c.weight - torch.Size([448, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.dw0.m.bn.weight - torch.Size([448]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.dw0.m.bn.bias - torch.Size([448]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.ffn0.m.pw1.c.weight - torch.Size([896, 448, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.ffn0.m.pw1.bn.weight - torch.Size([896]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.ffn0.m.pw1.bn.bias - torch.Size([896]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.ffn0.m.pw2.c.weight - torch.Size([448, 896, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.ffn0.m.pw2.bn.weight - torch.Size([448]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.ffn0.m.pw2.bn.bias - torch.Size([448]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.local_op.dwconv3x3.weight - torch.Size([134, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.local_op.bn1.weight - torch.Size([134]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.local_op.bn1.bias - torch.Size([134]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.local_op.dwconv1x1.weight - torch.Size([134, 1, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.local_op.bn2.weight - torch.Size([134]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.local_op.bn2.bias - torch.Size([134]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.global_op.wt_filter - torch.Size([1088, 1, 2, 2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.global_op.iwt_filter - torch.Size([1088, 1, 2, 2]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.global_op.global_atten.x_proj_weight - torch.Size([2, 19, 544]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.global_op.global_atten.Ds - torch.Size([1088]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.global_op.global_atten.A_logs - torch.Size([1088, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.global_op.global_atten.dt_projs_weight - torch.Size([2, 544, 17]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.global_op.global_atten.dt_projs_bias - torch.Size([2, 544]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.global_op.global_atten.out_norm.weight - torch.Size([544]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.global_op.global_atten.out_norm.bias - torch.Size([544]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.global_op.global_atten.in_proj.c.weight - torch.Size([1088, 272, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.global_op.global_atten.in_proj.bn.weight - torch.Size([1088]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.global_op.global_atten.in_proj.bn.bias - torch.Size([1088]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.global_op.global_atten.conv2d.weight - torch.Size([544, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.global_op.global_atten.conv2d.bias - torch.Size([544]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.global_op.global_atten.out_proj.c.weight - torch.Size([272, 544, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.global_op.global_atten.out_proj.bn.weight - torch.Size([272]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.global_op.global_atten.out_proj.bn.bias - torch.Size([272]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.global_op.base_scale.weight - torch.Size([1, 272, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.global_op.wavelet_convs.0.weight - torch.Size([1088, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.global_op.wavelet_scale.0.weight - torch.Size([1, 1088, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.proj.1.c.weight - torch.Size([448, 448, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.proj.1.bn.weight - torch.Size([448]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.mixer.m.attn.proj.1.bn.bias - torch.Size([448]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.dw1.m.c.weight - torch.Size([448, 1, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.dw1.m.bn.weight - torch.Size([448]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.dw1.m.bn.bias - torch.Size([448]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.ffn1.m.pw1.c.weight - torch.Size([896, 448, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.ffn1.m.pw1.bn.weight - torch.Size([896]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.ffn1.m.pw1.bn.bias - torch.Size([896]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.ffn1.m.pw2.c.weight - torch.Size([448, 896, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.ffn1.m.pw2.bn.weight - torch.Size([448]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

backbone.blocks3.4.ffn1.m.pw2.bn.bias - torch.Size([448]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.conv_seg.weight - torch.Size([150, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.conv_seg.bias - torch.Size([150]): 
NormalInit: mean=0, std=0.01, bias=0 

decode_head.psp_modules.0.1.conv.weight - torch.Size([256, 448, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.0.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.0.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.1.1.conv.weight - torch.Size([256, 448, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.1.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.1.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.2.1.conv.weight - torch.Size([256, 448, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.2.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.2.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.3.1.conv.weight - torch.Size([256, 448, 1, 1]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.3.1.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.psp_modules.3.1.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.bottleneck.conv.weight - torch.Size([256, 1472, 3, 3]): 
Initialized by user-defined `init_weights` in ConvModule  

decode_head.bottleneck.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

decode_head.bottleneck.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.conv_seg.weight - torch.Size([150, 256, 1, 1]): 
NormalInit: mean=0, std=0.01, bias=0 

auxiliary_head.conv_seg.bias - torch.Size([150]): 
NormalInit: mean=0, std=0.01, bias=0 

auxiliary_head.convs.0.conv.weight - torch.Size([256, 376, 3, 3]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.convs.0.bn.weight - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  

auxiliary_head.convs.0.bn.bias - torch.Size([256]): 
The value is the same before and after calling `init_weights` of EncoderDecoder  
2024/10/27 23:32:49 - mmengine - INFO - Auto resumed from the latest checkpoint work_dirs/pspnet_mobilemamba_B4P-80k_ade20k-512x512/iter_24000.pth.
2024/10/27 23:33:50 - mmengine - INFO - Load checkpoint from work_dirs/pspnet_mobilemamba_B4P-80k_ade20k-512x512/iter_24000.pth
2024/10/27 23:33:50 - mmengine - INFO - resumed epoch: 0, iter: 24000
2024/10/27 23:33:50 - mmengine - WARNING - "FileClient" will be deprecated in future. Please use io functions in https://mmengine.readthedocs.io/en/latest/api/fileio.html#file-io
2024/10/27 23:33:50 - mmengine - WARNING - "HardDiskBackend" is the alias of "LocalBackend" and the former will be deprecated in future.
2024/10/27 23:33:50 - mmengine - INFO - Checkpoints will be saved to work_dirs/pspnet_mobilemamba_B4P-80k_ade20k-512x512.
2024/10/27 23:33:50 - mmengine - WARNING - Advance dataloader 24000 steps to skip data that has already been trained
2024/10/27 23:41:32 - mmengine - INFO - Iter(train) [24050/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 5 days, 23:27:14  time: 1.6000  data_time: 0.0095  memory: 14767  grad_norm: 6.1430  loss: 0.8052  decode.loss_ce: 0.5522  decode.acc_seg: 80.7403  aux.loss_ce: 0.2530  aux.acc_seg: 80.6820
2024/10/27 23:42:52 - mmengine - INFO - Iter(train) [24100/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 3 days, 12:06:38  time: 1.6026  data_time: 0.0100  memory: 6600  grad_norm: 7.8156  loss: 0.7099  decode.loss_ce: 0.4600  decode.acc_seg: 82.5008  aux.loss_ce: 0.2499  aux.acc_seg: 69.1533
2024/10/27 23:44:12 - mmengine - INFO - Iter(train) [24150/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 2 days, 16:20:02  time: 1.6015  data_time: 0.0098  memory: 6603  grad_norm: 7.3070  loss: 0.7618  decode.loss_ce: 0.5139  decode.acc_seg: 86.4025  aux.loss_ce: 0.2478  aux.acc_seg: 85.6491
2024/10/27 23:45:32 - mmengine - INFO - Iter(train) [24200/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 2 days, 6:25:22  time: 1.6023  data_time: 0.0092  memory: 6601  grad_norm: 5.9787  loss: 0.7008  decode.loss_ce: 0.4771  decode.acc_seg: 85.0210  aux.loss_ce: 0.2237  aux.acc_seg: 83.9177
2024/10/27 23:46:53 - mmengine - INFO - Iter(train) [24250/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 2 days, 0:29:41  time: 1.6014  data_time: 0.0091  memory: 6600  grad_norm: 6.4607  loss: 0.8369  decode.loss_ce: 0.5778  decode.acc_seg: 69.0827  aux.loss_ce: 0.2591  aux.acc_seg: 67.5303
2024/10/27 23:48:13 - mmengine - INFO - Iter(train) [24300/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 20:30:58  time: 1.6037  data_time: 0.0091  memory: 6602  grad_norm: 7.2972  loss: 0.8587  decode.loss_ce: 0.5928  decode.acc_seg: 78.0521  aux.loss_ce: 0.2659  aux.acc_seg: 71.2139
2024/10/27 23:49:34 - mmengine - INFO - Iter(train) [24350/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 17:41:09  time: 1.6090  data_time: 0.0097  memory: 6601  grad_norm: 5.4819  loss: 0.8130  decode.loss_ce: 0.5666  decode.acc_seg: 88.6353  aux.loss_ce: 0.2464  aux.acc_seg: 86.3496
2024/10/27 23:50:54 - mmengine - INFO - Iter(train) [24400/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 15:32:38  time: 1.6037  data_time: 0.0098  memory: 6600  grad_norm: 5.5501  loss: 0.6833  decode.loss_ce: 0.4658  decode.acc_seg: 82.5938  aux.loss_ce: 0.2175  aux.acc_seg: 80.7706
2024/10/27 23:52:14 - mmengine - INFO - Iter(train) [24450/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 13:52:07  time: 1.6017  data_time: 0.0101  memory: 6600  grad_norm: 7.7741  loss: 0.7146  decode.loss_ce: 0.4806  decode.acc_seg: 81.9583  aux.loss_ce: 0.2340  aux.acc_seg: 80.1505
2024/10/27 23:53:34 - mmengine - INFO - Iter(train) [24500/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 12:30:47  time: 1.5969  data_time: 0.0098  memory: 6600  grad_norm: 6.6676  loss: 0.7207  decode.loss_ce: 0.4826  decode.acc_seg: 83.1898  aux.loss_ce: 0.2380  aux.acc_seg: 78.7969
2024/10/27 23:54:55 - mmengine - INFO - Iter(train) [24550/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 11:24:40  time: 1.5946  data_time: 0.0097  memory: 6601  grad_norm: 5.5876  loss: 0.7007  decode.loss_ce: 0.4701  decode.acc_seg: 89.7840  aux.loss_ce: 0.2305  aux.acc_seg: 89.7587
2024/10/27 23:56:14 - mmengine - INFO - Iter(train) [24600/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 10:28:42  time: 1.5960  data_time: 0.0102  memory: 6600  grad_norm: 6.0014  loss: 0.7109  decode.loss_ce: 0.4800  decode.acc_seg: 85.4297  aux.loss_ce: 0.2309  aux.acc_seg: 85.2277
2024/10/27 23:57:34 - mmengine - INFO - Iter(train) [24650/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 9:41:08  time: 1.5955  data_time: 0.0098  memory: 6600  grad_norm: 7.0532  loss: 0.7311  decode.loss_ce: 0.5030  decode.acc_seg: 71.8182  aux.loss_ce: 0.2281  aux.acc_seg: 67.7612
2024/10/27 23:58:54 - mmengine - INFO - Iter(train) [24700/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 9:00:15  time: 1.5971  data_time: 0.0100  memory: 6602  grad_norm: 5.5896  loss: 0.6475  decode.loss_ce: 0.4262  decode.acc_seg: 82.5543  aux.loss_ce: 0.2213  aux.acc_seg: 80.0924
2024/10/28 00:00:14 - mmengine - INFO - Iter(train) [24750/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 8:24:41  time: 1.5976  data_time: 0.0103  memory: 6601  grad_norm: 6.0680  loss: 0.7965  decode.loss_ce: 0.5477  decode.acc_seg: 69.9766  aux.loss_ce: 0.2487  aux.acc_seg: 67.3813
2024/10/28 00:01:34 - mmengine - INFO - Iter(train) [24800/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 7:53:56  time: 1.5952  data_time: 0.0102  memory: 6602  grad_norm: 6.9391  loss: 0.6388  decode.loss_ce: 0.4300  decode.acc_seg: 79.6756  aux.loss_ce: 0.2088  aux.acc_seg: 79.0409
2024/10/28 00:02:55 - mmengine - INFO - Iter(train) [24850/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 7:26:26  time: 1.6088  data_time: 0.0100  memory: 6600  grad_norm: 5.6556  loss: 0.7064  decode.loss_ce: 0.4739  decode.acc_seg: 77.8723  aux.loss_ce: 0.2326  aux.acc_seg: 75.1982
2024/10/28 00:04:15 - mmengine - INFO - Iter(train) [24900/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 7:01:46  time: 1.5973  data_time: 0.0101  memory: 6601  grad_norm: 6.6921  loss: 0.7963  decode.loss_ce: 0.5357  decode.acc_seg: 68.3516  aux.loss_ce: 0.2606  aux.acc_seg: 65.7426
2024/10/28 00:05:35 - mmengine - INFO - Iter(train) [24950/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 6:39:19  time: 1.5963  data_time: 0.0102  memory: 6600  grad_norm: 6.8254  loss: 0.6680  decode.loss_ce: 0.4447  decode.acc_seg: 82.8436  aux.loss_ce: 0.2233  aux.acc_seg: 81.8289
2024/10/28 00:06:54 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 00:06:54 - mmengine - INFO - Iter(train) [25000/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 6:18:57  time: 1.5940  data_time: 0.0100  memory: 6600  grad_norm: 6.9309  loss: 0.7576  decode.loss_ce: 0.5227  decode.acc_seg: 69.3169  aux.loss_ce: 0.2349  aux.acc_seg: 74.5417
2024/10/28 00:08:14 - mmengine - INFO - Iter(train) [25050/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 6:00:33  time: 1.5969  data_time: 0.0103  memory: 6600  grad_norm: 5.8105  loss: 0.7756  decode.loss_ce: 0.5276  decode.acc_seg: 83.9614  aux.loss_ce: 0.2480  aux.acc_seg: 80.5559
2024/10/28 00:09:34 - mmengine - INFO - Iter(train) [25100/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 5:43:33  time: 1.5954  data_time: 0.0099  memory: 6603  grad_norm: 5.3008  loss: 0.7494  decode.loss_ce: 0.5213  decode.acc_seg: 83.1190  aux.loss_ce: 0.2281  aux.acc_seg: 82.6987
2024/10/28 00:10:54 - mmengine - INFO - Iter(train) [25150/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 5:28:00  time: 1.5970  data_time: 0.0099  memory: 6600  grad_norm: 5.1113  loss: 0.7487  decode.loss_ce: 0.5026  decode.acc_seg: 87.4154  aux.loss_ce: 0.2460  aux.acc_seg: 86.9110
2024/10/28 00:12:14 - mmengine - INFO - Iter(train) [25200/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 5:13:35  time: 1.5963  data_time: 0.0103  memory: 6600  grad_norm: 7.5085  loss: 0.6912  decode.loss_ce: 0.4660  decode.acc_seg: 78.1314  aux.loss_ce: 0.2252  aux.acc_seg: 73.7091
2024/10/28 00:13:34 - mmengine - INFO - Iter(train) [25250/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 5:00:21  time: 1.5950  data_time: 0.0104  memory: 6604  grad_norm: 7.7776  loss: 0.7513  decode.loss_ce: 0.5125  decode.acc_seg: 84.1518  aux.loss_ce: 0.2388  aux.acc_seg: 82.9758
2024/10/28 00:14:54 - mmengine - INFO - Iter(train) [25300/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 4:47:53  time: 1.5943  data_time: 0.0101  memory: 6600  grad_norm: 6.0406  loss: 0.7062  decode.loss_ce: 0.4849  decode.acc_seg: 78.2027  aux.loss_ce: 0.2212  aux.acc_seg: 77.0392
2024/10/28 00:16:14 - mmengine - INFO - Iter(train) [25350/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 4:36:13  time: 1.5945  data_time: 0.0100  memory: 6600  grad_norm: 6.9231  loss: 0.6532  decode.loss_ce: 0.4489  decode.acc_seg: 90.6917  aux.loss_ce: 0.2044  aux.acc_seg: 89.9517
2024/10/28 00:17:34 - mmengine - INFO - Iter(train) [25400/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 4:25:22  time: 1.5937  data_time: 0.0100  memory: 6601  grad_norm: 7.5205  loss: 0.7362  decode.loss_ce: 0.5043  decode.acc_seg: 78.3718  aux.loss_ce: 0.2319  aux.acc_seg: 74.9169
2024/10/28 00:18:54 - mmengine - INFO - Iter(train) [25450/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 4:15:09  time: 1.6032  data_time: 0.0127  memory: 6600  grad_norm: 8.8847  loss: 0.7152  decode.loss_ce: 0.4686  decode.acc_seg: 90.7676  aux.loss_ce: 0.2466  aux.acc_seg: 76.8219
2024/10/28 00:20:14 - mmengine - INFO - Iter(train) [25500/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 4:05:53  time: 1.6049  data_time: 0.0125  memory: 6600  grad_norm: 5.6999  loss: 0.7032  decode.loss_ce: 0.4767  decode.acc_seg: 73.3353  aux.loss_ce: 0.2266  aux.acc_seg: 65.6922
2024/10/28 00:21:35 - mmengine - INFO - Iter(train) [25550/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 3:57:06  time: 1.6256  data_time: 0.0123  memory: 6600  grad_norm: 7.7517  loss: 0.5923  decode.loss_ce: 0.4170  decode.acc_seg: 88.6864  aux.loss_ce: 0.1753  aux.acc_seg: 88.9082
2024/10/28 00:22:55 - mmengine - INFO - Iter(train) [25600/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 3:48:47  time: 1.6062  data_time: 0.0127  memory: 6600  grad_norm: 7.5613  loss: 0.7852  decode.loss_ce: 0.5409  decode.acc_seg: 85.6908  aux.loss_ce: 0.2443  aux.acc_seg: 84.0378
2024/10/28 00:24:16 - mmengine - INFO - Iter(train) [25650/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 3:40:55  time: 1.6025  data_time: 0.0128  memory: 6600  grad_norm: 6.8218  loss: 0.8445  decode.loss_ce: 0.5781  decode.acc_seg: 74.6409  aux.loss_ce: 0.2664  aux.acc_seg: 73.7349
2024/10/28 00:25:36 - mmengine - INFO - Iter(train) [25700/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 3:33:21  time: 1.6075  data_time: 0.0134  memory: 6601  grad_norm: 7.4419  loss: 0.7730  decode.loss_ce: 0.5340  decode.acc_seg: 76.0237  aux.loss_ce: 0.2391  aux.acc_seg: 74.1487
2024/10/28 00:26:56 - mmengine - INFO - Iter(train) [25750/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 3:26:09  time: 1.6035  data_time: 0.0127  memory: 6601  grad_norm: 6.7960  loss: 0.7001  decode.loss_ce: 0.4781  decode.acc_seg: 85.6037  aux.loss_ce: 0.2220  aux.acc_seg: 82.9947
2024/10/28 00:28:16 - mmengine - INFO - Iter(train) [25800/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 3:19:11  time: 1.6027  data_time: 0.0130  memory: 6602  grad_norm: 6.3099  loss: 0.7758  decode.loss_ce: 0.5274  decode.acc_seg: 83.8080  aux.loss_ce: 0.2484  aux.acc_seg: 76.7897
2024/10/28 00:29:37 - mmengine - INFO - Iter(train) [25850/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 3:12:38  time: 1.6077  data_time: 0.0131  memory: 6601  grad_norm: 6.9991  loss: 0.7006  decode.loss_ce: 0.4841  decode.acc_seg: 75.5017  aux.loss_ce: 0.2165  aux.acc_seg: 77.6704
2024/10/28 00:30:57 - mmengine - INFO - Iter(train) [25900/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 3:06:17  time: 1.6019  data_time: 0.0126  memory: 6600  grad_norm: 7.7463  loss: 0.6875  decode.loss_ce: 0.4782  decode.acc_seg: 85.8533  aux.loss_ce: 0.2093  aux.acc_seg: 85.4493
2024/10/28 00:32:17 - mmengine - INFO - Iter(train) [25950/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 3:00:13  time: 1.6040  data_time: 0.0126  memory: 6599  grad_norm: 6.9436  loss: 0.6030  decode.loss_ce: 0.4221  decode.acc_seg: 89.1553  aux.loss_ce: 0.1808  aux.acc_seg: 87.6092
2024/10/28 00:33:38 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 00:33:38 - mmengine - INFO - Iter(train) [26000/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 2:54:30  time: 1.6047  data_time: 0.0131  memory: 6600  grad_norm: 7.6507  loss: 0.6899  decode.loss_ce: 0.4741  decode.acc_seg: 78.6847  aux.loss_ce: 0.2158  aux.acc_seg: 73.6579
2024/10/28 00:34:59 - mmengine - INFO - Iter(train) [26050/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 2:49:02  time: 1.6054  data_time: 0.0133  memory: 6600  grad_norm: 9.3750  loss: 0.6740  decode.loss_ce: 0.4609  decode.acc_seg: 80.8292  aux.loss_ce: 0.2132  aux.acc_seg: 83.1589
2024/10/28 00:36:19 - mmengine - INFO - Iter(train) [26100/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 2:43:46  time: 1.6050  data_time: 0.0135  memory: 6602  grad_norm: 4.7045  loss: 0.5704  decode.loss_ce: 0.3978  decode.acc_seg: 84.2429  aux.loss_ce: 0.1727  aux.acc_seg: 77.9471
2024/10/28 00:37:40 - mmengine - INFO - Iter(train) [26150/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 2:38:32  time: 1.6020  data_time: 0.0128  memory: 6602  grad_norm: 6.6052  loss: 0.6843  decode.loss_ce: 0.4759  decode.acc_seg: 80.0087  aux.loss_ce: 0.2084  aux.acc_seg: 80.5512
2024/10/28 00:39:00 - mmengine - INFO - Iter(train) [26200/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 2:33:28  time: 1.6054  data_time: 0.0129  memory: 6603  grad_norm: 8.6490  loss: 0.7995  decode.loss_ce: 0.5437  decode.acc_seg: 84.7129  aux.loss_ce: 0.2558  aux.acc_seg: 84.0787
2024/10/28 00:40:20 - mmengine - INFO - Iter(train) [26250/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 2:28:37  time: 1.6051  data_time: 0.0130  memory: 6603  grad_norm: 8.0056  loss: 0.7175  decode.loss_ce: 0.4987  decode.acc_seg: 79.1005  aux.loss_ce: 0.2188  aux.acc_seg: 73.5367
2024/10/28 00:41:41 - mmengine - INFO - Iter(train) [26300/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 2:23:58  time: 1.6056  data_time: 0.0129  memory: 6601  grad_norm: 5.4816  loss: 0.6901  decode.loss_ce: 0.4693  decode.acc_seg: 80.1570  aux.loss_ce: 0.2208  aux.acc_seg: 73.6733
2024/10/28 00:43:01 - mmengine - INFO - Iter(train) [26350/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 2:19:32  time: 1.6047  data_time: 0.0134  memory: 6600  grad_norm: 6.4505  loss: 0.6562  decode.loss_ce: 0.4463  decode.acc_seg: 85.0215  aux.loss_ce: 0.2099  aux.acc_seg: 85.2926
2024/10/28 00:44:26 - mmengine - INFO - Iter(train) [26400/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 2:16:48  time: 1.6067  data_time: 0.0137  memory: 6600  grad_norm: 8.0038  loss: 0.8392  decode.loss_ce: 0.5692  decode.acc_seg: 83.9909  aux.loss_ce: 0.2701  aux.acc_seg: 83.1113
2024/10/28 00:45:47 - mmengine - INFO - Iter(train) [26450/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 2:12:27  time: 1.6074  data_time: 0.0129  memory: 6600  grad_norm: 8.1736  loss: 0.7744  decode.loss_ce: 0.5337  decode.acc_seg: 81.0474  aux.loss_ce: 0.2407  aux.acc_seg: 80.0210
2024/10/28 00:47:07 - mmengine - INFO - Iter(train) [26500/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 2:08:11  time: 1.6040  data_time: 0.0130  memory: 6600  grad_norm: 6.1586  loss: 0.6549  decode.loss_ce: 0.4544  decode.acc_seg: 84.4923  aux.loss_ce: 0.2005  aux.acc_seg: 86.5792
2024/10/28 00:48:27 - mmengine - INFO - Iter(train) [26550/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 2:04:05  time: 1.6055  data_time: 0.0133  memory: 6601  grad_norm: 6.5638  loss: 0.7063  decode.loss_ce: 0.4850  decode.acc_seg: 82.0544  aux.loss_ce: 0.2214  aux.acc_seg: 78.1518
2024/10/28 00:49:48 - mmengine - INFO - Iter(train) [26600/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 2:00:03  time: 1.6070  data_time: 0.0131  memory: 6600  grad_norm: 9.2727  loss: 0.6582  decode.loss_ce: 0.4542  decode.acc_seg: 86.7156  aux.loss_ce: 0.2039  aux.acc_seg: 84.5378
2024/10/28 00:51:08 - mmengine - INFO - Iter(train) [26650/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 1:56:09  time: 1.6051  data_time: 0.0132  memory: 6599  grad_norm: 9.0588  loss: 0.5644  decode.loss_ce: 0.3881  decode.acc_seg: 82.1697  aux.loss_ce: 0.1763  aux.acc_seg: 84.0269
2024/10/28 00:52:28 - mmengine - INFO - Iter(train) [26700/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 1:52:19  time: 1.6052  data_time: 0.0133  memory: 6601  grad_norm: 5.2595  loss: 0.5995  decode.loss_ce: 0.4029  decode.acc_seg: 82.5324  aux.loss_ce: 0.1966  aux.acc_seg: 81.0785
2024/10/28 00:53:49 - mmengine - INFO - Iter(train) [26750/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 1:48:40  time: 1.6021  data_time: 0.0130  memory: 6600  grad_norm: 6.9403  loss: 0.6789  decode.loss_ce: 0.4663  decode.acc_seg: 83.4324  aux.loss_ce: 0.2126  aux.acc_seg: 79.9614
2024/10/28 00:55:10 - mmengine - INFO - Iter(train) [26800/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 1:45:12  time: 1.6316  data_time: 0.0130  memory: 6600  grad_norm: 7.2179  loss: 0.5762  decode.loss_ce: 0.3829  decode.acc_seg: 84.6703  aux.loss_ce: 0.1934  aux.acc_seg: 83.9008
2024/10/28 00:56:30 - mmengine - INFO - Iter(train) [26850/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 1:41:44  time: 1.6073  data_time: 0.0131  memory: 6600  grad_norm: 6.1644  loss: 0.6921  decode.loss_ce: 0.4745  decode.acc_seg: 83.9621  aux.loss_ce: 0.2176  aux.acc_seg: 85.7388
2024/10/28 00:57:51 - mmengine - INFO - Iter(train) [26900/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 1:38:15  time: 1.6038  data_time: 0.0129  memory: 6603  grad_norm: 6.2896  loss: 0.6891  decode.loss_ce: 0.4780  decode.acc_seg: 84.3057  aux.loss_ce: 0.2111  aux.acc_seg: 83.2455
2024/10/28 00:59:11 - mmengine - INFO - Iter(train) [26950/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 1:34:49  time: 1.6038  data_time: 0.0131  memory: 6600  grad_norm: 9.4236  loss: 0.7010  decode.loss_ce: 0.4698  decode.acc_seg: 74.1863  aux.loss_ce: 0.2312  aux.acc_seg: 73.5748
2024/10/28 01:00:31 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 01:00:31 - mmengine - INFO - Iter(train) [27000/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 1:31:28  time: 1.6058  data_time: 0.0130  memory: 6600  grad_norm: 9.2293  loss: 0.7307  decode.loss_ce: 0.5166  decode.acc_seg: 82.4438  aux.loss_ce: 0.2141  aux.acc_seg: 76.7557
2024/10/28 01:01:52 - mmengine - INFO - Iter(train) [27050/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 1:28:13  time: 1.6042  data_time: 0.0103  memory: 6600  grad_norm: 6.9487  loss: 0.6904  decode.loss_ce: 0.4682  decode.acc_seg: 79.6962  aux.loss_ce: 0.2222  aux.acc_seg: 72.9053
2024/10/28 01:03:13 - mmengine - INFO - Iter(train) [27100/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 1:25:07  time: 1.6047  data_time: 0.0108  memory: 6603  grad_norm: 7.1403  loss: 0.6525  decode.loss_ce: 0.4410  decode.acc_seg: 74.3075  aux.loss_ce: 0.2114  aux.acc_seg: 72.0185
2024/10/28 01:04:33 - mmengine - INFO - Iter(train) [27150/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 1:21:56  time: 1.6027  data_time: 0.0108  memory: 6601  grad_norm: 8.3082  loss: 0.7160  decode.loss_ce: 0.4883  decode.acc_seg: 79.4357  aux.loss_ce: 0.2277  aux.acc_seg: 79.1363
2024/10/28 01:05:53 - mmengine - INFO - Iter(train) [27200/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 1:18:51  time: 1.6027  data_time: 0.0110  memory: 6600  grad_norm: 5.7822  loss: 0.7610  decode.loss_ce: 0.5203  decode.acc_seg: 77.9003  aux.loss_ce: 0.2407  aux.acc_seg: 76.1772
2024/10/28 01:07:14 - mmengine - INFO - Iter(train) [27250/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 1:15:46  time: 1.6044  data_time: 0.0112  memory: 6600  grad_norm: 7.9063  loss: 0.6428  decode.loss_ce: 0.4435  decode.acc_seg: 82.3532  aux.loss_ce: 0.1993  aux.acc_seg: 84.2632
2024/10/28 01:08:34 - mmengine - INFO - Iter(train) [27300/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 1:12:49  time: 1.6040  data_time: 0.0107  memory: 6601  grad_norm: 7.2340  loss: 0.6892  decode.loss_ce: 0.4703  decode.acc_seg: 91.2319  aux.loss_ce: 0.2189  aux.acc_seg: 90.4315
2024/10/28 01:09:55 - mmengine - INFO - Iter(train) [27350/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 1:09:56  time: 1.6057  data_time: 0.0107  memory: 6600  grad_norm: 5.9533  loss: 0.6286  decode.loss_ce: 0.4152  decode.acc_seg: 90.8392  aux.loss_ce: 0.2134  aux.acc_seg: 89.4090
2024/10/28 01:11:15 - mmengine - INFO - Iter(train) [27400/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 1:07:00  time: 1.6038  data_time: 0.0108  memory: 6600  grad_norm: 6.9825  loss: 0.7498  decode.loss_ce: 0.5068  decode.acc_seg: 90.8255  aux.loss_ce: 0.2430  aux.acc_seg: 90.7419
2024/10/28 01:12:35 - mmengine - INFO - Iter(train) [27450/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 1:04:06  time: 1.6057  data_time: 0.0109  memory: 6601  grad_norm: 5.7418  loss: 0.7252  decode.loss_ce: 0.4897  decode.acc_seg: 76.4175  aux.loss_ce: 0.2355  aux.acc_seg: 66.4191
2024/10/28 01:13:56 - mmengine - INFO - Iter(train) [27500/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 1:01:18  time: 1.6254  data_time: 0.0109  memory: 6600  grad_norm: 5.2555  loss: 0.6513  decode.loss_ce: 0.4373  decode.acc_seg: 78.1203  aux.loss_ce: 0.2140  aux.acc_seg: 74.2578
2024/10/28 01:15:16 - mmengine - INFO - Iter(train) [27550/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 0:58:31  time: 1.6025  data_time: 0.0104  memory: 6600  grad_norm: 7.2090  loss: 0.7857  decode.loss_ce: 0.5464  decode.acc_seg: 84.2292  aux.loss_ce: 0.2393  aux.acc_seg: 78.0909
2024/10/28 01:16:36 - mmengine - INFO - Iter(train) [27600/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 0:55:46  time: 1.6034  data_time: 0.0102  memory: 6599  grad_norm: 5.9508  loss: 0.6087  decode.loss_ce: 0.4223  decode.acc_seg: 87.4739  aux.loss_ce: 0.1864  aux.acc_seg: 87.8090
2024/10/28 01:17:57 - mmengine - INFO - Iter(train) [27650/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 0:53:13  time: 1.6086  data_time: 0.0104  memory: 6602  grad_norm: 7.9910  loss: 0.7116  decode.loss_ce: 0.4958  decode.acc_seg: 83.7397  aux.loss_ce: 0.2157  aux.acc_seg: 82.1518
2024/10/28 01:19:18 - mmengine - INFO - Iter(train) [27700/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 0:50:40  time: 1.6059  data_time: 0.0104  memory: 6599  grad_norm: 6.8721  loss: 0.7265  decode.loss_ce: 0.4993  decode.acc_seg: 80.2769  aux.loss_ce: 0.2272  aux.acc_seg: 81.6237
2024/10/28 01:20:38 - mmengine - INFO - Iter(train) [27750/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 0:48:03  time: 1.6041  data_time: 0.0104  memory: 6600  grad_norm: 5.8844  loss: 0.6037  decode.loss_ce: 0.4048  decode.acc_seg: 75.9823  aux.loss_ce: 0.1989  aux.acc_seg: 77.0035
2024/10/28 01:21:59 - mmengine - INFO - Iter(train) [27800/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 0:45:33  time: 1.6043  data_time: 0.0106  memory: 6600  grad_norm: 6.0737  loss: 0.7509  decode.loss_ce: 0.5187  decode.acc_seg: 74.9003  aux.loss_ce: 0.2322  aux.acc_seg: 74.3284
2024/10/28 01:23:19 - mmengine - INFO - Iter(train) [27850/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 0:43:00  time: 1.6119  data_time: 0.0107  memory: 6600  grad_norm: 7.5298  loss: 0.7460  decode.loss_ce: 0.5086  decode.acc_seg: 79.9854  aux.loss_ce: 0.2373  aux.acc_seg: 77.3346
2024/10/28 01:24:40 - mmengine - INFO - Iter(train) [27900/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 0:40:31  time: 1.6059  data_time: 0.0108  memory: 6602  grad_norm: 5.6935  loss: 0.6749  decode.loss_ce: 0.4637  decode.acc_seg: 83.0374  aux.loss_ce: 0.2113  aux.acc_seg: 82.4930
2024/10/28 01:26:00 - mmengine - INFO - Iter(train) [27950/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 0:38:00  time: 1.6055  data_time: 0.0110  memory: 6600  grad_norm: 4.9993  loss: 0.7499  decode.loss_ce: 0.5036  decode.acc_seg: 79.1304  aux.loss_ce: 0.2463  aux.acc_seg: 78.0938
2024/10/28 01:27:21 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 01:27:21 - mmengine - INFO - Iter(train) [28000/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 0:35:34  time: 1.6040  data_time: 0.0110  memory: 6600  grad_norm: 9.4238  loss: 0.7584  decode.loss_ce: 0.5231  decode.acc_seg: 76.6112  aux.loss_ce: 0.2353  aux.acc_seg: 78.8072
2024/10/28 01:28:41 - mmengine - INFO - Iter(train) [28050/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 0:33:08  time: 1.6029  data_time: 0.0104  memory: 6601  grad_norm: 6.9062  loss: 0.7037  decode.loss_ce: 0.4756  decode.acc_seg: 87.2562  aux.loss_ce: 0.2281  aux.acc_seg: 81.1249
2024/10/28 01:30:02 - mmengine - INFO - Iter(train) [28100/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 0:30:48  time: 1.6039  data_time: 0.0105  memory: 6600  grad_norm: 6.1780  loss: 0.6782  decode.loss_ce: 0.4567  decode.acc_seg: 84.5377  aux.loss_ce: 0.2215  aux.acc_seg: 85.3933
2024/10/28 01:31:26 - mmengine - INFO - Iter(train) [28150/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 0:29:08  time: 1.6052  data_time: 0.0104  memory: 6601  grad_norm: 6.6980  loss: 0.6595  decode.loss_ce: 0.4733  decode.acc_seg: 83.7822  aux.loss_ce: 0.1862  aux.acc_seg: 79.7595
2024/10/28 01:32:46 - mmengine - INFO - Iter(train) [28200/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 0:26:44  time: 1.6026  data_time: 0.0108  memory: 6599  grad_norm: 6.4360  loss: 0.6995  decode.loss_ce: 0.4724  decode.acc_seg: 84.2126  aux.loss_ce: 0.2271  aux.acc_seg: 85.5986
2024/10/28 01:34:06 - mmengine - INFO - Iter(train) [28250/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 0:24:23  time: 1.6028  data_time: 0.0107  memory: 6600  grad_norm: 5.9028  loss: 0.7335  decode.loss_ce: 0.4989  decode.acc_seg: 84.5004  aux.loss_ce: 0.2346  aux.acc_seg: 83.4214
2024/10/28 01:35:26 - mmengine - INFO - Iter(train) [28300/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 0:22:02  time: 1.6034  data_time: 0.0106  memory: 6601  grad_norm: 6.4073  loss: 0.7861  decode.loss_ce: 0.5390  decode.acc_seg: 81.8259  aux.loss_ce: 0.2471  aux.acc_seg: 80.6409
2024/10/28 01:36:47 - mmengine - INFO - Iter(train) [28350/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 0:19:43  time: 1.6026  data_time: 0.0111  memory: 6600  grad_norm: 8.6384  loss: 0.6861  decode.loss_ce: 0.4662  decode.acc_seg: 77.6334  aux.loss_ce: 0.2199  aux.acc_seg: 74.6827
2024/10/28 01:38:07 - mmengine - INFO - Iter(train) [28400/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 0:17:26  time: 1.6010  data_time: 0.0107  memory: 6600  grad_norm: 6.1405  loss: 0.5683  decode.loss_ce: 0.3867  decode.acc_seg: 86.2534  aux.loss_ce: 0.1816  aux.acc_seg: 85.4996
2024/10/28 01:39:27 - mmengine - INFO - Iter(train) [28450/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 0:15:09  time: 1.6037  data_time: 0.0109  memory: 6603  grad_norm: 5.8357  loss: 0.6479  decode.loss_ce: 0.4461  decode.acc_seg: 80.4373  aux.loss_ce: 0.2017  aux.acc_seg: 76.8155
2024/10/28 01:40:48 - mmengine - INFO - Iter(train) [28500/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 0:12:56  time: 1.6051  data_time: 0.0109  memory: 6600  grad_norm: 8.3475  loss: 0.6313  decode.loss_ce: 0.4303  decode.acc_seg: 88.1865  aux.loss_ce: 0.2010  aux.acc_seg: 88.2373
2024/10/28 01:42:09 - mmengine - INFO - Iter(train) [28550/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 0:10:50  time: 1.6293  data_time: 0.0110  memory: 6602  grad_norm: 6.3308  loss: 0.7104  decode.loss_ce: 0.4971  decode.acc_seg: 81.7006  aux.loss_ce: 0.2133  aux.acc_seg: 82.1238
2024/10/28 01:43:29 - mmengine - INFO - Iter(train) [28600/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 0:08:38  time: 1.6028  data_time: 0.0111  memory: 6601  grad_norm: 5.3278  loss: 0.8047  decode.loss_ce: 0.5443  decode.acc_seg: 82.1264  aux.loss_ce: 0.2605  aux.acc_seg: 78.3670
2024/10/28 01:44:49 - mmengine - INFO - Iter(train) [28650/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 0:06:27  time: 1.6066  data_time: 0.0110  memory: 6600  grad_norm: 5.6234  loss: 0.8056  decode.loss_ce: 0.5424  decode.acc_seg: 78.8007  aux.loss_ce: 0.2632  aux.acc_seg: 73.1025
2024/10/28 01:46:10 - mmengine - INFO - Iter(train) [28700/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 0:04:16  time: 1.6078  data_time: 0.0115  memory: 6599  grad_norm: 6.5007  loss: 0.7784  decode.loss_ce: 0.5219  decode.acc_seg: 82.1739  aux.loss_ce: 0.2565  aux.acc_seg: 79.5369
2024/10/28 01:47:30 - mmengine - INFO - Iter(train) [28750/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 0:02:10  time: 1.6230  data_time: 0.0109  memory: 6601  grad_norm: 8.0443  loss: 0.7321  decode.loss_ce: 0.5027  decode.acc_seg: 75.3109  aux.loss_ce: 0.2294  aux.acc_seg: 71.6370
2024/10/28 01:48:50 - mmengine - INFO - Iter(train) [28800/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 1 day, 0:00:01  time: 1.6050  data_time: 0.0109  memory: 6600  grad_norm: 7.8076  loss: 0.6731  decode.loss_ce: 0.4545  decode.acc_seg: 81.0842  aux.loss_ce: 0.2186  aux.acc_seg: 82.9227
2024/10/28 01:50:11 - mmengine - INFO - Iter(train) [28850/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:57:55  time: 1.6031  data_time: 0.0107  memory: 6600  grad_norm: 6.4062  loss: 0.6760  decode.loss_ce: 0.4685  decode.acc_seg: 79.8921  aux.loss_ce: 0.2075  aux.acc_seg: 79.4796
2024/10/28 01:51:31 - mmengine - INFO - Iter(train) [28900/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:55:50  time: 1.6027  data_time: 0.0107  memory: 6600  grad_norm: 5.9237  loss: 0.5727  decode.loss_ce: 0.3975  decode.acc_seg: 87.0658  aux.loss_ce: 0.1752  aux.acc_seg: 81.5935
2024/10/28 01:52:52 - mmengine - INFO - Iter(train) [28950/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:53:49  time: 1.6068  data_time: 0.0106  memory: 6601  grad_norm: 6.9568  loss: 0.8540  decode.loss_ce: 0.5805  decode.acc_seg: 90.3943  aux.loss_ce: 0.2736  aux.acc_seg: 89.0103
2024/10/28 01:54:12 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 01:54:12 - mmengine - INFO - Iter(train) [29000/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:51:44  time: 1.6030  data_time: 0.0106  memory: 6600  grad_norm: 6.4572  loss: 0.6308  decode.loss_ce: 0.4393  decode.acc_seg: 83.1348  aux.loss_ce: 0.1915  aux.acc_seg: 82.3761
2024/10/28 01:55:33 - mmengine - INFO - Iter(train) [29050/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:49:39  time: 1.6025  data_time: 0.0108  memory: 6600  grad_norm: 5.8050  loss: 0.7053  decode.loss_ce: 0.4835  decode.acc_seg: 84.7366  aux.loss_ce: 0.2218  aux.acc_seg: 83.7638
2024/10/28 01:56:53 - mmengine - INFO - Iter(train) [29100/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:47:38  time: 1.6044  data_time: 0.0107  memory: 6600  grad_norm: 6.7844  loss: 0.6409  decode.loss_ce: 0.4286  decode.acc_seg: 79.4907  aux.loss_ce: 0.2123  aux.acc_seg: 74.8373
2024/10/28 01:58:13 - mmengine - INFO - Iter(train) [29150/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:45:36  time: 1.6029  data_time: 0.0106  memory: 6600  grad_norm: 5.0156  loss: 0.8059  decode.loss_ce: 0.5539  decode.acc_seg: 84.8247  aux.loss_ce: 0.2521  aux.acc_seg: 81.7565
2024/10/28 01:59:34 - mmengine - INFO - Iter(train) [29200/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:43:35  time: 1.6041  data_time: 0.0107  memory: 6600  grad_norm: 6.1916  loss: 0.7498  decode.loss_ce: 0.5064  decode.acc_seg: 82.3295  aux.loss_ce: 0.2434  aux.acc_seg: 81.1322
2024/10/28 02:00:54 - mmengine - INFO - Iter(train) [29250/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:41:36  time: 1.6041  data_time: 0.0103  memory: 6599  grad_norm: 8.3652  loss: 0.6644  decode.loss_ce: 0.4514  decode.acc_seg: 77.0216  aux.loss_ce: 0.2129  aux.acc_seg: 76.9758
2024/10/28 02:02:15 - mmengine - INFO - Iter(train) [29300/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:39:37  time: 1.6041  data_time: 0.0106  memory: 6600  grad_norm: 5.0659  loss: 0.6334  decode.loss_ce: 0.4373  decode.acc_seg: 78.6941  aux.loss_ce: 0.1961  aux.acc_seg: 77.3792
2024/10/28 02:03:35 - mmengine - INFO - Iter(train) [29350/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:37:42  time: 1.6028  data_time: 0.0105  memory: 6600  grad_norm: 6.5149  loss: 0.6337  decode.loss_ce: 0.4362  decode.acc_seg: 87.2823  aux.loss_ce: 0.1975  aux.acc_seg: 83.8548
2024/10/28 02:04:55 - mmengine - INFO - Iter(train) [29400/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:35:43  time: 1.6019  data_time: 0.0105  memory: 6601  grad_norm: 7.9964  loss: 0.6157  decode.loss_ce: 0.4162  decode.acc_seg: 69.0859  aux.loss_ce: 0.1995  aux.acc_seg: 62.8721
2024/10/28 02:06:16 - mmengine - INFO - Iter(train) [29450/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:33:44  time: 1.6016  data_time: 0.0110  memory: 6601  grad_norm: 6.1432  loss: 0.7406  decode.loss_ce: 0.4931  decode.acc_seg: 67.4433  aux.loss_ce: 0.2475  aux.acc_seg: 68.0521
2024/10/28 02:07:36 - mmengine - INFO - Iter(train) [29500/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:31:47  time: 1.6039  data_time: 0.0109  memory: 6601  grad_norm: 4.3236  loss: 0.7157  decode.loss_ce: 0.5017  decode.acc_seg: 79.4383  aux.loss_ce: 0.2140  aux.acc_seg: 78.8811
2024/10/28 02:08:56 - mmengine - INFO - Iter(train) [29550/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:29:50  time: 1.6047  data_time: 0.0108  memory: 6600  grad_norm: 5.7101  loss: 0.7539  decode.loss_ce: 0.5134  decode.acc_seg: 87.1846  aux.loss_ce: 0.2405  aux.acc_seg: 86.2457
2024/10/28 02:10:16 - mmengine - INFO - Iter(train) [29600/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:27:53  time: 1.6022  data_time: 0.0106  memory: 6600  grad_norm: 11.6206  loss: 0.6880  decode.loss_ce: 0.4804  decode.acc_seg: 78.9790  aux.loss_ce: 0.2076  aux.acc_seg: 72.1935
2024/10/28 02:11:37 - mmengine - INFO - Iter(train) [29650/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:26:00  time: 1.6021  data_time: 0.0108  memory: 6600  grad_norm: 5.8791  loss: 0.6090  decode.loss_ce: 0.4181  decode.acc_seg: 81.0099  aux.loss_ce: 0.1909  aux.acc_seg: 82.7041
2024/10/28 02:12:57 - mmengine - INFO - Iter(train) [29700/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:24:05  time: 1.6040  data_time: 0.0107  memory: 6600  grad_norm: 7.1997  loss: 0.6599  decode.loss_ce: 0.4582  decode.acc_seg: 86.7838  aux.loss_ce: 0.2016  aux.acc_seg: 86.6861
2024/10/28 02:14:17 - mmengine - INFO - Iter(train) [29750/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:22:10  time: 1.6129  data_time: 0.0105  memory: 6599  grad_norm: 6.2218  loss: 0.6056  decode.loss_ce: 0.4090  decode.acc_seg: 86.5416  aux.loss_ce: 0.1967  aux.acc_seg: 84.5935
2024/10/28 02:15:38 - mmengine - INFO - Iter(train) [29800/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:20:18  time: 1.6027  data_time: 0.0108  memory: 6600  grad_norm: 10.9342  loss: 0.6524  decode.loss_ce: 0.4511  decode.acc_seg: 84.8698  aux.loss_ce: 0.2013  aux.acc_seg: 84.2304
2024/10/28 02:16:58 - mmengine - INFO - Iter(train) [29850/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:18:27  time: 1.6018  data_time: 0.0107  memory: 6600  grad_norm: 6.2333  loss: 0.6422  decode.loss_ce: 0.4456  decode.acc_seg: 76.0776  aux.loss_ce: 0.1966  aux.acc_seg: 76.5581
2024/10/28 02:18:18 - mmengine - INFO - Iter(train) [29900/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:16:34  time: 1.6042  data_time: 0.0103  memory: 6600  grad_norm: 5.3512  loss: 0.6200  decode.loss_ce: 0.4115  decode.acc_seg: 86.8720  aux.loss_ce: 0.2086  aux.acc_seg: 85.4057
2024/10/28 02:19:38 - mmengine - INFO - Iter(train) [29950/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:14:41  time: 1.6016  data_time: 0.0109  memory: 6601  grad_norm: 6.8326  loss: 0.7239  decode.loss_ce: 0.4864  decode.acc_seg: 86.9253  aux.loss_ce: 0.2375  aux.acc_seg: 87.3160
2024/10/28 02:20:59 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 02:20:59 - mmengine - INFO - Iter(train) [30000/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:12:52  time: 1.6056  data_time: 0.0108  memory: 6600  grad_norm: 6.7744  loss: 0.6133  decode.loss_ce: 0.4121  decode.acc_seg: 83.0912  aux.loss_ce: 0.2012  aux.acc_seg: 81.3324
2024/10/28 02:22:19 - mmengine - INFO - Iter(train) [30050/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:11:00  time: 1.6008  data_time: 0.0108  memory: 6600  grad_norm: 6.7819  loss: 0.6621  decode.loss_ce: 0.4494  decode.acc_seg: 84.7569  aux.loss_ce: 0.2127  aux.acc_seg: 82.4297
2024/10/28 02:23:39 - mmengine - INFO - Iter(train) [30100/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:09:09  time: 1.6012  data_time: 0.0105  memory: 6600  grad_norm: 6.1817  loss: 0.7671  decode.loss_ce: 0.5416  decode.acc_seg: 66.6719  aux.loss_ce: 0.2255  aux.acc_seg: 66.0167
2024/10/28 02:25:00 - mmengine - INFO - Iter(train) [30150/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:07:19  time: 1.6044  data_time: 0.0106  memory: 6601  grad_norm: 5.0166  loss: 0.6874  decode.loss_ce: 0.4753  decode.acc_seg: 83.3055  aux.loss_ce: 0.2121  aux.acc_seg: 84.3137
2024/10/28 02:26:20 - mmengine - INFO - Iter(train) [30200/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:05:31  time: 1.6081  data_time: 0.0107  memory: 6600  grad_norm: 5.7722  loss: 0.6034  decode.loss_ce: 0.4058  decode.acc_seg: 86.3480  aux.loss_ce: 0.1976  aux.acc_seg: 83.1976
2024/10/28 02:27:40 - mmengine - INFO - Iter(train) [30250/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:03:42  time: 1.6058  data_time: 0.0106  memory: 6600  grad_norm: 6.2182  loss: 0.7263  decode.loss_ce: 0.4959  decode.acc_seg: 88.0399  aux.loss_ce: 0.2303  aux.acc_seg: 82.7677
2024/10/28 02:29:01 - mmengine - INFO - Iter(train) [30300/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:01:54  time: 1.6023  data_time: 0.0111  memory: 6601  grad_norm: 6.8367  loss: 0.7338  decode.loss_ce: 0.5015  decode.acc_seg: 70.0140  aux.loss_ce: 0.2323  aux.acc_seg: 71.0399
2024/10/28 02:30:21 - mmengine - INFO - Iter(train) [30350/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 23:00:06  time: 1.6017  data_time: 0.0112  memory: 6600  grad_norm: 5.8943  loss: 0.5881  decode.loss_ce: 0.4014  decode.acc_seg: 87.9605  aux.loss_ce: 0.1867  aux.acc_seg: 85.4099
2024/10/28 02:31:41 - mmengine - INFO - Iter(train) [30400/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:58:19  time: 1.6006  data_time: 0.0110  memory: 6600  grad_norm: 6.8168  loss: 0.6649  decode.loss_ce: 0.4505  decode.acc_seg: 81.5796  aux.loss_ce: 0.2144  aux.acc_seg: 77.9789
2024/10/28 02:33:02 - mmengine - INFO - Iter(train) [30450/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:56:32  time: 1.6046  data_time: 0.0111  memory: 6601  grad_norm: 6.8137  loss: 0.6749  decode.loss_ce: 0.4531  decode.acc_seg: 80.3070  aux.loss_ce: 0.2219  aux.acc_seg: 79.1624
2024/10/28 02:34:27 - mmengine - INFO - Iter(train) [30500/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:55:21  time: 1.6054  data_time: 0.0134  memory: 6599  grad_norm: 5.8186  loss: 0.6277  decode.loss_ce: 0.4226  decode.acc_seg: 78.4445  aux.loss_ce: 0.2050  aux.acc_seg: 80.9441
2024/10/28 02:35:48 - mmengine - INFO - Iter(train) [30550/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:53:41  time: 1.6026  data_time: 0.0128  memory: 6600  grad_norm: 7.0940  loss: 0.6509  decode.loss_ce: 0.4547  decode.acc_seg: 84.3990  aux.loss_ce: 0.1962  aux.acc_seg: 83.7461
2024/10/28 02:37:09 - mmengine - INFO - Iter(train) [30600/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:51:59  time: 1.6057  data_time: 0.0133  memory: 6601  grad_norm: 7.6640  loss: 0.6831  decode.loss_ce: 0.4811  decode.acc_seg: 80.1240  aux.loss_ce: 0.2020  aux.acc_seg: 79.6295
2024/10/28 02:38:29 - mmengine - INFO - Iter(train) [30650/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:50:15  time: 1.6067  data_time: 0.0134  memory: 6599  grad_norm: 7.5636  loss: 0.7479  decode.loss_ce: 0.5123  decode.acc_seg: 86.7649  aux.loss_ce: 0.2356  aux.acc_seg: 79.5388
2024/10/28 02:39:50 - mmengine - INFO - Iter(train) [30700/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:48:31  time: 1.6037  data_time: 0.0131  memory: 6600  grad_norm: 5.8383  loss: 0.6508  decode.loss_ce: 0.4478  decode.acc_seg: 76.6500  aux.loss_ce: 0.2030  aux.acc_seg: 74.6676
2024/10/28 02:41:10 - mmengine - INFO - Iter(train) [30750/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:46:45  time: 1.6034  data_time: 0.0129  memory: 6602  grad_norm: 6.0746  loss: 0.6185  decode.loss_ce: 0.4162  decode.acc_seg: 84.5966  aux.loss_ce: 0.2023  aux.acc_seg: 78.0327
2024/10/28 02:42:30 - mmengine - INFO - Iter(train) [30800/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:45:00  time: 1.6019  data_time: 0.0132  memory: 6600  grad_norm: 7.1858  loss: 0.7720  decode.loss_ce: 0.5329  decode.acc_seg: 67.6699  aux.loss_ce: 0.2390  aux.acc_seg: 65.5753
2024/10/28 02:43:50 - mmengine - INFO - Iter(train) [30850/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:43:16  time: 1.6034  data_time: 0.0137  memory: 6600  grad_norm: 6.5270  loss: 0.7000  decode.loss_ce: 0.4786  decode.acc_seg: 85.8556  aux.loss_ce: 0.2214  aux.acc_seg: 81.9911
2024/10/28 02:45:11 - mmengine - INFO - Iter(train) [30900/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:41:31  time: 1.6034  data_time: 0.0128  memory: 6601  grad_norm: 5.6288  loss: 0.5564  decode.loss_ce: 0.3822  decode.acc_seg: 75.6596  aux.loss_ce: 0.1742  aux.acc_seg: 74.9928
2024/10/28 02:46:31 - mmengine - INFO - Iter(train) [30950/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:39:47  time: 1.6018  data_time: 0.0130  memory: 6600  grad_norm: 6.0266  loss: 0.6215  decode.loss_ce: 0.4179  decode.acc_seg: 87.7968  aux.loss_ce: 0.2035  aux.acc_seg: 88.2820
2024/10/28 02:47:51 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 02:47:51 - mmengine - INFO - Iter(train) [31000/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:38:06  time: 1.6055  data_time: 0.0131  memory: 6599  grad_norm: 7.9762  loss: 0.6402  decode.loss_ce: 0.4316  decode.acc_seg: 82.7094  aux.loss_ce: 0.2086  aux.acc_seg: 79.7659
2024/10/28 02:49:12 - mmengine - INFO - Iter(train) [31050/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:36:28  time: 1.6177  data_time: 0.0130  memory: 6602  grad_norm: 6.3711  loss: 0.6855  decode.loss_ce: 0.4598  decode.acc_seg: 82.5244  aux.loss_ce: 0.2256  aux.acc_seg: 80.6517
2024/10/28 02:50:33 - mmengine - INFO - Iter(train) [31100/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:34:47  time: 1.6074  data_time: 0.0134  memory: 6600  grad_norm: 6.9989  loss: 0.6663  decode.loss_ce: 0.4453  decode.acc_seg: 79.1983  aux.loss_ce: 0.2210  aux.acc_seg: 72.9081
2024/10/28 02:51:53 - mmengine - INFO - Iter(train) [31150/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:33:05  time: 1.6062  data_time: 0.0132  memory: 6602  grad_norm: 6.9651  loss: 0.6568  decode.loss_ce: 0.4538  decode.acc_seg: 86.8554  aux.loss_ce: 0.2030  aux.acc_seg: 87.1128
2024/10/28 02:53:14 - mmengine - INFO - Iter(train) [31200/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:31:24  time: 1.6075  data_time: 0.0134  memory: 6603  grad_norm: 8.4259  loss: 0.6329  decode.loss_ce: 0.4275  decode.acc_seg: 82.3920  aux.loss_ce: 0.2054  aux.acc_seg: 85.5884
2024/10/28 02:54:35 - mmengine - INFO - Iter(train) [31250/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:29:46  time: 1.6093  data_time: 0.0129  memory: 6599  grad_norm: 8.0167  loss: 0.7002  decode.loss_ce: 0.4547  decode.acc_seg: 83.6564  aux.loss_ce: 0.2455  aux.acc_seg: 82.1474
2024/10/28 02:55:55 - mmengine - INFO - Iter(train) [31300/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:28:04  time: 1.6038  data_time: 0.0127  memory: 6600  grad_norm: 5.6465  loss: 0.6905  decode.loss_ce: 0.4663  decode.acc_seg: 73.3403  aux.loss_ce: 0.2242  aux.acc_seg: 74.8324
2024/10/28 02:57:15 - mmengine - INFO - Iter(train) [31350/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:26:23  time: 1.6054  data_time: 0.0130  memory: 6601  grad_norm: 11.4455  loss: 0.7006  decode.loss_ce: 0.4814  decode.acc_seg: 74.5647  aux.loss_ce: 0.2192  aux.acc_seg: 75.3221
2024/10/28 02:58:35 - mmengine - INFO - Iter(train) [31400/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:24:42  time: 1.6060  data_time: 0.0132  memory: 6600  grad_norm: 5.7358  loss: 0.6474  decode.loss_ce: 0.4463  decode.acc_seg: 87.6680  aux.loss_ce: 0.2011  aux.acc_seg: 87.3006
2024/10/28 02:59:56 - mmengine - INFO - Iter(train) [31450/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:23:04  time: 1.6037  data_time: 0.0126  memory: 6600  grad_norm: 6.9975  loss: 0.6385  decode.loss_ce: 0.4350  decode.acc_seg: 82.8970  aux.loss_ce: 0.2036  aux.acc_seg: 83.9250
2024/10/28 03:01:17 - mmengine - INFO - Iter(train) [31500/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:21:25  time: 1.6059  data_time: 0.0133  memory: 6600  grad_norm: 5.8382  loss: 0.7157  decode.loss_ce: 0.4920  decode.acc_seg: 81.8289  aux.loss_ce: 0.2237  aux.acc_seg: 78.3447
2024/10/28 03:02:37 - mmengine - INFO - Iter(train) [31550/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:19:46  time: 1.6074  data_time: 0.0136  memory: 6601  grad_norm: 8.8256  loss: 0.7457  decode.loss_ce: 0.5085  decode.acc_seg: 66.0079  aux.loss_ce: 0.2372  aux.acc_seg: 70.9970
2024/10/28 03:03:58 - mmengine - INFO - Iter(train) [31600/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:18:10  time: 1.6069  data_time: 0.0131  memory: 6600  grad_norm: 6.3233  loss: 0.6398  decode.loss_ce: 0.4359  decode.acc_seg: 88.3780  aux.loss_ce: 0.2039  aux.acc_seg: 86.1049
2024/10/28 03:05:18 - mmengine - INFO - Iter(train) [31650/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:16:29  time: 1.6004  data_time: 0.0098  memory: 6602  grad_norm: 6.4011  loss: 0.7043  decode.loss_ce: 0.4918  decode.acc_seg: 74.7029  aux.loss_ce: 0.2125  aux.acc_seg: 74.2865
2024/10/28 03:06:38 - mmengine - INFO - Iter(train) [31700/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:14:49  time: 1.6216  data_time: 0.0099  memory: 6599  grad_norm: 5.8072  loss: 0.7539  decode.loss_ce: 0.5094  decode.acc_seg: 77.5702  aux.loss_ce: 0.2445  aux.acc_seg: 76.1231
2024/10/28 03:07:58 - mmengine - INFO - Iter(train) [31750/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:13:08  time: 1.6011  data_time: 0.0101  memory: 6600  grad_norm: 7.9260  loss: 0.6992  decode.loss_ce: 0.4706  decode.acc_seg: 81.4588  aux.loss_ce: 0.2287  aux.acc_seg: 81.5616
2024/10/28 03:09:19 - mmengine - INFO - Iter(train) [31800/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:11:29  time: 1.5999  data_time: 0.0098  memory: 6600  grad_norm: 6.3452  loss: 0.7105  decode.loss_ce: 0.4867  decode.acc_seg: 76.4192  aux.loss_ce: 0.2238  aux.acc_seg: 77.7361
2024/10/28 03:10:39 - mmengine - INFO - Iter(train) [31850/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:09:54  time: 1.6044  data_time: 0.0100  memory: 6600  grad_norm: 6.8877  loss: 0.6464  decode.loss_ce: 0.4443  decode.acc_seg: 87.7719  aux.loss_ce: 0.2021  aux.acc_seg: 82.4697
2024/10/28 03:12:00 - mmengine - INFO - Iter(train) [31900/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:08:16  time: 1.5976  data_time: 0.0098  memory: 6600  grad_norm: 7.8021  loss: 0.5901  decode.loss_ce: 0.4110  decode.acc_seg: 78.2771  aux.loss_ce: 0.1791  aux.acc_seg: 74.0687
2024/10/28 03:13:20 - mmengine - INFO - Iter(train) [31950/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:06:36  time: 1.5980  data_time: 0.0108  memory: 6600  grad_norm: 7.8711  loss: 0.7278  decode.loss_ce: 0.4993  decode.acc_seg: 86.4143  aux.loss_ce: 0.2285  aux.acc_seg: 87.2238
2024/10/28 03:14:40 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 03:14:40 - mmengine - INFO - Iter(train) [32000/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:04:57  time: 1.6008  data_time: 0.0099  memory: 6600  grad_norm: 6.2704  loss: 0.7123  decode.loss_ce: 0.4838  decode.acc_seg: 78.7374  aux.loss_ce: 0.2285  aux.acc_seg: 74.8426
2024/10/28 03:14:40 - mmengine - INFO - Saving checkpoint at 32000 iterations
2024/10/28 03:14:59 - mmengine - INFO - Iter(val) [ 50/500]    eta: 0:02:23  time: 0.1461  data_time: 0.0013  memory: 11315  
2024/10/28 03:15:07 - mmengine - INFO - Iter(val) [100/500]    eta: 0:01:36  time: 0.0459  data_time: 0.0011  memory: 11317  
2024/10/28 03:15:11 - mmengine - INFO - Iter(val) [150/500]    eta: 0:01:04  time: 0.0327  data_time: 0.0011  memory: 2521  
2024/10/28 03:15:18 - mmengine - INFO - Iter(val) [200/500]    eta: 0:00:51  time: 0.0333  data_time: 0.0011  memory: 5505  
2024/10/28 03:15:21 - mmengine - INFO - Iter(val) [250/500]    eta: 0:00:37  time: 0.1354  data_time: 0.0012  memory: 867  
2024/10/28 03:15:25 - mmengine - INFO - Iter(val) [300/500]    eta: 0:00:27  time: 0.1378  data_time: 0.0013  memory: 5504  
2024/10/28 03:15:27 - mmengine - INFO - Iter(val) [350/500]    eta: 0:00:18  time: 0.0367  data_time: 0.0012  memory: 793  
2024/10/28 03:15:31 - mmengine - INFO - Iter(val) [400/500]    eta: 0:00:11  time: 0.0267  data_time: 0.0011  memory: 863  
2024/10/28 03:15:35 - mmengine - INFO - Iter(val) [450/500]    eta: 0:00:05  time: 0.0303  data_time: 0.0011  memory: 5044  
2024/10/28 03:15:39 - mmengine - INFO - Iter(val) [500/500]    eta: 0:00:00  time: 0.1527  data_time: 0.0012  memory: 848  
2024/10/28 03:15:41 - mmengine - INFO - per class results:
2024/10/28 03:15:41 - mmengine - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 65.63 | 83.83 |
|       building      | 75.41 | 88.83 |
|         sky         | 88.59 |  94.3 |
|        floor        | 69.02 | 82.98 |
|         tree        |  65.3 | 85.33 |
|       ceiling       | 76.49 |  87.0 |
|         road        | 76.21 | 83.43 |
|         bed         | 78.49 | 87.32 |
|      windowpane     | 50.14 |  68.3 |
|        grass        | 51.34 | 64.89 |
|       cabinet       | 50.36 | 64.29 |
|       sidewalk      | 54.65 | 69.47 |
|        person       | 59.63 | 76.68 |
|        earth        | 24.08 | 38.67 |
|         door        | 30.26 | 40.91 |
|        table        | 41.98 | 58.32 |
|       mountain      | 48.66 | 57.86 |
|        plant        | 35.73 | 43.68 |
|       curtain       |  53.2 | 71.47 |
|        chair        | 36.69 | 47.62 |
|         car         | 70.19 | 83.89 |
|        water        | 41.24 | 53.12 |
|       painting      | 47.33 |  59.5 |
|         sofa        | 51.94 | 69.28 |
|        shelf        | 28.98 | 44.07 |
|        house        | 22.88 | 25.28 |
|         sea         | 45.35 | 75.78 |
|        mirror       |  51.3 | 59.14 |
|         rug         | 46.34 | 60.31 |
|        field        | 22.46 | 57.38 |
|       armchair      | 31.59 | 50.28 |
|         seat        | 54.91 |  69.6 |
|        fence        | 35.36 | 49.66 |
|         desk        | 36.22 | 48.99 |
|         rock        | 33.15 | 45.91 |
|       wardrobe      | 34.93 |  44.1 |
|         lamp        | 27.21 | 33.63 |
|       bathtub       | 55.51 | 69.23 |
|       railing       | 25.48 |  36.1 |
|       cushion       | 31.17 | 40.76 |
|         base        | 15.93 | 28.39 |
|         box         | 12.82 | 17.16 |
|        column       | 23.45 | 36.57 |
|      signboard      | 17.03 | 22.76 |
|   chest of drawers  | 37.18 | 47.52 |
|       counter       | 23.47 | 34.09 |
|         sand        |  25.8 | 37.16 |
|         sink        | 38.77 | 60.73 |
|      skyscraper     |  42.8 | 68.04 |
|      fireplace      | 62.26 | 81.29 |
|     refrigerator    | 53.18 | 79.72 |
|      grandstand     | 25.96 | 48.75 |
|         path        | 21.74 | 31.85 |
|        stairs       | 29.27 | 43.13 |
|        runway       | 67.29 |  92.8 |
|         case        | 52.21 | 67.04 |
|      pool table     | 40.14 |  45.8 |
|        pillow       | 41.93 | 55.58 |
|     screen door     | 56.21 |  76.3 |
|       stairway      | 24.02 | 36.37 |
|        river        |  8.66 | 21.88 |
|        bridge       | 49.88 | 54.31 |
|       bookcase      | 28.47 |  40.1 |
|        blind        |  26.7 |  31.7 |
|     coffee table    | 45.11 | 67.09 |
|        toilet       | 51.08 | 69.25 |
|        flower       | 17.59 |  47.2 |
|         book        | 34.33 | 50.88 |
|         hill        | 10.98 | 18.36 |
|        bench        | 34.75 | 41.48 |
|      countertop     | 36.39 | 49.33 |
|        stove        | 56.54 | 69.14 |
|         palm        | 31.22 | 37.87 |
|    kitchen island   | 25.08 | 76.21 |
|       computer      | 43.86 | 52.32 |
|     swivel chair    | 29.73 | 41.94 |
|         boat        | 59.38 |  70.3 |
|         bar         | 19.78 | 22.71 |
|    arcade machine   | 61.45 | 70.18 |
|        hovel        | 36.43 | 42.52 |
|         bus         | 71.66 | 83.77 |
|        towel        | 31.18 | 47.11 |
|        light        |  6.78 |  7.2  |
|        truck        | 15.72 | 23.62 |
|        tower        | 32.27 | 55.69 |
|      chandelier     | 45.66 | 56.67 |
|        awning       |  8.09 |  8.64 |
|     streetlight     |  3.87 |  4.51 |
|        booth        | 34.92 | 40.58 |
| television receiver | 51.39 | 67.97 |
|       airplane      |  29.7 | 37.07 |
|      dirt track     | 16.22 | 41.63 |
|       apparel       | 19.89 | 33.64 |
|         pole        |  6.43 | 14.29 |
|         land        |  0.67 |  1.49 |
|      bannister      |  3.17 |  3.85 |
|      escalator      | 37.52 | 49.32 |
|       ottoman       | 31.33 |  49.6 |
|        bottle       | 20.18 | 32.65 |
|        buffet       | 38.53 | 41.57 |
|        poster       | 12.59 | 13.26 |
|        stage        |  8.86 | 19.79 |
|         van         | 21.66 | 26.17 |
|         ship        | 89.52 | 91.95 |
|       fountain      | 16.65 | 18.12 |
|    conveyer belt    | 47.81 | 84.82 |
|        canopy       |  5.37 | 10.72 |
|        washer       | 60.46 | 65.01 |
|      plaything      |  13.3 | 20.96 |
|    swimming pool    | 54.75 | 56.12 |
|        stool        | 15.94 | 27.74 |
|        barrel       | 11.67 | 80.45 |
|        basket       | 12.34 | 16.29 |
|      waterfall      | 48.78 | 76.88 |
|         tent        |  75.0 | 90.12 |
|         bag         |  3.64 |  4.7  |
|       minibike      | 44.07 | 52.19 |
|        cradle       | 59.46 | 77.11 |
|         oven        | 24.21 | 47.09 |
|         ball        | 28.16 | 43.88 |
|         food        | 41.26 | 57.97 |
|         step        | 10.93 | 18.16 |
|         tank        | 32.82 | 42.14 |
|      trade name     |  8.56 |  8.95 |
|      microwave      | 24.76 | 26.03 |
|         pot         | 17.78 | 20.71 |
|        animal       | 37.11 | 42.09 |
|       bicycle       | 30.27 | 43.96 |
|         lake        | 32.56 | 67.68 |
|      dishwasher     | 43.23 | 58.25 |
|        screen       | 50.14 | 79.78 |
|       blanket       |  0.19 |  0.21 |
|      sculpture      |  33.6 |  45.1 |
|         hood        | 35.22 | 57.03 |
|        sconce       | 17.59 | 21.75 |
|         vase        | 14.24 | 17.21 |
|    traffic light    | 10.86 | 17.19 |
|         tray        |  1.44 |  2.59 |
|        ashcan       | 19.15 | 31.43 |
|         fan         | 26.27 | 32.56 |
|         pier        |  7.58 |  8.68 |
|      crt screen     |  0.0  |  0.0  |
|        plate        | 17.72 | 20.92 |
|       monitor       |  6.32 |  7.47 |
|    bulletin board   | 21.52 |  25.1 |
|        shower       |  0.0  |  0.0  |
|       radiator      | 30.35 |  33.6 |
|        glass        |  1.56 |  1.71 |
|        clock        | 13.46 | 16.44 |
|         flag        | 21.03 | 27.74 |
+---------------------+-------+-------+
2024/10/28 03:15:41 - mmengine - INFO - Iter(val) [500/500]    aAcc: 74.3500  mIoU: 34.0700  mAcc: 46.0900  data_time: 0.0015  time: 0.1113
2024/10/28 03:17:01 - mmengine - INFO - Iter(train) [32050/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:03:29  time: 1.6018  data_time: 0.0103  memory: 6600  grad_norm: 7.1964  loss: 0.7023  decode.loss_ce: 0.4776  decode.acc_seg: 88.8146  aux.loss_ce: 0.2248  aux.acc_seg: 89.1183
2024/10/28 03:18:21 - mmengine - INFO - Iter(train) [32100/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:01:51  time: 1.6011  data_time: 0.0102  memory: 6598  grad_norm: 9.2698  loss: 0.6318  decode.loss_ce: 0.4309  decode.acc_seg: 84.4272  aux.loss_ce: 0.2009  aux.acc_seg: 81.2359
2024/10/28 03:19:41 - mmengine - INFO - Iter(train) [32150/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 22:00:12  time: 1.6018  data_time: 0.0100  memory: 6600  grad_norm: 7.6194  loss: 0.7811  decode.loss_ce: 0.5367  decode.acc_seg: 83.6877  aux.loss_ce: 0.2444  aux.acc_seg: 79.4195
2024/10/28 03:21:01 - mmengine - INFO - Iter(train) [32200/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:58:34  time: 1.6024  data_time: 0.0102  memory: 6600  grad_norm: 6.1415  loss: 0.5851  decode.loss_ce: 0.3952  decode.acc_seg: 78.2880  aux.loss_ce: 0.1899  aux.acc_seg: 77.7955
2024/10/28 03:22:26 - mmengine - INFO - Iter(train) [32250/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:57:19  time: 1.5998  data_time: 0.0095  memory: 6600  grad_norm: 6.8545  loss: 0.5813  decode.loss_ce: 0.3944  decode.acc_seg: 91.3788  aux.loss_ce: 0.1869  aux.acc_seg: 92.1654
2024/10/28 03:23:46 - mmengine - INFO - Iter(train) [32300/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:55:43  time: 1.6005  data_time: 0.0101  memory: 6600  grad_norm: 6.0267  loss: 0.7497  decode.loss_ce: 0.5200  decode.acc_seg: 75.8306  aux.loss_ce: 0.2297  aux.acc_seg: 74.1929
2024/10/28 03:25:06 - mmengine - INFO - Iter(train) [32350/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:54:07  time: 1.6016  data_time: 0.0104  memory: 6599  grad_norm: 8.9311  loss: 0.7686  decode.loss_ce: 0.5278  decode.acc_seg: 81.2725  aux.loss_ce: 0.2409  aux.acc_seg: 78.4009
2024/10/28 03:26:27 - mmengine - INFO - Iter(train) [32400/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:52:30  time: 1.6010  data_time: 0.0105  memory: 6599  grad_norm: 5.8168  loss: 0.6088  decode.loss_ce: 0.3958  decode.acc_seg: 86.3262  aux.loss_ce: 0.2130  aux.acc_seg: 82.1164
2024/10/28 03:27:47 - mmengine - INFO - Iter(train) [32450/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:50:54  time: 1.6006  data_time: 0.0100  memory: 6600  grad_norm: 6.0446  loss: 0.6540  decode.loss_ce: 0.4384  decode.acc_seg: 88.4727  aux.loss_ce: 0.2156  aux.acc_seg: 86.9527
2024/10/28 03:29:07 - mmengine - INFO - Iter(train) [32500/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:49:18  time: 1.6126  data_time: 0.0098  memory: 6598  grad_norm: 7.9882  loss: 0.5788  decode.loss_ce: 0.4010  decode.acc_seg: 91.7026  aux.loss_ce: 0.1779  aux.acc_seg: 90.2448
2024/10/28 03:30:28 - mmengine - INFO - Iter(train) [32550/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:47:45  time: 1.6136  data_time: 0.0101  memory: 6601  grad_norm: 6.4397  loss: 0.6469  decode.loss_ce: 0.4414  decode.acc_seg: 80.4971  aux.loss_ce: 0.2055  aux.acc_seg: 78.7383
2024/10/28 03:31:49 - mmengine - INFO - Iter(train) [32600/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:46:11  time: 1.6131  data_time: 0.0098  memory: 6599  grad_norm: 6.0415  loss: 0.6184  decode.loss_ce: 0.4185  decode.acc_seg: 84.2747  aux.loss_ce: 0.2000  aux.acc_seg: 83.1602
2024/10/28 03:33:10 - mmengine - INFO - Iter(train) [32650/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:44:38  time: 1.6132  data_time: 0.0098  memory: 6599  grad_norm: 7.6052  loss: 0.7404  decode.loss_ce: 0.5076  decode.acc_seg: 77.8616  aux.loss_ce: 0.2329  aux.acc_seg: 77.0237
2024/10/28 03:34:30 - mmengine - INFO - Iter(train) [32700/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:43:05  time: 1.6121  data_time: 0.0097  memory: 6600  grad_norm: 8.5529  loss: 0.5722  decode.loss_ce: 0.3957  decode.acc_seg: 82.9735  aux.loss_ce: 0.1765  aux.acc_seg: 82.8310
2024/10/28 03:35:51 - mmengine - INFO - Iter(train) [32750/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:41:31  time: 1.6093  data_time: 0.0097  memory: 6599  grad_norm: 10.2846  loss: 0.6595  decode.loss_ce: 0.4436  decode.acc_seg: 82.2090  aux.loss_ce: 0.2159  aux.acc_seg: 83.1741
2024/10/28 03:37:11 - mmengine - INFO - Iter(train) [32800/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:39:57  time: 1.6095  data_time: 0.0098  memory: 6598  grad_norm: 7.9544  loss: 0.8949  decode.loss_ce: 0.6131  decode.acc_seg: 74.4321  aux.loss_ce: 0.2818  aux.acc_seg: 73.7485
2024/10/28 03:38:32 - mmengine - INFO - Iter(train) [32850/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:38:25  time: 1.6144  data_time: 0.0104  memory: 6599  grad_norm: 5.8011  loss: 0.5750  decode.loss_ce: 0.3875  decode.acc_seg: 88.5429  aux.loss_ce: 0.1875  aux.acc_seg: 88.0261
2024/10/28 03:39:53 - mmengine - INFO - Iter(train) [32900/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:36:50  time: 1.6151  data_time: 0.0101  memory: 6599  grad_norm: 7.0879  loss: 0.7887  decode.loss_ce: 0.5365  decode.acc_seg: 82.1199  aux.loss_ce: 0.2522  aux.acc_seg: 73.0750
2024/10/28 03:41:13 - mmengine - INFO - Iter(train) [32950/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:35:15  time: 1.6031  data_time: 0.0101  memory: 6599  grad_norm: 7.3685  loss: 0.5840  decode.loss_ce: 0.3980  decode.acc_seg: 87.3538  aux.loss_ce: 0.1860  aux.acc_seg: 85.6821
2024/10/28 03:42:33 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 03:42:33 - mmengine - INFO - Iter(train) [33000/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:33:40  time: 1.6022  data_time: 0.0099  memory: 6600  grad_norm: 6.8664  loss: 0.6923  decode.loss_ce: 0.4676  decode.acc_seg: 82.7103  aux.loss_ce: 0.2247  aux.acc_seg: 82.5097
2024/10/28 03:43:53 - mmengine - INFO - Iter(train) [33050/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:32:05  time: 1.6013  data_time: 0.0102  memory: 6599  grad_norm: 6.0613  loss: 0.6307  decode.loss_ce: 0.4157  decode.acc_seg: 85.9172  aux.loss_ce: 0.2151  aux.acc_seg: 83.0666
2024/10/28 03:45:13 - mmengine - INFO - Iter(train) [33100/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:30:30  time: 1.6009  data_time: 0.0104  memory: 6600  grad_norm: 8.7735  loss: 0.7054  decode.loss_ce: 0.4686  decode.acc_seg: 87.4109  aux.loss_ce: 0.2368  aux.acc_seg: 83.4714
2024/10/28 03:46:34 - mmengine - INFO - Iter(train) [33150/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:28:59  time: 1.6160  data_time: 0.0101  memory: 6598  grad_norm: 5.4523  loss: 0.6012  decode.loss_ce: 0.4162  decode.acc_seg: 77.3982  aux.loss_ce: 0.1851  aux.acc_seg: 75.7885
2024/10/28 03:47:55 - mmengine - INFO - Iter(train) [33200/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:27:28  time: 1.6155  data_time: 0.0098  memory: 6599  grad_norm: 4.8096  loss: 0.5813  decode.loss_ce: 0.3996  decode.acc_seg: 84.7091  aux.loss_ce: 0.1817  aux.acc_seg: 78.1821
2024/10/28 03:49:16 - mmengine - INFO - Iter(train) [33250/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:25:58  time: 1.6160  data_time: 0.0104  memory: 6599  grad_norm: 7.4017  loss: 0.6287  decode.loss_ce: 0.4267  decode.acc_seg: 78.2353  aux.loss_ce: 0.2020  aux.acc_seg: 77.5259
2024/10/28 03:50:37 - mmengine - INFO - Iter(train) [33300/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:24:27  time: 1.6162  data_time: 0.0097  memory: 6601  grad_norm: 5.7291  loss: 0.7983  decode.loss_ce: 0.5343  decode.acc_seg: 76.6757  aux.loss_ce: 0.2639  aux.acc_seg: 78.8882
2024/10/28 03:51:58 - mmengine - INFO - Iter(train) [33350/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:22:56  time: 1.6136  data_time: 0.0096  memory: 6599  grad_norm: 6.4039  loss: 0.5946  decode.loss_ce: 0.4177  decode.acc_seg: 86.5495  aux.loss_ce: 0.1770  aux.acc_seg: 86.1404
2024/10/28 03:53:19 - mmengine - INFO - Iter(train) [33400/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:21:25  time: 1.6139  data_time: 0.0096  memory: 6599  grad_norm: 5.4569  loss: 0.6921  decode.loss_ce: 0.4792  decode.acc_seg: 84.6642  aux.loss_ce: 0.2128  aux.acc_seg: 86.3989
2024/10/28 03:54:39 - mmengine - INFO - Iter(train) [33450/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:19:53  time: 1.6140  data_time: 0.0099  memory: 6599  grad_norm: 6.3482  loss: 0.7432  decode.loss_ce: 0.5126  decode.acc_seg: 70.2243  aux.loss_ce: 0.2307  aux.acc_seg: 71.4621
2024/10/28 03:56:00 - mmengine - INFO - Iter(train) [33500/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:18:23  time: 1.6136  data_time: 0.0095  memory: 6598  grad_norm: 4.8937  loss: 0.5636  decode.loss_ce: 0.3830  decode.acc_seg: 79.9958  aux.loss_ce: 0.1806  aux.acc_seg: 84.7369
2024/10/28 03:57:21 - mmengine - INFO - Iter(train) [33550/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:16:53  time: 1.6141  data_time: 0.0097  memory: 6602  grad_norm: 6.2710  loss: 0.6657  decode.loss_ce: 0.4443  decode.acc_seg: 87.9578  aux.loss_ce: 0.2214  aux.acc_seg: 84.4839
2024/10/28 03:58:42 - mmengine - INFO - Iter(train) [33600/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:15:22  time: 1.6151  data_time: 0.0096  memory: 6598  grad_norm: 6.1521  loss: 0.5991  decode.loss_ce: 0.4087  decode.acc_seg: 82.7575  aux.loss_ce: 0.1904  aux.acc_seg: 78.4990
2024/10/28 04:00:03 - mmengine - INFO - Iter(train) [33650/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:13:52  time: 1.6104  data_time: 0.0093  memory: 6598  grad_norm: 6.7437  loss: 0.7261  decode.loss_ce: 0.4964  decode.acc_seg: 76.8434  aux.loss_ce: 0.2298  aux.acc_seg: 77.6327
2024/10/28 04:01:27 - mmengine - INFO - Iter(train) [33700/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:12:38  time: 1.6130  data_time: 0.0094  memory: 6600  grad_norm: 5.6375  loss: 0.5945  decode.loss_ce: 0.4060  decode.acc_seg: 82.9504  aux.loss_ce: 0.1885  aux.acc_seg: 82.4431
2024/10/28 04:02:47 - mmengine - INFO - Iter(train) [33750/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:11:06  time: 1.6116  data_time: 0.0100  memory: 6599  grad_norm: 6.2984  loss: 0.6123  decode.loss_ce: 0.4088  decode.acc_seg: 82.1714  aux.loss_ce: 0.2035  aux.acc_seg: 80.5203
2024/10/28 04:04:08 - mmengine - INFO - Iter(train) [33800/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:09:35  time: 1.6007  data_time: 0.0104  memory: 6600  grad_norm: 6.2978  loss: 0.7702  decode.loss_ce: 0.5253  decode.acc_seg: 88.7444  aux.loss_ce: 0.2449  aux.acc_seg: 86.1008
2024/10/28 04:05:29 - mmengine - INFO - Iter(train) [33850/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:08:04  time: 1.6137  data_time: 0.0101  memory: 6598  grad_norm: 5.8832  loss: 0.6743  decode.loss_ce: 0.4583  decode.acc_seg: 81.9872  aux.loss_ce: 0.2159  aux.acc_seg: 64.8325
2024/10/28 04:06:49 - mmengine - INFO - Iter(train) [33900/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:06:34  time: 1.6116  data_time: 0.0098  memory: 6600  grad_norm: 4.1786  loss: 0.6338  decode.loss_ce: 0.4395  decode.acc_seg: 89.2769  aux.loss_ce: 0.1942  aux.acc_seg: 90.5614
2024/10/28 04:08:10 - mmengine - INFO - Iter(train) [33950/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:05:04  time: 1.6105  data_time: 0.0099  memory: 6600  grad_norm: 5.8269  loss: 0.6034  decode.loss_ce: 0.4145  decode.acc_seg: 84.1620  aux.loss_ce: 0.1890  aux.acc_seg: 81.4874
2024/10/28 04:09:31 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 04:09:31 - mmengine - INFO - Iter(train) [34000/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:03:33  time: 1.6141  data_time: 0.0102  memory: 6599  grad_norm: 5.9337  loss: 0.7459  decode.loss_ce: 0.5053  decode.acc_seg: 79.8325  aux.loss_ce: 0.2406  aux.acc_seg: 79.9710
2024/10/28 04:10:52 - mmengine - INFO - Iter(train) [34050/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:02:03  time: 1.6118  data_time: 0.0101  memory: 6599  grad_norm: 8.8999  loss: 0.6191  decode.loss_ce: 0.4216  decode.acc_seg: 68.6068  aux.loss_ce: 0.1975  aux.acc_seg: 64.7340
2024/10/28 04:12:12 - mmengine - INFO - Iter(train) [34100/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 21:00:34  time: 1.6136  data_time: 0.0099  memory: 6600  grad_norm: 4.9450  loss: 0.6578  decode.loss_ce: 0.4534  decode.acc_seg: 77.2870  aux.loss_ce: 0.2044  aux.acc_seg: 77.1550
2024/10/28 04:13:33 - mmengine - INFO - Iter(train) [34150/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:59:05  time: 1.6388  data_time: 0.0098  memory: 6600  grad_norm: 6.0827  loss: 0.6323  decode.loss_ce: 0.4344  decode.acc_seg: 79.9406  aux.loss_ce: 0.1980  aux.acc_seg: 79.0788
2024/10/28 04:14:55 - mmengine - INFO - Iter(train) [34200/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:57:38  time: 1.6097  data_time: 0.0100  memory: 6598  grad_norm: 7.2343  loss: 0.6583  decode.loss_ce: 0.4406  decode.acc_seg: 83.5536  aux.loss_ce: 0.2176  aux.acc_seg: 86.3962
2024/10/28 04:16:16 - mmengine - INFO - Iter(train) [34250/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:56:09  time: 1.6375  data_time: 0.0100  memory: 6599  grad_norm: 6.5917  loss: 0.5633  decode.loss_ce: 0.3745  decode.acc_seg: 81.2098  aux.loss_ce: 0.1888  aux.acc_seg: 81.3855
2024/10/28 04:17:37 - mmengine - INFO - Iter(train) [34300/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:54:40  time: 1.6092  data_time: 0.0099  memory: 6598  grad_norm: 7.5042  loss: 0.6281  decode.loss_ce: 0.4232  decode.acc_seg: 81.9597  aux.loss_ce: 0.2049  aux.acc_seg: 79.1878
2024/10/28 04:18:57 - mmengine - INFO - Iter(train) [34350/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:53:10  time: 1.6108  data_time: 0.0102  memory: 6600  grad_norm: 8.8849  loss: 0.6287  decode.loss_ce: 0.4173  decode.acc_seg: 83.3803  aux.loss_ce: 0.2113  aux.acc_seg: 76.0726
2024/10/28 04:20:18 - mmengine - INFO - Iter(train) [34400/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:51:40  time: 1.6130  data_time: 0.0103  memory: 6600  grad_norm: 5.6698  loss: 0.6168  decode.loss_ce: 0.4158  decode.acc_seg: 85.1228  aux.loss_ce: 0.2010  aux.acc_seg: 80.0415
2024/10/28 04:21:38 - mmengine - INFO - Iter(train) [34450/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:50:10  time: 1.6142  data_time: 0.0104  memory: 6600  grad_norm: 6.8916  loss: 0.5873  decode.loss_ce: 0.3995  decode.acc_seg: 87.4764  aux.loss_ce: 0.1878  aux.acc_seg: 84.3136
2024/10/28 04:22:59 - mmengine - INFO - Iter(train) [34500/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:48:41  time: 1.6155  data_time: 0.0101  memory: 6602  grad_norm: 7.6741  loss: 0.6975  decode.loss_ce: 0.4784  decode.acc_seg: 81.7472  aux.loss_ce: 0.2191  aux.acc_seg: 78.8023
2024/10/28 04:24:20 - mmengine - INFO - Iter(train) [34550/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:47:14  time: 1.6109  data_time: 0.0113  memory: 6599  grad_norm: 6.4803  loss: 0.5989  decode.loss_ce: 0.4040  decode.acc_seg: 84.3183  aux.loss_ce: 0.1948  aux.acc_seg: 84.9181
2024/10/28 04:25:41 - mmengine - INFO - Iter(train) [34600/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:45:44  time: 1.6130  data_time: 0.0105  memory: 6598  grad_norm: 6.3444  loss: 0.7463  decode.loss_ce: 0.5091  decode.acc_seg: 87.2070  aux.loss_ce: 0.2372  aux.acc_seg: 87.2409
2024/10/28 04:27:02 - mmengine - INFO - Iter(train) [34650/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:44:15  time: 1.6108  data_time: 0.0106  memory: 6598  grad_norm: 6.6091  loss: 0.6348  decode.loss_ce: 0.4405  decode.acc_seg: 80.8286  aux.loss_ce: 0.1943  aux.acc_seg: 79.6414
2024/10/28 04:28:26 - mmengine - INFO - Iter(train) [34700/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:43:01  time: 1.6161  data_time: 0.0106  memory: 6600  grad_norm: 6.1235  loss: 0.6536  decode.loss_ce: 0.4481  decode.acc_seg: 78.9415  aux.loss_ce: 0.2055  aux.acc_seg: 78.9987
2024/10/28 04:29:47 - mmengine - INFO - Iter(train) [34750/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:41:33  time: 1.6121  data_time: 0.0105  memory: 6598  grad_norm: 5.3655  loss: 0.7415  decode.loss_ce: 0.5010  decode.acc_seg: 76.7897  aux.loss_ce: 0.2405  aux.acc_seg: 76.9852
2024/10/28 04:31:08 - mmengine - INFO - Iter(train) [34800/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:40:03  time: 1.6139  data_time: 0.0106  memory: 6599  grad_norm: 6.7238  loss: 0.7339  decode.loss_ce: 0.5016  decode.acc_seg: 85.4389  aux.loss_ce: 0.2323  aux.acc_seg: 85.6051
2024/10/28 04:32:28 - mmengine - INFO - Iter(train) [34850/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:38:34  time: 1.6108  data_time: 0.0106  memory: 6599  grad_norm: 5.8610  loss: 0.7150  decode.loss_ce: 0.4795  decode.acc_seg: 81.1241  aux.loss_ce: 0.2355  aux.acc_seg: 76.6318
2024/10/28 04:33:49 - mmengine - INFO - Iter(train) [34900/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:37:06  time: 1.6117  data_time: 0.0103  memory: 6599  grad_norm: 7.3741  loss: 0.6627  decode.loss_ce: 0.4620  decode.acc_seg: 85.2817  aux.loss_ce: 0.2007  aux.acc_seg: 83.5910
2024/10/28 04:35:10 - mmengine - INFO - Iter(train) [34950/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:35:38  time: 1.6147  data_time: 0.0109  memory: 6599  grad_norm: 9.4591  loss: 0.5829  decode.loss_ce: 0.4018  decode.acc_seg: 83.6267  aux.loss_ce: 0.1811  aux.acc_seg: 82.8666
2024/10/28 04:36:31 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 04:36:31 - mmengine - INFO - Iter(train) [35000/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:34:09  time: 1.6078  data_time: 0.0108  memory: 6599  grad_norm: 7.0117  loss: 0.6901  decode.loss_ce: 0.4672  decode.acc_seg: 79.8746  aux.loss_ce: 0.2229  aux.acc_seg: 82.1523
2024/10/28 04:37:51 - mmengine - INFO - Iter(train) [35050/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:32:41  time: 1.6140  data_time: 0.0104  memory: 6600  grad_norm: 7.2371  loss: 0.5994  decode.loss_ce: 0.4051  decode.acc_seg: 83.1442  aux.loss_ce: 0.1943  aux.acc_seg: 81.0628
2024/10/28 04:39:12 - mmengine - INFO - Iter(train) [35100/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:31:12  time: 1.6114  data_time: 0.0108  memory: 6599  grad_norm: 6.2345  loss: 0.6037  decode.loss_ce: 0.4204  decode.acc_seg: 89.3043  aux.loss_ce: 0.1833  aux.acc_seg: 89.1266
2024/10/28 04:40:33 - mmengine - INFO - Iter(train) [35150/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:29:42  time: 1.6103  data_time: 0.0105  memory: 6599  grad_norm: 7.0640  loss: 0.7462  decode.loss_ce: 0.5149  decode.acc_seg: 83.5350  aux.loss_ce: 0.2314  aux.acc_seg: 83.7870
2024/10/28 04:41:53 - mmengine - INFO - Iter(train) [35200/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:28:14  time: 1.6135  data_time: 0.0108  memory: 6600  grad_norm: 5.0051  loss: 0.6412  decode.loss_ce: 0.4432  decode.acc_seg: 87.0933  aux.loss_ce: 0.1980  aux.acc_seg: 85.0013
2024/10/28 04:43:15 - mmengine - INFO - Iter(train) [35250/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:26:48  time: 1.6158  data_time: 0.0105  memory: 6600  grad_norm: 5.9630  loss: 0.6227  decode.loss_ce: 0.4234  decode.acc_seg: 79.5528  aux.loss_ce: 0.1993  aux.acc_seg: 73.8254
2024/10/28 04:44:35 - mmengine - INFO - Iter(train) [35300/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:25:21  time: 1.6196  data_time: 0.0107  memory: 6602  grad_norm: 5.3451  loss: 0.6759  decode.loss_ce: 0.4631  decode.acc_seg: 84.6644  aux.loss_ce: 0.2129  aux.acc_seg: 84.4528
2024/10/28 04:45:57 - mmengine - INFO - Iter(train) [35350/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:23:54  time: 1.6171  data_time: 0.0103  memory: 6598  grad_norm: 5.4731  loss: 0.6638  decode.loss_ce: 0.4496  decode.acc_seg: 83.2326  aux.loss_ce: 0.2142  aux.acc_seg: 81.1448
2024/10/28 04:47:18 - mmengine - INFO - Iter(train) [35400/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:22:27  time: 1.6152  data_time: 0.0104  memory: 6600  grad_norm: 7.1116  loss: 0.7553  decode.loss_ce: 0.4987  decode.acc_seg: 76.4467  aux.loss_ce: 0.2566  aux.acc_seg: 75.3902
2024/10/28 04:48:38 - mmengine - INFO - Iter(train) [35450/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:20:59  time: 1.6094  data_time: 0.0102  memory: 6598  grad_norm: 6.6646  loss: 0.6505  decode.loss_ce: 0.4315  decode.acc_seg: 83.7184  aux.loss_ce: 0.2190  aux.acc_seg: 80.3335
2024/10/28 04:49:59 - mmengine - INFO - Iter(train) [35500/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:19:31  time: 1.6218  data_time: 0.0103  memory: 6599  grad_norm: 8.6347  loss: 0.6585  decode.loss_ce: 0.4417  decode.acc_seg: 86.1842  aux.loss_ce: 0.2167  aux.acc_seg: 83.9361
2024/10/28 04:51:20 - mmengine - INFO - Iter(train) [35550/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:18:03  time: 1.6177  data_time: 0.0106  memory: 6598  grad_norm: 6.0555  loss: 0.6370  decode.loss_ce: 0.4288  decode.acc_seg: 82.9346  aux.loss_ce: 0.2082  aux.acc_seg: 79.1300
2024/10/28 04:52:41 - mmengine - INFO - Iter(train) [35600/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:16:35  time: 1.6154  data_time: 0.0103  memory: 6598  grad_norm: 5.3932  loss: 0.5952  decode.loss_ce: 0.4014  decode.acc_seg: 80.1845  aux.loss_ce: 0.1939  aux.acc_seg: 73.2853
2024/10/28 04:54:01 - mmengine - INFO - Iter(train) [35650/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:15:07  time: 1.6122  data_time: 0.0101  memory: 6598  grad_norm: 6.7871  loss: 0.6171  decode.loss_ce: 0.4156  decode.acc_seg: 85.2412  aux.loss_ce: 0.2014  aux.acc_seg: 82.0651
2024/10/28 04:55:27 - mmengine - INFO - Iter(train) [35700/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:13:57  time: 1.6136  data_time: 0.0100  memory: 6599  grad_norm: 5.8441  loss: 0.5115  decode.loss_ce: 0.3538  decode.acc_seg: 77.4212  aux.loss_ce: 0.1577  aux.acc_seg: 76.4130
2024/10/28 04:56:48 - mmengine - INFO - Iter(train) [35750/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:12:30  time: 1.6142  data_time: 0.0106  memory: 6600  grad_norm: 6.1595  loss: 0.6386  decode.loss_ce: 0.4336  decode.acc_seg: 81.0122  aux.loss_ce: 0.2050  aux.acc_seg: 78.8710
2024/10/28 04:58:08 - mmengine - INFO - Iter(train) [35800/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:11:03  time: 1.6141  data_time: 0.0102  memory: 6599  grad_norm: 6.6228  loss: 0.7197  decode.loss_ce: 0.5029  decode.acc_seg: 83.0522  aux.loss_ce: 0.2168  aux.acc_seg: 82.9220
2024/10/28 04:59:29 - mmengine - INFO - Iter(train) [35850/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:09:35  time: 1.6140  data_time: 0.0107  memory: 6599  grad_norm: 9.2611  loss: 0.6457  decode.loss_ce: 0.4417  decode.acc_seg: 88.3138  aux.loss_ce: 0.2040  aux.acc_seg: 88.2462
2024/10/28 05:00:50 - mmengine - INFO - Iter(train) [35900/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:08:07  time: 1.6133  data_time: 0.0100  memory: 6600  grad_norm: 6.7655  loss: 0.6163  decode.loss_ce: 0.4202  decode.acc_seg: 85.1337  aux.loss_ce: 0.1960  aux.acc_seg: 83.3585
2024/10/28 05:02:11 - mmengine - INFO - Iter(train) [35950/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:06:39  time: 1.6119  data_time: 0.0107  memory: 6600  grad_norm: 9.1992  loss: 0.6374  decode.loss_ce: 0.4306  decode.acc_seg: 86.0288  aux.loss_ce: 0.2067  aux.acc_seg: 79.5746
2024/10/28 05:03:31 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 05:03:31 - mmengine - INFO - Iter(train) [36000/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:05:13  time: 1.6123  data_time: 0.0102  memory: 6599  grad_norm: 6.9866  loss: 0.6117  decode.loss_ce: 0.4171  decode.acc_seg: 78.8612  aux.loss_ce: 0.1947  aux.acc_seg: 75.8336
2024/10/28 05:04:52 - mmengine - INFO - Iter(train) [36050/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:03:46  time: 1.6131  data_time: 0.0106  memory: 6598  grad_norm: 6.8261  loss: 0.5460  decode.loss_ce: 0.3804  decode.acc_seg: 88.5110  aux.loss_ce: 0.1656  aux.acc_seg: 90.0148
2024/10/28 05:06:13 - mmengine - INFO - Iter(train) [36100/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:02:18  time: 1.6162  data_time: 0.0102  memory: 6599  grad_norm: 8.0462  loss: 0.7872  decode.loss_ce: 0.5395  decode.acc_seg: 76.8422  aux.loss_ce: 0.2477  aux.acc_seg: 74.8026
2024/10/28 05:07:34 - mmengine - INFO - Iter(train) [36150/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 20:00:51  time: 1.6106  data_time: 0.0105  memory: 6600  grad_norm: 6.7881  loss: 0.6625  decode.loss_ce: 0.4439  decode.acc_seg: 83.5400  aux.loss_ce: 0.2186  aux.acc_seg: 74.2811
2024/10/28 05:08:55 - mmengine - INFO - Iter(train) [36200/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:59:25  time: 1.6134  data_time: 0.0105  memory: 6600  grad_norm: 6.3991  loss: 0.5893  decode.loss_ce: 0.4037  decode.acc_seg: 84.5204  aux.loss_ce: 0.1857  aux.acc_seg: 84.2038
2024/10/28 05:10:15 - mmengine - INFO - Iter(train) [36250/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:57:57  time: 1.6130  data_time: 0.0105  memory: 6599  grad_norm: 5.9830  loss: 0.5501  decode.loss_ce: 0.3857  decode.acc_seg: 89.7419  aux.loss_ce: 0.1644  aux.acc_seg: 88.1801
2024/10/28 05:11:36 - mmengine - INFO - Iter(train) [36300/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:56:30  time: 1.6152  data_time: 0.0107  memory: 6599  grad_norm: 4.9089  loss: 0.6251  decode.loss_ce: 0.4329  decode.acc_seg: 87.1360  aux.loss_ce: 0.1922  aux.acc_seg: 85.2020
2024/10/28 05:12:57 - mmengine - INFO - Iter(train) [36350/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:55:03  time: 1.6115  data_time: 0.0105  memory: 6600  grad_norm: 6.1890  loss: 0.6366  decode.loss_ce: 0.4396  decode.acc_seg: 79.5732  aux.loss_ce: 0.1969  aux.acc_seg: 79.5306
2024/10/28 05:14:18 - mmengine - INFO - Iter(train) [36400/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:53:36  time: 1.6117  data_time: 0.0102  memory: 6600  grad_norm: 5.5020  loss: 0.6797  decode.loss_ce: 0.4543  decode.acc_seg: 81.8407  aux.loss_ce: 0.2253  aux.acc_seg: 71.0420
2024/10/28 05:15:38 - mmengine - INFO - Iter(train) [36450/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:52:09  time: 1.6131  data_time: 0.0106  memory: 6599  grad_norm: 6.9788  loss: 0.5531  decode.loss_ce: 0.3793  decode.acc_seg: 78.4555  aux.loss_ce: 0.1738  aux.acc_seg: 79.3615
2024/10/28 05:16:59 - mmengine - INFO - Iter(train) [36500/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:50:42  time: 1.6096  data_time: 0.0104  memory: 6600  grad_norm: 6.7569  loss: 0.6604  decode.loss_ce: 0.4511  decode.acc_seg: 85.3953  aux.loss_ce: 0.2092  aux.acc_seg: 80.6036
2024/10/28 05:18:20 - mmengine - INFO - Iter(train) [36550/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:49:15  time: 1.6124  data_time: 0.0107  memory: 6600  grad_norm: 8.3638  loss: 0.6209  decode.loss_ce: 0.4227  decode.acc_seg: 79.6379  aux.loss_ce: 0.1982  aux.acc_seg: 80.3781
2024/10/28 05:19:41 - mmengine - INFO - Iter(train) [36600/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:47:49  time: 1.6146  data_time: 0.0104  memory: 6598  grad_norm: 6.9415  loss: 0.6091  decode.loss_ce: 0.4183  decode.acc_seg: 85.0541  aux.loss_ce: 0.1908  aux.acc_seg: 87.6846
2024/10/28 05:21:02 - mmengine - INFO - Iter(train) [36650/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:46:23  time: 1.6148  data_time: 0.0104  memory: 6600  grad_norm: 6.5708  loss: 0.6868  decode.loss_ce: 0.4713  decode.acc_seg: 88.0329  aux.loss_ce: 0.2155  aux.acc_seg: 86.4730
2024/10/28 05:22:22 - mmengine - INFO - Iter(train) [36700/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:44:56  time: 1.6083  data_time: 0.0105  memory: 6599  grad_norm: 4.0822  loss: 0.5841  decode.loss_ce: 0.3941  decode.acc_seg: 84.1791  aux.loss_ce: 0.1899  aux.acc_seg: 81.2603
2024/10/28 05:23:43 - mmengine - INFO - Iter(train) [36750/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:43:29  time: 1.6144  data_time: 0.0096  memory: 6599  grad_norm: 7.2085  loss: 0.5953  decode.loss_ce: 0.4096  decode.acc_seg: 79.3716  aux.loss_ce: 0.1857  aux.acc_seg: 75.5091
2024/10/28 05:25:04 - mmengine - INFO - Iter(train) [36800/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:42:02  time: 1.6124  data_time: 0.0097  memory: 6599  grad_norm: 6.4743  loss: 0.5546  decode.loss_ce: 0.3827  decode.acc_seg: 82.5603  aux.loss_ce: 0.1718  aux.acc_seg: 78.8982
2024/10/28 05:26:27 - mmengine - INFO - Iter(train) [36850/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:40:42  time: 1.6099  data_time: 0.0095  memory: 6599  grad_norm: 6.6593  loss: 0.5890  decode.loss_ce: 0.4033  decode.acc_seg: 86.3914  aux.loss_ce: 0.1857  aux.acc_seg: 85.5450
2024/10/28 05:27:47 - mmengine - INFO - Iter(train) [36900/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:39:15  time: 1.6115  data_time: 0.0093  memory: 6598  grad_norm: 4.8437  loss: 0.6235  decode.loss_ce: 0.4267  decode.acc_seg: 83.9902  aux.loss_ce: 0.1968  aux.acc_seg: 82.8366
2024/10/28 05:29:08 - mmengine - INFO - Iter(train) [36950/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:37:48  time: 1.6113  data_time: 0.0113  memory: 6600  grad_norm: 8.6679  loss: 0.8027  decode.loss_ce: 0.5379  decode.acc_seg: 77.8859  aux.loss_ce: 0.2648  aux.acc_seg: 78.8378
2024/10/28 05:30:29 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 05:30:29 - mmengine - INFO - Iter(train) [37000/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:36:22  time: 1.6138  data_time: 0.0139  memory: 6599  grad_norm: 7.0995  loss: 0.6731  decode.loss_ce: 0.4516  decode.acc_seg: 89.4637  aux.loss_ce: 0.2215  aux.acc_seg: 80.5319
2024/10/28 05:31:50 - mmengine - INFO - Iter(train) [37050/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:34:56  time: 1.6130  data_time: 0.0139  memory: 6599  grad_norm: 6.9104  loss: 0.6516  decode.loss_ce: 0.4698  decode.acc_seg: 80.2823  aux.loss_ce: 0.1817  aux.acc_seg: 71.3723
2024/10/28 05:33:11 - mmengine - INFO - Iter(train) [37100/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:33:31  time: 1.6140  data_time: 0.0139  memory: 6599  grad_norm: 6.4753  loss: 0.7126  decode.loss_ce: 0.4891  decode.acc_seg: 88.5718  aux.loss_ce: 0.2235  aux.acc_seg: 89.2621
2024/10/28 05:34:31 - mmengine - INFO - Iter(train) [37150/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:32:04  time: 1.6126  data_time: 0.0138  memory: 6598  grad_norm: 8.7581  loss: 0.5457  decode.loss_ce: 0.3717  decode.acc_seg: 91.8305  aux.loss_ce: 0.1740  aux.acc_seg: 91.5985
2024/10/28 05:35:52 - mmengine - INFO - Iter(train) [37200/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:30:38  time: 1.6127  data_time: 0.0134  memory: 6600  grad_norm: 7.6461  loss: 0.5719  decode.loss_ce: 0.3812  decode.acc_seg: 84.5462  aux.loss_ce: 0.1907  aux.acc_seg: 84.0796
2024/10/28 05:37:13 - mmengine - INFO - Iter(train) [37250/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:29:13  time: 1.6168  data_time: 0.0145  memory: 6600  grad_norm: 5.3317  loss: 0.6078  decode.loss_ce: 0.4096  decode.acc_seg: 78.2903  aux.loss_ce: 0.1982  aux.acc_seg: 77.2288
2024/10/28 05:38:34 - mmengine - INFO - Iter(train) [37300/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:27:47  time: 1.6103  data_time: 0.0101  memory: 6598  grad_norm: 6.5273  loss: 0.6010  decode.loss_ce: 0.4201  decode.acc_seg: 86.3029  aux.loss_ce: 0.1809  aux.acc_seg: 85.1792
2024/10/28 05:39:55 - mmengine - INFO - Iter(train) [37350/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:26:21  time: 1.6135  data_time: 0.0100  memory: 6598  grad_norm: 5.5922  loss: 0.5609  decode.loss_ce: 0.3853  decode.acc_seg: 87.3028  aux.loss_ce: 0.1755  aux.acc_seg: 84.7840
2024/10/28 05:41:16 - mmengine - INFO - Iter(train) [37400/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:24:55  time: 1.6108  data_time: 0.0106  memory: 6599  grad_norm: 8.3122  loss: 0.6615  decode.loss_ce: 0.4555  decode.acc_seg: 79.8211  aux.loss_ce: 0.2060  aux.acc_seg: 72.1192
2024/10/28 05:42:37 - mmengine - INFO - Iter(train) [37450/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:23:31  time: 1.6126  data_time: 0.0103  memory: 6598  grad_norm: 6.8961  loss: 0.6527  decode.loss_ce: 0.4301  decode.acc_seg: 83.6012  aux.loss_ce: 0.2226  aux.acc_seg: 81.5197
2024/10/28 05:43:58 - mmengine - INFO - Iter(train) [37500/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:22:04  time: 1.6088  data_time: 0.0099  memory: 6600  grad_norm: 5.6254  loss: 0.6200  decode.loss_ce: 0.4218  decode.acc_seg: 77.6775  aux.loss_ce: 0.1982  aux.acc_seg: 69.7660
2024/10/28 05:45:18 - mmengine - INFO - Iter(train) [37550/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:20:38  time: 1.6122  data_time: 0.0101  memory: 6600  grad_norm: 5.7487  loss: 0.6111  decode.loss_ce: 0.4131  decode.acc_seg: 75.3147  aux.loss_ce: 0.1980  aux.acc_seg: 72.4487
2024/10/28 05:46:39 - mmengine - INFO - Iter(train) [37600/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:19:12  time: 1.6117  data_time: 0.0099  memory: 6600  grad_norm: 5.6717  loss: 0.7082  decode.loss_ce: 0.4821  decode.acc_seg: 81.9210  aux.loss_ce: 0.2261  aux.acc_seg: 79.5236
2024/10/28 05:48:00 - mmengine - INFO - Iter(train) [37650/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:17:46  time: 1.6123  data_time: 0.0100  memory: 6600  grad_norm: 9.2878  loss: 0.6345  decode.loss_ce: 0.4223  decode.acc_seg: 78.9770  aux.loss_ce: 0.2123  aux.acc_seg: 75.2001
2024/10/28 05:49:20 - mmengine - INFO - Iter(train) [37700/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:16:19  time: 1.6100  data_time: 0.0104  memory: 6598  grad_norm: 6.0663  loss: 0.6255  decode.loss_ce: 0.4338  decode.acc_seg: 89.0105  aux.loss_ce: 0.1917  aux.acc_seg: 90.5618
2024/10/28 05:50:41 - mmengine - INFO - Iter(train) [37750/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:14:53  time: 1.6119  data_time: 0.0099  memory: 6598  grad_norm: 7.3996  loss: 0.6307  decode.loss_ce: 0.4279  decode.acc_seg: 81.0070  aux.loss_ce: 0.2029  aux.acc_seg: 75.5093
2024/10/28 05:52:02 - mmengine - INFO - Iter(train) [37800/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:13:28  time: 1.6257  data_time: 0.0098  memory: 6599  grad_norm: 7.0340  loss: 0.6117  decode.loss_ce: 0.4255  decode.acc_seg: 84.1560  aux.loss_ce: 0.1862  aux.acc_seg: 84.5699
2024/10/28 05:53:27 - mmengine - INFO - Iter(train) [37850/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:12:15  time: 1.6115  data_time: 0.0094  memory: 6599  grad_norm: 7.2605  loss: 0.6127  decode.loss_ce: 0.4200  decode.acc_seg: 80.6106  aux.loss_ce: 0.1927  aux.acc_seg: 78.6753
2024/10/28 05:54:48 - mmengine - INFO - Iter(train) [37900/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:10:49  time: 1.6095  data_time: 0.0098  memory: 6601  grad_norm: 5.9900  loss: 0.6023  decode.loss_ce: 0.4091  decode.acc_seg: 88.3595  aux.loss_ce: 0.1932  aux.acc_seg: 89.6011
2024/10/28 05:56:08 - mmengine - INFO - Iter(train) [37950/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:09:23  time: 1.6120  data_time: 0.0100  memory: 6599  grad_norm: 7.7413  loss: 0.6106  decode.loss_ce: 0.4190  decode.acc_seg: 85.0563  aux.loss_ce: 0.1916  aux.acc_seg: 85.4653
2024/10/28 05:57:29 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 05:57:29 - mmengine - INFO - Iter(train) [38000/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:07:58  time: 1.6109  data_time: 0.0096  memory: 6600  grad_norm: 7.5026  loss: 0.5884  decode.loss_ce: 0.3991  decode.acc_seg: 82.9996  aux.loss_ce: 0.1893  aux.acc_seg: 82.8331
2024/10/28 05:58:50 - mmengine - INFO - Iter(train) [38050/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:06:32  time: 1.6138  data_time: 0.0101  memory: 6598  grad_norm: 5.4468  loss: 0.5278  decode.loss_ce: 0.3588  decode.acc_seg: 89.1125  aux.loss_ce: 0.1691  aux.acc_seg: 87.6828
2024/10/28 06:00:11 - mmengine - INFO - Iter(train) [38100/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:05:07  time: 1.6136  data_time: 0.0099  memory: 6598  grad_norm: 5.0596  loss: 0.5548  decode.loss_ce: 0.3766  decode.acc_seg: 84.1099  aux.loss_ce: 0.1782  aux.acc_seg: 82.6137
2024/10/28 06:01:32 - mmengine - INFO - Iter(train) [38150/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:03:42  time: 1.6126  data_time: 0.0099  memory: 6600  grad_norm: 6.7785  loss: 0.6358  decode.loss_ce: 0.4301  decode.acc_seg: 82.9069  aux.loss_ce: 0.2057  aux.acc_seg: 80.6364
2024/10/28 06:02:53 - mmengine - INFO - Iter(train) [38200/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:02:16  time: 1.6122  data_time: 0.0099  memory: 6600  grad_norm: 6.1558  loss: 0.6417  decode.loss_ce: 0.4350  decode.acc_seg: 73.1773  aux.loss_ce: 0.2068  aux.acc_seg: 71.0804
2024/10/28 06:04:13 - mmengine - INFO - Iter(train) [38250/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 19:00:50  time: 1.6120  data_time: 0.0102  memory: 6599  grad_norm: 6.5770  loss: 0.5916  decode.loss_ce: 0.4071  decode.acc_seg: 82.4493  aux.loss_ce: 0.1845  aux.acc_seg: 79.3573
2024/10/28 06:05:34 - mmengine - INFO - Iter(train) [38300/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:59:25  time: 1.6097  data_time: 0.0100  memory: 6599  grad_norm: 8.3845  loss: 0.6546  decode.loss_ce: 0.4533  decode.acc_seg: 84.0117  aux.loss_ce: 0.2013  aux.acc_seg: 83.7657
2024/10/28 06:06:55 - mmengine - INFO - Iter(train) [38350/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:57:59  time: 1.6112  data_time: 0.0100  memory: 6599  grad_norm: 6.2164  loss: 0.5844  decode.loss_ce: 0.3994  decode.acc_seg: 88.8902  aux.loss_ce: 0.1851  aux.acc_seg: 88.2873
2024/10/28 06:08:16 - mmengine - INFO - Iter(train) [38400/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:56:34  time: 1.6091  data_time: 0.0099  memory: 6600  grad_norm: 8.2108  loss: 0.5982  decode.loss_ce: 0.4037  decode.acc_seg: 81.8130  aux.loss_ce: 0.1945  aux.acc_seg: 80.5552
2024/10/28 06:09:37 - mmengine - INFO - Iter(train) [38450/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:55:09  time: 1.6388  data_time: 0.0101  memory: 6598  grad_norm: 7.4585  loss: 0.5448  decode.loss_ce: 0.3640  decode.acc_seg: 86.6201  aux.loss_ce: 0.1808  aux.acc_seg: 84.6459
2024/10/28 06:10:57 - mmengine - INFO - Iter(train) [38500/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:53:44  time: 1.6166  data_time: 0.0106  memory: 6598  grad_norm: 7.3412  loss: 0.7173  decode.loss_ce: 0.4690  decode.acc_seg: 82.2209  aux.loss_ce: 0.2483  aux.acc_seg: 79.2641
2024/10/28 06:12:18 - mmengine - INFO - Iter(train) [38550/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:52:18  time: 1.6168  data_time: 0.0109  memory: 6600  grad_norm: 7.2108  loss: 0.6782  decode.loss_ce: 0.4610  decode.acc_seg: 82.9439  aux.loss_ce: 0.2172  aux.acc_seg: 82.3878
2024/10/28 06:13:39 - mmengine - INFO - Iter(train) [38600/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:50:54  time: 1.6359  data_time: 0.0104  memory: 6599  grad_norm: 8.1660  loss: 0.6582  decode.loss_ce: 0.4527  decode.acc_seg: 85.8513  aux.loss_ce: 0.2054  aux.acc_seg: 79.8981
2024/10/28 06:15:00 - mmengine - INFO - Iter(train) [38650/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:49:28  time: 1.6130  data_time: 0.0107  memory: 6599  grad_norm: 4.9940  loss: 0.5856  decode.loss_ce: 0.3978  decode.acc_seg: 84.4343  aux.loss_ce: 0.1878  aux.acc_seg: 84.2755
2024/10/28 06:16:21 - mmengine - INFO - Iter(train) [38700/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:48:04  time: 1.6126  data_time: 0.0106  memory: 6600  grad_norm: 6.4343  loss: 0.5531  decode.loss_ce: 0.3769  decode.acc_seg: 82.2189  aux.loss_ce: 0.1763  aux.acc_seg: 84.3262
2024/10/28 06:17:42 - mmengine - INFO - Iter(train) [38750/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:46:40  time: 1.6156  data_time: 0.0108  memory: 6600  grad_norm: 5.7023  loss: 0.6186  decode.loss_ce: 0.4217  decode.acc_seg: 85.7975  aux.loss_ce: 0.1969  aux.acc_seg: 84.6868
2024/10/28 06:19:03 - mmengine - INFO - Iter(train) [38800/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:45:15  time: 1.6117  data_time: 0.0108  memory: 6598  grad_norm: 6.8791  loss: 0.7063  decode.loss_ce: 0.4773  decode.acc_seg: 90.7335  aux.loss_ce: 0.2290  aux.acc_seg: 90.7113
2024/10/28 06:20:26 - mmengine - INFO - Iter(train) [38850/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:43:55  time: 1.6108  data_time: 0.0110  memory: 6599  grad_norm: 8.3504  loss: 0.5817  decode.loss_ce: 0.4047  decode.acc_seg: 81.4296  aux.loss_ce: 0.1771  aux.acc_seg: 79.6915
2024/10/28 06:21:46 - mmengine - INFO - Iter(train) [38900/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:42:29  time: 1.6084  data_time: 0.0107  memory: 6598  grad_norm: 6.8408  loss: 0.5238  decode.loss_ce: 0.3627  decode.acc_seg: 87.6897  aux.loss_ce: 0.1611  aux.acc_seg: 85.1456
2024/10/28 06:23:07 - mmengine - INFO - Iter(train) [38950/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:41:03  time: 1.6092  data_time: 0.0112  memory: 6600  grad_norm: 6.1467  loss: 0.5860  decode.loss_ce: 0.4005  decode.acc_seg: 85.3809  aux.loss_ce: 0.1855  aux.acc_seg: 84.9860
2024/10/28 06:24:27 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 06:24:27 - mmengine - INFO - Iter(train) [39000/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:39:37  time: 1.6107  data_time: 0.0109  memory: 6599  grad_norm: 7.1879  loss: 0.6136  decode.loss_ce: 0.4114  decode.acc_seg: 84.5653  aux.loss_ce: 0.2021  aux.acc_seg: 85.4364
2024/10/28 06:25:48 - mmengine - INFO - Iter(train) [39050/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:38:13  time: 1.6427  data_time: 0.0143  memory: 6600  grad_norm: 6.4957  loss: 0.7397  decode.loss_ce: 0.5064  decode.acc_seg: 85.8073  aux.loss_ce: 0.2333  aux.acc_seg: 84.2823
2024/10/28 06:27:09 - mmengine - INFO - Iter(train) [39100/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:36:49  time: 1.6115  data_time: 0.0139  memory: 6600  grad_norm: 6.0937  loss: 0.6436  decode.loss_ce: 0.4509  decode.acc_seg: 76.8956  aux.loss_ce: 0.1927  aux.acc_seg: 77.7367
2024/10/28 06:28:30 - mmengine - INFO - Iter(train) [39150/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:35:25  time: 1.6134  data_time: 0.0132  memory: 6599  grad_norm: 5.9049  loss: 0.6086  decode.loss_ce: 0.4117  decode.acc_seg: 90.4587  aux.loss_ce: 0.1969  aux.acc_seg: 87.6894
2024/10/28 06:29:51 - mmengine - INFO - Iter(train) [39200/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:34:00  time: 1.6115  data_time: 0.0137  memory: 6599  grad_norm: 5.7382  loss: 0.4961  decode.loss_ce: 0.3358  decode.acc_seg: 83.1770  aux.loss_ce: 0.1603  aux.acc_seg: 82.0981
2024/10/28 06:31:12 - mmengine - INFO - Iter(train) [39250/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:32:36  time: 1.6111  data_time: 0.0139  memory: 6598  grad_norm: 5.6422  loss: 0.5865  decode.loss_ce: 0.3881  decode.acc_seg: 87.4859  aux.loss_ce: 0.1984  aux.acc_seg: 87.2370
2024/10/28 06:32:33 - mmengine - INFO - Iter(train) [39300/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:31:12  time: 1.6134  data_time: 0.0104  memory: 6599  grad_norm: 5.7369  loss: 0.7211  decode.loss_ce: 0.4832  decode.acc_seg: 87.6763  aux.loss_ce: 0.2379  aux.acc_seg: 78.1665
2024/10/28 06:33:55 - mmengine - INFO - Iter(train) [39350/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:29:48  time: 1.6142  data_time: 0.0104  memory: 6600  grad_norm: 6.3167  loss: 0.6754  decode.loss_ce: 0.4702  decode.acc_seg: 85.1456  aux.loss_ce: 0.2052  aux.acc_seg: 87.8981
2024/10/28 06:35:15 - mmengine - INFO - Iter(train) [39400/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:28:23  time: 1.6133  data_time: 0.0101  memory: 6599  grad_norm: 7.1213  loss: 0.6782  decode.loss_ce: 0.4655  decode.acc_seg: 81.0871  aux.loss_ce: 0.2127  aux.acc_seg: 77.9477
2024/10/28 06:36:36 - mmengine - INFO - Iter(train) [39450/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:26:58  time: 1.6123  data_time: 0.0100  memory: 6599  grad_norm: 5.5288  loss: 0.5834  decode.loss_ce: 0.4004  decode.acc_seg: 89.7578  aux.loss_ce: 0.1830  aux.acc_seg: 85.2658
2024/10/28 06:37:57 - mmengine - INFO - Iter(train) [39500/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:25:33  time: 1.6143  data_time: 0.0102  memory: 6599  grad_norm: 6.8613  loss: 0.6732  decode.loss_ce: 0.4555  decode.acc_seg: 76.8867  aux.loss_ce: 0.2176  aux.acc_seg: 71.3093
2024/10/28 06:39:18 - mmengine - INFO - Iter(train) [39550/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:24:09  time: 1.6150  data_time: 0.0144  memory: 6598  grad_norm: 5.3504  loss: 0.6805  decode.loss_ce: 0.4578  decode.acc_seg: 84.0791  aux.loss_ce: 0.2227  aux.acc_seg: 80.7818
2024/10/28 06:40:39 - mmengine - INFO - Iter(train) [39600/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:22:44  time: 1.6178  data_time: 0.0146  memory: 6599  grad_norm: 6.1372  loss: 0.6569  decode.loss_ce: 0.4488  decode.acc_seg: 90.5251  aux.loss_ce: 0.2081  aux.acc_seg: 88.8146
2024/10/28 06:41:59 - mmengine - INFO - Iter(train) [39650/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:21:20  time: 1.6115  data_time: 0.0138  memory: 6600  grad_norm: 5.8182  loss: 0.5963  decode.loss_ce: 0.4047  decode.acc_seg: 87.8017  aux.loss_ce: 0.1917  aux.acc_seg: 82.5184
2024/10/28 06:43:20 - mmengine - INFO - Iter(train) [39700/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:19:55  time: 1.6338  data_time: 0.0135  memory: 6601  grad_norm: 6.5812  loss: 0.5845  decode.loss_ce: 0.4104  decode.acc_seg: 75.3702  aux.loss_ce: 0.1741  aux.acc_seg: 78.2483
2024/10/28 06:44:41 - mmengine - INFO - Iter(train) [39750/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:18:31  time: 1.6143  data_time: 0.0133  memory: 6599  grad_norm: 5.1142  loss: 0.5663  decode.loss_ce: 0.3824  decode.acc_seg: 86.3259  aux.loss_ce: 0.1840  aux.acc_seg: 85.1343
2024/10/28 06:46:02 - mmengine - INFO - Iter(train) [39800/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:17:06  time: 1.6138  data_time: 0.0130  memory: 6598  grad_norm: 4.3340  loss: 0.5853  decode.loss_ce: 0.3885  decode.acc_seg: 80.1394  aux.loss_ce: 0.1967  aux.acc_seg: 76.7254
2024/10/28 06:47:26 - mmengine - INFO - Iter(train) [39850/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:15:50  time: 1.6251  data_time: 0.0132  memory: 6599  grad_norm: 7.9854  loss: 0.6211  decode.loss_ce: 0.4197  decode.acc_seg: 88.3632  aux.loss_ce: 0.2014  aux.acc_seg: 87.4862
2024/10/28 06:48:47 - mmengine - INFO - Iter(train) [39900/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:14:26  time: 1.6122  data_time: 0.0130  memory: 6600  grad_norm: 7.1062  loss: 0.6122  decode.loss_ce: 0.4204  decode.acc_seg: 69.4653  aux.loss_ce: 0.1918  aux.acc_seg: 68.8413
2024/10/28 06:50:08 - mmengine - INFO - Iter(train) [39950/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:13:02  time: 1.6117  data_time: 0.0133  memory: 6599  grad_norm: 7.0426  loss: 0.6039  decode.loss_ce: 0.4031  decode.acc_seg: 84.6016  aux.loss_ce: 0.2008  aux.acc_seg: 82.6278
2024/10/28 06:51:29 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 06:51:29 - mmengine - INFO - Iter(train) [40000/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:11:37  time: 1.6116  data_time: 0.0133  memory: 6601  grad_norm: 4.7676  loss: 0.5933  decode.loss_ce: 0.4051  decode.acc_seg: 81.5220  aux.loss_ce: 0.1882  aux.acc_seg: 80.5626
2024/10/28 06:51:29 - mmengine - INFO - Saving checkpoint at 40000 iterations
2024/10/28 06:51:35 - mmengine - INFO - Iter(val) [ 50/500]    eta: 0:00:13  time: 0.0293  data_time: 0.0014  memory: 1007  
2024/10/28 06:51:37 - mmengine - INFO - Iter(val) [100/500]    eta: 0:00:11  time: 0.0289  data_time: 0.0013  memory: 1077  
2024/10/28 06:51:38 - mmengine - INFO - Iter(val) [150/500]    eta: 0:00:10  time: 0.0292  data_time: 0.0014  memory: 792  
2024/10/28 06:51:40 - mmengine - INFO - Iter(val) [200/500]    eta: 0:00:08  time: 0.0301  data_time: 0.0020  memory: 825  
2024/10/28 06:51:41 - mmengine - INFO - Iter(val) [250/500]    eta: 0:00:07  time: 0.0293  data_time: 0.0015  memory: 865  
2024/10/28 06:51:43 - mmengine - INFO - Iter(val) [300/500]    eta: 0:00:05  time: 0.0282  data_time: 0.0017  memory: 1988  
2024/10/28 06:51:44 - mmengine - INFO - Iter(val) [350/500]    eta: 0:00:04  time: 0.0293  data_time: 0.0014  memory: 791  
2024/10/28 06:51:46 - mmengine - INFO - Iter(val) [400/500]    eta: 0:00:02  time: 0.0294  data_time: 0.0014  memory: 863  
2024/10/28 06:51:47 - mmengine - INFO - Iter(val) [450/500]    eta: 0:00:01  time: 0.0292  data_time: 0.0013  memory: 798  
2024/10/28 06:51:48 - mmengine - INFO - Iter(val) [500/500]    eta: 0:00:00  time: 0.0287  data_time: 0.0013  memory: 847  
2024/10/28 06:51:51 - mmengine - INFO - per class results:
2024/10/28 06:51:51 - mmengine - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 65.38 | 82.02 |
|       building      | 75.25 | 89.56 |
|         sky         | 88.51 | 94.46 |
|        floor        | 70.03 |  84.7 |
|         tree        | 65.29 | 81.58 |
|       ceiling       | 75.74 | 87.09 |
|         road        | 76.92 | 82.89 |
|         bed         | 77.42 | 89.43 |
|      windowpane     | 51.28 | 66.41 |
|        grass        | 57.15 | 69.02 |
|       cabinet       | 48.79 | 64.17 |
|       sidewalk      | 55.48 | 75.74 |
|        person       |  59.9 | 75.19 |
|        earth        |  31.6 | 49.58 |
|         door        | 32.23 | 49.41 |
|        table        | 42.65 | 58.29 |
|       mountain      |  48.0 | 54.93 |
|        plant        | 40.04 | 50.65 |
|       curtain       | 54.72 | 70.53 |
|        chair        | 37.57 |  50.1 |
|         car         | 69.77 | 82.05 |
|        water        |  45.0 | 58.07 |
|       painting      | 47.82 | 60.36 |
|         sofa        |  52.7 | 65.88 |
|        shelf        | 32.18 | 52.95 |
|        house        |  24.0 |  29.2 |
|         sea         | 49.29 | 71.14 |
|        mirror       | 48.99 |  59.6 |
|         rug         |  48.4 | 61.37 |
|        field        | 22.74 | 45.21 |
|       armchair      | 33.55 | 51.37 |
|         seat        | 59.68 | 74.05 |
|        fence        | 27.78 | 36.44 |
|         desk        |  35.5 | 57.12 |
|         rock        | 36.55 | 66.18 |
|       wardrobe      | 41.55 | 61.55 |
|         lamp        | 30.85 | 39.58 |
|       bathtub       | 64.33 | 73.72 |
|       railing       | 23.31 | 30.41 |
|       cushion       | 31.81 | 46.21 |
|         base        | 14.58 | 26.81 |
|         box         | 10.09 | 15.16 |
|        column       | 19.87 | 26.82 |
|      signboard      | 18.16 | 24.45 |
|   chest of drawers  | 32.99 | 49.58 |
|       counter       |  19.4 |  27.2 |
|         sand        | 37.13 | 61.44 |
|         sink        | 43.67 | 54.03 |
|      skyscraper     | 49.98 | 62.03 |
|      fireplace      | 60.09 | 74.17 |
|     refrigerator    | 53.82 | 75.39 |
|      grandstand     | 26.18 | 66.33 |
|         path        | 18.47 | 32.73 |
|        stairs       | 23.54 | 41.87 |
|        runway       | 64.71 | 91.97 |
|         case        | 46.09 |  70.0 |
|      pool table     |  71.5 | 80.74 |
|        pillow       | 35.61 | 43.83 |
|     screen door     | 59.05 | 68.53 |
|       stairway      | 24.04 | 29.77 |
|        river        | 12.47 | 32.04 |
|        bridge       | 30.33 | 33.08 |
|       bookcase      | 25.03 |  36.2 |
|        blind        | 29.94 | 37.31 |
|     coffee table    | 48.08 |  69.4 |
|        toilet       | 51.18 | 72.52 |
|        flower       |  19.3 | 44.33 |
|         book        | 30.31 | 54.82 |
|         hill        |  4.21 | 10.26 |
|        bench        | 31.82 | 38.92 |
|      countertop     | 38.95 | 57.99 |
|        stove        | 43.79 | 47.09 |
|         palm        | 32.43 | 40.82 |
|    kitchen island   |  26.8 | 67.85 |
|       computer      | 37.36 | 43.36 |
|     swivel chair    | 35.94 | 52.24 |
|         boat        | 45.51 |  55.1 |
|         bar         | 30.07 | 37.63 |
|    arcade machine   | 41.96 | 60.38 |
|        hovel        |  3.66 |  4.48 |
|         bus         | 68.99 | 79.15 |
|        towel        | 28.94 | 37.59 |
|        light        |  6.84 |  7.25 |
|        truck        | 20.47 | 26.42 |
|        tower        | 34.79 | 66.41 |
|      chandelier     | 44.01 | 54.95 |
|        awning       | 11.55 | 13.96 |
|     streetlight     |  1.89 |  2.17 |
|        booth        | 37.61 | 39.71 |
| television receiver | 52.18 |  63.0 |
|       airplane      | 38.52 | 51.57 |
|      dirt track     | 15.35 |  32.4 |
|       apparel       | 16.22 | 21.89 |
|         pole        |  4.41 |  6.46 |
|         land        |  0.0  |  0.01 |
|      bannister      |  0.15 |  0.17 |
|      escalator      | 18.93 | 24.94 |
|       ottoman       | 22.52 | 46.04 |
|        bottle       | 15.81 | 33.54 |
|        buffet       | 49.15 | 55.05 |
|        poster       | 17.59 | 36.32 |
|        stage        | 14.44 | 21.13 |
|         van         | 30.83 | 40.68 |
|         ship        | 44.77 |  58.8 |
|       fountain      | 18.86 |  19.2 |
|    conveyer belt    | 48.85 | 86.82 |
|        canopy       |  6.38 | 10.04 |
|        washer       | 56.03 | 61.43 |
|      plaything      | 11.03 | 21.56 |
|    swimming pool    | 38.28 | 59.47 |
|        stool        | 20.99 | 33.23 |
|        barrel       | 12.47 | 81.57 |
|        basket       | 16.05 | 22.97 |
|      waterfall      | 29.08 | 35.17 |
|         tent        |  86.6 | 90.72 |
|         bag         |  3.81 |  4.56 |
|       minibike      | 43.29 | 55.41 |
|        cradle       |  55.4 | 72.59 |
|         oven        | 17.34 | 42.79 |
|         ball        | 27.94 | 32.14 |
|         food        | 28.54 | 32.89 |
|         step        |  6.22 |  7.09 |
|         tank        | 35.37 | 49.09 |
|      trade name     | 10.33 | 10.77 |
|      microwave      | 33.36 | 37.37 |
|         pot         | 19.34 | 21.81 |
|        animal       | 34.44 | 35.86 |
|       bicycle       |  33.0 | 46.54 |
|         lake        | 72.83 | 90.41 |
|      dishwasher     | 43.57 | 60.18 |
|        screen       | 48.92 | 73.46 |
|       blanket       |  5.08 |  5.58 |
|      sculpture      | 36.64 | 55.05 |
|         hood        | 36.36 | 43.94 |
|        sconce       | 13.76 | 15.77 |
|         vase        | 12.55 | 18.83 |
|    traffic light    | 12.93 | 16.37 |
|         tray        |  1.23 |  2.03 |
|        ashcan       | 18.29 | 23.98 |
|         fan         |  31.2 | 42.19 |
|         pier        | 16.21 | 19.07 |
|      crt screen     |  4.19 | 11.02 |
|        plate        | 20.89 | 28.12 |
|       monitor       |  4.89 |  5.03 |
|    bulletin board   |  31.2 | 42.35 |
|        shower       |  0.0  |  0.0  |
|       radiator      | 32.65 | 38.78 |
|        glass        |  0.88 |  0.93 |
|        clock        |  7.88 | 10.65 |
|         flag        | 20.42 | 22.71 |
+---------------------+-------+-------+
2024/10/28 06:51:51 - mmengine - INFO - Iter(val) [500/500]    aAcc: 74.6800  mIoU: 33.9300  mAcc: 45.8900  data_time: 0.0015  time: 0.0292
2024/10/28 06:53:12 - mmengine - INFO - Iter(train) [40050/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:10:19  time: 1.6134  data_time: 0.0137  memory: 6602  grad_norm: 5.8213  loss: 0.6804  decode.loss_ce: 0.4641  decode.acc_seg: 81.7630  aux.loss_ce: 0.2163  aux.acc_seg: 81.3684
2024/10/28 06:54:33 - mmengine - INFO - Iter(train) [40100/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:08:55  time: 1.6108  data_time: 0.0136  memory: 6599  grad_norm: 5.9342  loss: 0.5704  decode.loss_ce: 0.3875  decode.acc_seg: 81.0922  aux.loss_ce: 0.1829  aux.acc_seg: 78.0236
2024/10/28 06:55:54 - mmengine - INFO - Iter(train) [40150/80000]  base_lr: 1.2000e-04 lr: 1.2000e-04  eta: 18:07:30  time: 1.6133  data_time: 0.0137  memory: 6599  grad_norm: 5.6939  loss: 0.6804  decode.loss_ce: 0.4547  decode.acc_seg: 84.3629  aux.loss_ce: 0.2257  aux.acc_seg: 82.9721
2024/10/28 06:57:14 - mmengine - INFO - Iter(train) [40200/80000]  base_lr: 1.1999e-04 lr: 1.1999e-04  eta: 18:06:05  time: 1.6134  data_time: 0.0138  memory: 6598  grad_norm: 5.9350  loss: 0.6111  decode.loss_ce: 0.4225  decode.acc_seg: 89.8915  aux.loss_ce: 0.1886  aux.acc_seg: 90.1979
2024/10/28 06:58:35 - mmengine - INFO - Iter(train) [40250/80000]  base_lr: 1.1999e-04 lr: 1.1999e-04  eta: 18:04:41  time: 1.6166  data_time: 0.0133  memory: 6600  grad_norm: 4.8497  loss: 0.5768  decode.loss_ce: 0.3916  decode.acc_seg: 81.9562  aux.loss_ce: 0.1851  aux.acc_seg: 78.8466
2024/10/28 06:59:56 - mmengine - INFO - Iter(train) [40300/80000]  base_lr: 1.1998e-04 lr: 1.1998e-04  eta: 18:03:17  time: 1.6132  data_time: 0.0140  memory: 6600  grad_norm: 8.1267  loss: 0.6249  decode.loss_ce: 0.4277  decode.acc_seg: 84.1794  aux.loss_ce: 0.1973  aux.acc_seg: 84.3461
2024/10/28 07:01:17 - mmengine - INFO - Iter(train) [40350/80000]  base_lr: 1.1998e-04 lr: 1.1998e-04  eta: 18:01:53  time: 1.6148  data_time: 0.0139  memory: 6600  grad_norm: 6.0044  loss: 0.5391  decode.loss_ce: 0.3674  decode.acc_seg: 86.8506  aux.loss_ce: 0.1717  aux.acc_seg: 83.3252
2024/10/28 07:02:39 - mmengine - INFO - Iter(train) [40400/80000]  base_lr: 1.1997e-04 lr: 1.1997e-04  eta: 18:00:31  time: 1.6159  data_time: 0.0145  memory: 6600  grad_norm: 6.0704  loss: 0.5418  decode.loss_ce: 0.3656  decode.acc_seg: 82.0553  aux.loss_ce: 0.1762  aux.acc_seg: 82.1771
2024/10/28 07:04:00 - mmengine - INFO - Iter(train) [40450/80000]  base_lr: 1.1996e-04 lr: 1.1996e-04  eta: 17:59:07  time: 1.6111  data_time: 0.0137  memory: 6598  grad_norm: 7.2214  loss: 0.5773  decode.loss_ce: 0.3898  decode.acc_seg: 85.0940  aux.loss_ce: 0.1875  aux.acc_seg: 83.1121
2024/10/28 07:05:21 - mmengine - INFO - Iter(train) [40500/80000]  base_lr: 1.1995e-04 lr: 1.1995e-04  eta: 17:57:43  time: 1.6139  data_time: 0.0140  memory: 6600  grad_norm: 5.3646  loss: 0.5706  decode.loss_ce: 0.3931  decode.acc_seg: 86.3726  aux.loss_ce: 0.1775  aux.acc_seg: 86.5325
2024/10/28 07:06:42 - mmengine - INFO - Iter(train) [40550/80000]  base_lr: 1.1994e-04 lr: 1.1994e-04  eta: 17:56:18  time: 1.6122  data_time: 0.0142  memory: 6600  grad_norm: 8.0827  loss: 0.7168  decode.loss_ce: 0.4778  decode.acc_seg: 81.0977  aux.loss_ce: 0.2390  aux.acc_seg: 74.1666
2024/10/28 07:08:03 - mmengine - INFO - Iter(train) [40600/80000]  base_lr: 1.1993e-04 lr: 1.1993e-04  eta: 17:54:54  time: 1.6138  data_time: 0.0140  memory: 6599  grad_norm: 7.5970  loss: 0.5894  decode.loss_ce: 0.3966  decode.acc_seg: 86.6623  aux.loss_ce: 0.1929  aux.acc_seg: 86.4201
2024/10/28 07:09:26 - mmengine - INFO - Iter(train) [40650/80000]  base_lr: 1.1992e-04 lr: 1.1992e-04  eta: 17:53:37  time: 1.6124  data_time: 0.0143  memory: 6599  grad_norm: 9.1518  loss: 0.6789  decode.loss_ce: 0.4494  decode.acc_seg: 79.0883  aux.loss_ce: 0.2296  aux.acc_seg: 78.4026
2024/10/28 07:10:47 - mmengine - INFO - Iter(train) [40700/80000]  base_lr: 1.1991e-04 lr: 1.1991e-04  eta: 17:52:13  time: 1.6138  data_time: 0.0146  memory: 6600  grad_norm: 5.8401  loss: 0.6192  decode.loss_ce: 0.4198  decode.acc_seg: 86.2933  aux.loss_ce: 0.1994  aux.acc_seg: 87.2087
2024/10/28 07:12:08 - mmengine - INFO - Iter(train) [40750/80000]  base_lr: 1.1990e-04 lr: 1.1990e-04  eta: 17:50:48  time: 1.6123  data_time: 0.0141  memory: 6600  grad_norm: 7.3932  loss: 0.5958  decode.loss_ce: 0.4223  decode.acc_seg: 82.7272  aux.loss_ce: 0.1735  aux.acc_seg: 82.0109
2024/10/28 07:13:29 - mmengine - INFO - Iter(train) [40800/80000]  base_lr: 1.1988e-04 lr: 1.1988e-04  eta: 17:49:24  time: 1.6200  data_time: 0.0142  memory: 6599  grad_norm: 6.9339  loss: 0.6059  decode.loss_ce: 0.4036  decode.acc_seg: 87.1098  aux.loss_ce: 0.2024  aux.acc_seg: 82.8225
2024/10/28 07:14:49 - mmengine - INFO - Iter(train) [40850/80000]  base_lr: 1.1987e-04 lr: 1.1987e-04  eta: 17:47:59  time: 1.6098  data_time: 0.0114  memory: 6600  grad_norm: 7.2105  loss: 0.6212  decode.loss_ce: 0.4254  decode.acc_seg: 82.7344  aux.loss_ce: 0.1958  aux.acc_seg: 77.9491
2024/10/28 07:16:10 - mmengine - INFO - Iter(train) [40900/80000]  base_lr: 1.1985e-04 lr: 1.1985e-04  eta: 17:46:35  time: 1.6111  data_time: 0.0110  memory: 6600  grad_norm: 6.0380  loss: 0.5958  decode.loss_ce: 0.4095  decode.acc_seg: 84.3711  aux.loss_ce: 0.1863  aux.acc_seg: 81.8510
2024/10/28 07:17:31 - mmengine - INFO - Iter(train) [40950/80000]  base_lr: 1.1983e-04 lr: 1.1983e-04  eta: 17:45:11  time: 1.6385  data_time: 0.0112  memory: 6599  grad_norm: 4.7639  loss: 0.6126  decode.loss_ce: 0.4147  decode.acc_seg: 75.1378  aux.loss_ce: 0.1978  aux.acc_seg: 74.1920
2024/10/28 07:18:52 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 07:18:52 - mmengine - INFO - Iter(train) [41000/80000]  base_lr: 1.1982e-04 lr: 1.1982e-04  eta: 17:43:47  time: 1.6381  data_time: 0.0114  memory: 6600  grad_norm: 5.6744  loss: 0.6263  decode.loss_ce: 0.4264  decode.acc_seg: 82.7933  aux.loss_ce: 0.1999  aux.acc_seg: 81.1470
2024/10/28 07:20:12 - mmengine - INFO - Iter(train) [41050/80000]  base_lr: 1.1980e-04 lr: 1.1980e-04  eta: 17:42:22  time: 1.6116  data_time: 0.0111  memory: 6600  grad_norm: 6.0046  loss: 0.6505  decode.loss_ce: 0.4431  decode.acc_seg: 83.4162  aux.loss_ce: 0.2074  aux.acc_seg: 80.2188
2024/10/28 07:21:33 - mmengine - INFO - Iter(train) [41100/80000]  base_lr: 1.1978e-04 lr: 1.1978e-04  eta: 17:40:58  time: 1.6117  data_time: 0.0113  memory: 6598  grad_norm: 4.8138  loss: 0.6454  decode.loss_ce: 0.4294  decode.acc_seg: 81.9421  aux.loss_ce: 0.2160  aux.acc_seg: 77.9747
2024/10/28 07:22:54 - mmengine - INFO - Iter(train) [41150/80000]  base_lr: 1.1976e-04 lr: 1.1976e-04  eta: 17:39:34  time: 1.6254  data_time: 0.0113  memory: 6600  grad_norm: 6.6650  loss: 0.5776  decode.loss_ce: 0.3934  decode.acc_seg: 90.8107  aux.loss_ce: 0.1842  aux.acc_seg: 91.8074
2024/10/28 07:24:15 - mmengine - INFO - Iter(train) [41200/80000]  base_lr: 1.1973e-04 lr: 1.1973e-04  eta: 17:38:10  time: 1.6176  data_time: 0.0120  memory: 6599  grad_norm: 4.7671  loss: 0.5608  decode.loss_ce: 0.3840  decode.acc_seg: 81.6893  aux.loss_ce: 0.1767  aux.acc_seg: 81.7570
2024/10/28 07:25:36 - mmengine - INFO - Iter(train) [41250/80000]  base_lr: 1.1971e-04 lr: 1.1971e-04  eta: 17:36:46  time: 1.6180  data_time: 0.0115  memory: 6598  grad_norm: 6.7672  loss: 0.5920  decode.loss_ce: 0.4066  decode.acc_seg: 92.7486  aux.loss_ce: 0.1854  aux.acc_seg: 91.7099
2024/10/28 07:26:57 - mmengine - INFO - Iter(train) [41300/80000]  base_lr: 1.1969e-04 lr: 1.1969e-04  eta: 17:35:23  time: 1.6104  data_time: 0.0112  memory: 6602  grad_norm: 6.8975  loss: 0.6580  decode.loss_ce: 0.4429  decode.acc_seg: 86.3796  aux.loss_ce: 0.2151  aux.acc_seg: 87.4054
2024/10/28 07:28:18 - mmengine - INFO - Iter(train) [41350/80000]  base_lr: 1.1966e-04 lr: 1.1966e-04  eta: 17:33:59  time: 1.6141  data_time: 0.0112  memory: 6600  grad_norm: 9.4797  loss: 0.6821  decode.loss_ce: 0.4725  decode.acc_seg: 87.5889  aux.loss_ce: 0.2096  aux.acc_seg: 85.5844
2024/10/28 07:29:39 - mmengine - INFO - Iter(train) [41400/80000]  base_lr: 1.1964e-04 lr: 1.1964e-04  eta: 17:32:35  time: 1.6118  data_time: 0.0125  memory: 6600  grad_norm: 6.5355  loss: 0.5481  decode.loss_ce: 0.3742  decode.acc_seg: 88.2730  aux.loss_ce: 0.1739  aux.acc_seg: 88.1574
2024/10/28 07:30:59 - mmengine - INFO - Iter(train) [41450/80000]  base_lr: 1.1961e-04 lr: 1.1961e-04  eta: 17:31:10  time: 1.6143  data_time: 0.0145  memory: 6598  grad_norm: 6.0163  loss: 0.5767  decode.loss_ce: 0.3778  decode.acc_seg: 88.3641  aux.loss_ce: 0.1989  aux.acc_seg: 84.2942
2024/10/28 07:32:21 - mmengine - INFO - Iter(train) [41500/80000]  base_lr: 1.1958e-04 lr: 1.1958e-04  eta: 17:29:48  time: 1.6134  data_time: 0.0142  memory: 6599  grad_norm: 6.0187  loss: 0.6128  decode.loss_ce: 0.4153  decode.acc_seg: 81.8993  aux.loss_ce: 0.1975  aux.acc_seg: 83.1019
2024/10/28 07:33:42 - mmengine - INFO - Iter(train) [41550/80000]  base_lr: 1.1956e-04 lr: 1.1956e-04  eta: 17:28:24  time: 1.6153  data_time: 0.0141  memory: 6599  grad_norm: 5.6669  loss: 0.5002  decode.loss_ce: 0.3395  decode.acc_seg: 88.3971  aux.loss_ce: 0.1606  aux.acc_seg: 89.8319
2024/10/28 07:35:03 - mmengine - INFO - Iter(train) [41600/80000]  base_lr: 1.1953e-04 lr: 1.1953e-04  eta: 17:27:00  time: 1.6148  data_time: 0.0144  memory: 6600  grad_norm: 6.2728  loss: 0.6738  decode.loss_ce: 0.4589  decode.acc_seg: 85.2421  aux.loss_ce: 0.2149  aux.acc_seg: 83.9450
2024/10/28 07:36:27 - mmengine - INFO - Iter(train) [41650/80000]  base_lr: 1.1950e-04 lr: 1.1950e-04  eta: 17:25:43  time: 1.6133  data_time: 0.0138  memory: 6599  grad_norm: 7.3551  loss: 0.6174  decode.loss_ce: 0.4141  decode.acc_seg: 86.6831  aux.loss_ce: 0.2033  aux.acc_seg: 79.9054
2024/10/28 07:37:47 - mmengine - INFO - Iter(train) [41700/80000]  base_lr: 1.1947e-04 lr: 1.1947e-04  eta: 17:24:19  time: 1.6118  data_time: 0.0143  memory: 6599  grad_norm: 11.6604  loss: 0.4878  decode.loss_ce: 0.3342  decode.acc_seg: 86.0425  aux.loss_ce: 0.1536  aux.acc_seg: 84.2273
2024/10/28 07:39:08 - mmengine - INFO - Iter(train) [41750/80000]  base_lr: 1.1943e-04 lr: 1.1943e-04  eta: 17:22:56  time: 1.6112  data_time: 0.0115  memory: 6599  grad_norm: 5.6763  loss: 0.6440  decode.loss_ce: 0.4425  decode.acc_seg: 75.8426  aux.loss_ce: 0.2015  aux.acc_seg: 78.6377
2024/10/28 07:40:30 - mmengine - INFO - Iter(train) [41800/80000]  base_lr: 1.1940e-04 lr: 1.1940e-04  eta: 17:21:33  time: 1.6138  data_time: 0.0112  memory: 6599  grad_norm: 4.6770  loss: 0.5626  decode.loss_ce: 0.3794  decode.acc_seg: 84.5409  aux.loss_ce: 0.1832  aux.acc_seg: 86.4048
2024/10/28 07:41:51 - mmengine - INFO - Iter(train) [41850/80000]  base_lr: 1.1937e-04 lr: 1.1937e-04  eta: 17:20:09  time: 1.6136  data_time: 0.0115  memory: 6599  grad_norm: 7.1677  loss: 0.6283  decode.loss_ce: 0.4303  decode.acc_seg: 87.3906  aux.loss_ce: 0.1981  aux.acc_seg: 83.9418
2024/10/28 07:43:12 - mmengine - INFO - Iter(train) [41900/80000]  base_lr: 1.1933e-04 lr: 1.1933e-04  eta: 17:18:46  time: 1.6144  data_time: 0.0112  memory: 6600  grad_norm: 8.4860  loss: 0.6033  decode.loss_ce: 0.3984  decode.acc_seg: 78.3896  aux.loss_ce: 0.2049  aux.acc_seg: 77.5261
2024/10/28 07:44:33 - mmengine - INFO - Iter(train) [41950/80000]  base_lr: 1.1930e-04 lr: 1.1930e-04  eta: 17:17:22  time: 1.6129  data_time: 0.0115  memory: 6599  grad_norm: 5.7761  loss: 0.6313  decode.loss_ce: 0.4384  decode.acc_seg: 81.2171  aux.loss_ce: 0.1929  aux.acc_seg: 78.7770
2024/10/28 07:45:53 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 07:45:53 - mmengine - INFO - Iter(train) [42000/80000]  base_lr: 1.1926e-04 lr: 1.1926e-04  eta: 17:15:58  time: 1.6114  data_time: 0.0114  memory: 6599  grad_norm: 5.3366  loss: 0.6030  decode.loss_ce: 0.4129  decode.acc_seg: 82.3380  aux.loss_ce: 0.1900  aux.acc_seg: 81.8178
2024/10/28 07:47:14 - mmengine - INFO - Iter(train) [42050/80000]  base_lr: 1.1922e-04 lr: 1.1922e-04  eta: 17:14:34  time: 1.6082  data_time: 0.0115  memory: 6600  grad_norm: 5.4175  loss: 0.5613  decode.loss_ce: 0.3875  decode.acc_seg: 88.4019  aux.loss_ce: 0.1737  aux.acc_seg: 88.7500
2024/10/28 07:48:35 - mmengine - INFO - Iter(train) [42100/80000]  base_lr: 1.1919e-04 lr: 1.1919e-04  eta: 17:13:10  time: 1.6108  data_time: 0.0116  memory: 6599  grad_norm: 5.6715  loss: 0.6752  decode.loss_ce: 0.4533  decode.acc_seg: 80.2802  aux.loss_ce: 0.2219  aux.acc_seg: 67.8357
2024/10/28 07:49:55 - mmengine - INFO - Iter(train) [42150/80000]  base_lr: 1.1915e-04 lr: 1.1915e-04  eta: 17:11:46  time: 1.6133  data_time: 0.0123  memory: 6600  grad_norm: 8.2272  loss: 0.6317  decode.loss_ce: 0.4170  decode.acc_seg: 81.8054  aux.loss_ce: 0.2146  aux.acc_seg: 82.5705
2024/10/28 07:51:16 - mmengine - INFO - Iter(train) [42200/80000]  base_lr: 1.1911e-04 lr: 1.1911e-04  eta: 17:10:22  time: 1.6142  data_time: 0.0117  memory: 6599  grad_norm: 7.9762  loss: 0.5228  decode.loss_ce: 0.3554  decode.acc_seg: 87.1000  aux.loss_ce: 0.1674  aux.acc_seg: 87.4817
2024/10/28 07:52:38 - mmengine - INFO - Iter(train) [42250/80000]  base_lr: 1.1907e-04 lr: 1.1907e-04  eta: 17:08:59  time: 1.6382  data_time: 0.0117  memory: 6598  grad_norm: 7.1205  loss: 0.6572  decode.loss_ce: 0.4531  decode.acc_seg: 86.3401  aux.loss_ce: 0.2041  aux.acc_seg: 86.9939
2024/10/28 07:53:58 - mmengine - INFO - Iter(train) [42300/80000]  base_lr: 1.1902e-04 lr: 1.1902e-04  eta: 17:07:36  time: 1.6110  data_time: 0.0110  memory: 6600  grad_norm: 8.1731  loss: 0.6040  decode.loss_ce: 0.4122  decode.acc_seg: 84.0099  aux.loss_ce: 0.1919  aux.acc_seg: 84.3516
2024/10/28 07:55:19 - mmengine - INFO - Iter(train) [42350/80000]  base_lr: 1.1898e-04 lr: 1.1898e-04  eta: 17:06:12  time: 1.6087  data_time: 0.0110  memory: 6599  grad_norm: 6.1841  loss: 0.5711  decode.loss_ce: 0.3898  decode.acc_seg: 82.6023  aux.loss_ce: 0.1813  aux.acc_seg: 85.1135
2024/10/28 07:56:41 - mmengine - INFO - Iter(train) [42400/80000]  base_lr: 1.1894e-04 lr: 1.1894e-04  eta: 17:04:49  time: 1.6267  data_time: 0.0114  memory: 6599  grad_norm: 5.3559  loss: 0.6353  decode.loss_ce: 0.4347  decode.acc_seg: 82.7362  aux.loss_ce: 0.2006  aux.acc_seg: 84.7745
2024/10/28 07:58:01 - mmengine - INFO - Iter(train) [42450/80000]  base_lr: 1.1889e-04 lr: 1.1889e-04  eta: 17:03:25  time: 1.6103  data_time: 0.0113  memory: 6599  grad_norm: 6.7249  loss: 0.6254  decode.loss_ce: 0.4255  decode.acc_seg: 85.8985  aux.loss_ce: 0.1999  aux.acc_seg: 84.2510
2024/10/28 07:59:27 - mmengine - INFO - Iter(train) [42500/80000]  base_lr: 1.1885e-04 lr: 1.1885e-04  eta: 17:02:12  time: 1.6115  data_time: 0.0110  memory: 6600  grad_norm: 9.2849  loss: 0.6725  decode.loss_ce: 0.4561  decode.acc_seg: 80.4637  aux.loss_ce: 0.2163  aux.acc_seg: 80.8821
2024/10/28 08:00:48 - mmengine - INFO - Iter(train) [42550/80000]  base_lr: 1.1880e-04 lr: 1.1880e-04  eta: 17:00:48  time: 1.6120  data_time: 0.0109  memory: 6599  grad_norm: 9.0121  loss: 0.6839  decode.loss_ce: 0.4683  decode.acc_seg: 77.3920  aux.loss_ce: 0.2156  aux.acc_seg: 79.4414
2024/10/28 08:02:09 - mmengine - INFO - Iter(train) [42600/80000]  base_lr: 1.1875e-04 lr: 1.1875e-04  eta: 16:59:25  time: 1.6108  data_time: 0.0114  memory: 6598  grad_norm: 7.8250  loss: 0.5947  decode.loss_ce: 0.4055  decode.acc_seg: 88.3587  aux.loss_ce: 0.1892  aux.acc_seg: 89.2970
2024/10/28 08:03:30 - mmengine - INFO - Iter(train) [42650/80000]  base_lr: 1.1871e-04 lr: 1.1871e-04  eta: 16:58:01  time: 1.6149  data_time: 0.0113  memory: 6598  grad_norm: 4.7786  loss: 0.6771  decode.loss_ce: 0.4609  decode.acc_seg: 88.8660  aux.loss_ce: 0.2162  aux.acc_seg: 88.1534
2024/10/28 08:04:50 - mmengine - INFO - Iter(train) [42700/80000]  base_lr: 1.1866e-04 lr: 1.1866e-04  eta: 16:56:37  time: 1.6109  data_time: 0.0116  memory: 6600  grad_norm: 12.2126  loss: 0.6852  decode.loss_ce: 0.4648  decode.acc_seg: 80.0921  aux.loss_ce: 0.2204  aux.acc_seg: 80.0564
2024/10/28 08:06:11 - mmengine - INFO - Iter(train) [42750/80000]  base_lr: 1.1861e-04 lr: 1.1861e-04  eta: 16:55:13  time: 1.6109  data_time: 0.0112  memory: 6599  grad_norm: 5.7841  loss: 0.5806  decode.loss_ce: 0.3971  decode.acc_seg: 87.0616  aux.loss_ce: 0.1835  aux.acc_seg: 87.2276
2024/10/28 08:07:32 - mmengine - INFO - Iter(train) [42800/80000]  base_lr: 1.1856e-04 lr: 1.1856e-04  eta: 16:53:49  time: 1.6121  data_time: 0.0117  memory: 6598  grad_norm: 4.7632  loss: 0.6098  decode.loss_ce: 0.4101  decode.acc_seg: 85.4494  aux.loss_ce: 0.1997  aux.acc_seg: 77.9916
2024/10/28 08:08:52 - mmengine - INFO - Iter(train) [42850/80000]  base_lr: 1.1850e-04 lr: 1.1850e-04  eta: 16:52:25  time: 1.6131  data_time: 0.0114  memory: 6600  grad_norm: 5.4309  loss: 0.5695  decode.loss_ce: 0.3842  decode.acc_seg: 82.4263  aux.loss_ce: 0.1854  aux.acc_seg: 82.1061
2024/10/28 08:10:14 - mmengine - INFO - Iter(train) [42900/80000]  base_lr: 1.1845e-04 lr: 1.1845e-04  eta: 16:51:03  time: 1.6104  data_time: 0.0114  memory: 6600  grad_norm: 4.9886  loss: 0.6701  decode.loss_ce: 0.4570  decode.acc_seg: 85.5756  aux.loss_ce: 0.2131  aux.acc_seg: 86.0531
2024/10/28 08:11:35 - mmengine - INFO - Iter(train) [42950/80000]  base_lr: 1.1840e-04 lr: 1.1840e-04  eta: 16:49:39  time: 1.6106  data_time: 0.0115  memory: 6598  grad_norm: 5.8311  loss: 0.7144  decode.loss_ce: 0.4739  decode.acc_seg: 90.5650  aux.loss_ce: 0.2405  aux.acc_seg: 89.0124
2024/10/28 08:12:56 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 08:12:56 - mmengine - INFO - Iter(train) [43000/80000]  base_lr: 1.1834e-04 lr: 1.1834e-04  eta: 16:48:16  time: 1.6110  data_time: 0.0113  memory: 6600  grad_norm: 6.7096  loss: 0.5776  decode.loss_ce: 0.3948  decode.acc_seg: 87.4612  aux.loss_ce: 0.1828  aux.acc_seg: 88.1236
2024/10/28 08:14:16 - mmengine - INFO - Iter(train) [43050/80000]  base_lr: 1.1829e-04 lr: 1.1829e-04  eta: 16:46:52  time: 1.6110  data_time: 0.0116  memory: 6599  grad_norm: 5.0040  loss: 0.5857  decode.loss_ce: 0.3986  decode.acc_seg: 77.6393  aux.loss_ce: 0.1871  aux.acc_seg: 74.7794
2024/10/28 08:15:37 - mmengine - INFO - Iter(train) [43100/80000]  base_lr: 1.1823e-04 lr: 1.1823e-04  eta: 16:45:29  time: 1.6113  data_time: 0.0118  memory: 6599  grad_norm: 5.3553  loss: 0.5325  decode.loss_ce: 0.3726  decode.acc_seg: 89.2491  aux.loss_ce: 0.1598  aux.acc_seg: 87.6895
2024/10/28 08:16:58 - mmengine - INFO - Iter(train) [43150/80000]  base_lr: 1.1817e-04 lr: 1.1817e-04  eta: 16:44:05  time: 1.6160  data_time: 0.0118  memory: 6599  grad_norm: 9.3197  loss: 0.6923  decode.loss_ce: 0.4786  decode.acc_seg: 80.2508  aux.loss_ce: 0.2137  aux.acc_seg: 77.8300
2024/10/28 08:18:19 - mmengine - INFO - Iter(train) [43200/80000]  base_lr: 1.1812e-04 lr: 1.1812e-04  eta: 16:42:42  time: 1.6111  data_time: 0.0117  memory: 6600  grad_norm: 6.7327  loss: 0.6434  decode.loss_ce: 0.4380  decode.acc_seg: 90.2745  aux.loss_ce: 0.2054  aux.acc_seg: 87.2092
2024/10/28 08:19:40 - mmengine - INFO - Iter(train) [43250/80000]  base_lr: 1.1806e-04 lr: 1.1806e-04  eta: 16:41:18  time: 1.6141  data_time: 0.0115  memory: 6599  grad_norm: 4.6879  loss: 0.5988  decode.loss_ce: 0.4003  decode.acc_seg: 76.4798  aux.loss_ce: 0.1984  aux.acc_seg: 73.1529
2024/10/28 08:21:01 - mmengine - INFO - Iter(train) [43300/80000]  base_lr: 1.1800e-04 lr: 1.1800e-04  eta: 16:39:55  time: 1.6131  data_time: 0.0112  memory: 6600  grad_norm: 7.7454  loss: 0.5309  decode.loss_ce: 0.3588  decode.acc_seg: 83.6614  aux.loss_ce: 0.1721  aux.acc_seg: 80.5377
2024/10/28 08:22:21 - mmengine - INFO - Iter(train) [43350/80000]  base_lr: 1.1794e-04 lr: 1.1794e-04  eta: 16:38:31  time: 1.6210  data_time: 0.0113  memory: 6598  grad_norm: 5.5518  loss: 0.5375  decode.loss_ce: 0.3652  decode.acc_seg: 85.9646  aux.loss_ce: 0.1724  aux.acc_seg: 87.5850
2024/10/28 08:23:42 - mmengine - INFO - Iter(train) [43400/80000]  base_lr: 1.1787e-04 lr: 1.1787e-04  eta: 16:37:08  time: 1.6161  data_time: 0.0112  memory: 6598  grad_norm: 8.8919  loss: 0.5666  decode.loss_ce: 0.3773  decode.acc_seg: 86.8774  aux.loss_ce: 0.1892  aux.acc_seg: 86.9943
2024/10/28 08:25:03 - mmengine - INFO - Iter(train) [43450/80000]  base_lr: 1.1781e-04 lr: 1.1781e-04  eta: 16:35:45  time: 1.6130  data_time: 0.0114  memory: 6598  grad_norm: 6.5254  loss: 0.6030  decode.loss_ce: 0.4051  decode.acc_seg: 89.0586  aux.loss_ce: 0.1979  aux.acc_seg: 85.5775
2024/10/28 08:26:27 - mmengine - INFO - Iter(train) [43500/80000]  base_lr: 1.1775e-04 lr: 1.1775e-04  eta: 16:34:28  time: 1.6127  data_time: 0.0112  memory: 6598  grad_norm: 5.8450  loss: 0.6626  decode.loss_ce: 0.4527  decode.acc_seg: 85.2672  aux.loss_ce: 0.2099  aux.acc_seg: 82.2575
2024/10/28 08:27:48 - mmengine - INFO - Iter(train) [43550/80000]  base_lr: 1.1768e-04 lr: 1.1768e-04  eta: 16:33:04  time: 1.6119  data_time: 0.0115  memory: 6599  grad_norm: 7.3903  loss: 0.6987  decode.loss_ce: 0.4854  decode.acc_seg: 83.8673  aux.loss_ce: 0.2133  aux.acc_seg: 83.4821
2024/10/28 08:29:09 - mmengine - INFO - Iter(train) [43600/80000]  base_lr: 1.1762e-04 lr: 1.1762e-04  eta: 16:31:41  time: 1.6134  data_time: 0.0115  memory: 6599  grad_norm: 8.0506  loss: 0.6003  decode.loss_ce: 0.4088  decode.acc_seg: 84.7527  aux.loss_ce: 0.1914  aux.acc_seg: 81.7321
2024/10/28 08:30:30 - mmengine - INFO - Iter(train) [43650/80000]  base_lr: 1.1755e-04 lr: 1.1755e-04  eta: 16:30:18  time: 1.6147  data_time: 0.0113  memory: 6601  grad_norm: 5.4649  loss: 0.6227  decode.loss_ce: 0.4222  decode.acc_seg: 80.3153  aux.loss_ce: 0.2005  aux.acc_seg: 76.4174
2024/10/28 08:31:51 - mmengine - INFO - Iter(train) [43700/80000]  base_lr: 1.1749e-04 lr: 1.1749e-04  eta: 16:28:55  time: 1.6140  data_time: 0.0109  memory: 6600  grad_norm: 7.5175  loss: 0.6395  decode.loss_ce: 0.4415  decode.acc_seg: 83.6691  aux.loss_ce: 0.1980  aux.acc_seg: 83.0760
2024/10/28 08:33:12 - mmengine - INFO - Iter(train) [43750/80000]  base_lr: 1.1742e-04 lr: 1.1742e-04  eta: 16:27:31  time: 1.6110  data_time: 0.0111  memory: 6599  grad_norm: 6.8771  loss: 0.5648  decode.loss_ce: 0.3900  decode.acc_seg: 86.3377  aux.loss_ce: 0.1748  aux.acc_seg: 84.7312
2024/10/28 08:34:33 - mmengine - INFO - Iter(train) [43800/80000]  base_lr: 1.1735e-04 lr: 1.1735e-04  eta: 16:26:08  time: 1.6102  data_time: 0.0112  memory: 6598  grad_norm: 8.8058  loss: 0.7269  decode.loss_ce: 0.4972  decode.acc_seg: 69.1496  aux.loss_ce: 0.2298  aux.acc_seg: 75.4429
2024/10/28 08:35:53 - mmengine - INFO - Iter(train) [43850/80000]  base_lr: 1.1728e-04 lr: 1.1728e-04  eta: 16:24:44  time: 1.6124  data_time: 0.0110  memory: 6600  grad_norm: 5.4579  loss: 0.5830  decode.loss_ce: 0.4001  decode.acc_seg: 86.9630  aux.loss_ce: 0.1829  aux.acc_seg: 86.1372
2024/10/28 08:37:14 - mmengine - INFO - Iter(train) [43900/80000]  base_lr: 1.1721e-04 lr: 1.1721e-04  eta: 16:23:21  time: 1.6122  data_time: 0.0119  memory: 6599  grad_norm: 7.6015  loss: 0.5536  decode.loss_ce: 0.3851  decode.acc_seg: 91.1477  aux.loss_ce: 0.1685  aux.acc_seg: 91.0285
2024/10/28 08:38:35 - mmengine - INFO - Iter(train) [43950/80000]  base_lr: 1.1714e-04 lr: 1.1714e-04  eta: 16:21:58  time: 1.6145  data_time: 0.0113  memory: 6600  grad_norm: 6.8257  loss: 0.6173  decode.loss_ce: 0.4296  decode.acc_seg: 90.4104  aux.loss_ce: 0.1878  aux.acc_seg: 90.5487
2024/10/28 08:39:57 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 08:39:57 - mmengine - INFO - Iter(train) [44000/80000]  base_lr: 1.1706e-04 lr: 1.1706e-04  eta: 16:20:36  time: 1.6130  data_time: 0.0115  memory: 6600  grad_norm: 7.3946  loss: 0.6816  decode.loss_ce: 0.4707  decode.acc_seg: 78.9930  aux.loss_ce: 0.2109  aux.acc_seg: 79.5266
2024/10/28 08:41:18 - mmengine - INFO - Iter(train) [44050/80000]  base_lr: 1.1699e-04 lr: 1.1699e-04  eta: 16:19:13  time: 1.6149  data_time: 0.0111  memory: 6600  grad_norm: 5.3243  loss: 0.5877  decode.loss_ce: 0.3993  decode.acc_seg: 88.4901  aux.loss_ce: 0.1884  aux.acc_seg: 88.0158
2024/10/28 08:42:38 - mmengine - INFO - Iter(train) [44100/80000]  base_lr: 1.1692e-04 lr: 1.1692e-04  eta: 16:17:49  time: 1.6122  data_time: 0.0112  memory: 6600  grad_norm: 7.4829  loss: 0.5633  decode.loss_ce: 0.3851  decode.acc_seg: 80.4115  aux.loss_ce: 0.1781  aux.acc_seg: 80.8457
2024/10/28 08:43:59 - mmengine - INFO - Iter(train) [44150/80000]  base_lr: 1.1684e-04 lr: 1.1684e-04  eta: 16:16:26  time: 1.6121  data_time: 0.0119  memory: 6600  grad_norm: 5.5722  loss: 0.4728  decode.loss_ce: 0.3286  decode.acc_seg: 85.5047  aux.loss_ce: 0.1442  aux.acc_seg: 84.8334
2024/10/28 08:45:20 - mmengine - INFO - Iter(train) [44200/80000]  base_lr: 1.1677e-04 lr: 1.1677e-04  eta: 16:15:03  time: 1.6120  data_time: 0.0119  memory: 6598  grad_norm: 7.1125  loss: 0.5972  decode.loss_ce: 0.4052  decode.acc_seg: 86.4079  aux.loss_ce: 0.1920  aux.acc_seg: 86.3162
2024/10/28 08:46:41 - mmengine - INFO - Iter(train) [44250/80000]  base_lr: 1.1669e-04 lr: 1.1669e-04  eta: 16:13:40  time: 1.6094  data_time: 0.0117  memory: 6599  grad_norm: 5.8624  loss: 0.6401  decode.loss_ce: 0.4365  decode.acc_seg: 84.2555  aux.loss_ce: 0.2036  aux.acc_seg: 83.0116
2024/10/28 08:48:02 - mmengine - INFO - Iter(train) [44300/80000]  base_lr: 1.1661e-04 lr: 1.1661e-04  eta: 16:12:17  time: 1.6109  data_time: 0.0114  memory: 6600  grad_norm: 6.5285  loss: 0.6570  decode.loss_ce: 0.4499  decode.acc_seg: 83.1266  aux.loss_ce: 0.2071  aux.acc_seg: 79.0822
2024/10/28 08:49:26 - mmengine - INFO - Iter(train) [44350/80000]  base_lr: 1.1653e-04 lr: 1.1653e-04  eta: 16:10:59  time: 1.6128  data_time: 0.0112  memory: 6599  grad_norm: 8.8331  loss: 0.6505  decode.loss_ce: 0.4385  decode.acc_seg: 73.3596  aux.loss_ce: 0.2120  aux.acc_seg: 67.1779
2024/10/28 08:50:47 - mmengine - INFO - Iter(train) [44400/80000]  base_lr: 1.1645e-04 lr: 1.1645e-04  eta: 16:09:35  time: 1.6126  data_time: 0.0110  memory: 6599  grad_norm: 4.5223  loss: 0.5875  decode.loss_ce: 0.3990  decode.acc_seg: 82.6365  aux.loss_ce: 0.1885  aux.acc_seg: 83.4603
2024/10/28 08:52:07 - mmengine - INFO - Iter(train) [44450/80000]  base_lr: 1.1637e-04 lr: 1.1637e-04  eta: 16:08:12  time: 1.6128  data_time: 0.0108  memory: 6600  grad_norm: 6.4406  loss: 0.6901  decode.loss_ce: 0.4574  decode.acc_seg: 88.6760  aux.loss_ce: 0.2327  aux.acc_seg: 84.3909
2024/10/28 08:53:28 - mmengine - INFO - Iter(train) [44500/80000]  base_lr: 1.1629e-04 lr: 1.1629e-04  eta: 16:06:49  time: 1.6122  data_time: 0.0100  memory: 6600  grad_norm: 6.0814  loss: 0.6569  decode.loss_ce: 0.4396  decode.acc_seg: 76.4980  aux.loss_ce: 0.2174  aux.acc_seg: 70.7838
2024/10/28 08:54:49 - mmengine - INFO - Iter(train) [44550/80000]  base_lr: 1.1621e-04 lr: 1.1621e-04  eta: 16:05:25  time: 1.6094  data_time: 0.0106  memory: 6598  grad_norm: 11.2637  loss: 0.6977  decode.loss_ce: 0.4799  decode.acc_seg: 85.2265  aux.loss_ce: 0.2178  aux.acc_seg: 85.2535
2024/10/28 08:56:09 - mmengine - INFO - Iter(train) [44600/80000]  base_lr: 1.1613e-04 lr: 1.1613e-04  eta: 16:04:01  time: 1.6097  data_time: 0.0105  memory: 6600  grad_norm: 6.5803  loss: 0.7249  decode.loss_ce: 0.5059  decode.acc_seg: 83.5889  aux.loss_ce: 0.2189  aux.acc_seg: 80.1987
2024/10/28 08:57:30 - mmengine - INFO - Iter(train) [44650/80000]  base_lr: 1.1604e-04 lr: 1.1604e-04  eta: 16:02:38  time: 1.6122  data_time: 0.0106  memory: 6602  grad_norm: 5.7863  loss: 0.6014  decode.loss_ce: 0.4213  decode.acc_seg: 87.4629  aux.loss_ce: 0.1801  aux.acc_seg: 87.9583
2024/10/28 08:58:51 - mmengine - INFO - Iter(train) [44700/80000]  base_lr: 1.1596e-04 lr: 1.1596e-04  eta: 16:01:15  time: 1.6098  data_time: 0.0105  memory: 6598  grad_norm: 6.5721  loss: 0.5636  decode.loss_ce: 0.3854  decode.acc_seg: 84.1558  aux.loss_ce: 0.1782  aux.acc_seg: 82.2631
2024/10/28 09:00:12 - mmengine - INFO - Iter(train) [44750/80000]  base_lr: 1.1587e-04 lr: 1.1587e-04  eta: 15:59:53  time: 1.6090  data_time: 0.0103  memory: 6598  grad_norm: 5.4780  loss: 0.6212  decode.loss_ce: 0.4064  decode.acc_seg: 83.7333  aux.loss_ce: 0.2149  aux.acc_seg: 84.1048
2024/10/28 09:01:33 - mmengine - INFO - Iter(train) [44800/80000]  base_lr: 1.1579e-04 lr: 1.1579e-04  eta: 15:58:30  time: 1.6452  data_time: 0.0102  memory: 6599  grad_norm: 6.4943  loss: 0.6116  decode.loss_ce: 0.4159  decode.acc_seg: 88.0476  aux.loss_ce: 0.1956  aux.acc_seg: 90.4922
2024/10/28 09:02:54 - mmengine - INFO - Iter(train) [44850/80000]  base_lr: 1.1570e-04 lr: 1.1570e-04  eta: 15:57:07  time: 1.6136  data_time: 0.0102  memory: 6599  grad_norm: 7.9864  loss: 0.5841  decode.loss_ce: 0.3979  decode.acc_seg: 81.2230  aux.loss_ce: 0.1862  aux.acc_seg: 84.4937
2024/10/28 09:04:15 - mmengine - INFO - Iter(train) [44900/80000]  base_lr: 1.1561e-04 lr: 1.1561e-04  eta: 15:55:43  time: 1.6098  data_time: 0.0103  memory: 6598  grad_norm: 5.6080  loss: 0.5835  decode.loss_ce: 0.3869  decode.acc_seg: 87.4854  aux.loss_ce: 0.1966  aux.acc_seg: 68.8704
2024/10/28 09:05:36 - mmengine - INFO - Iter(train) [44950/80000]  base_lr: 1.1552e-04 lr: 1.1552e-04  eta: 15:54:20  time: 1.6116  data_time: 0.0104  memory: 6600  grad_norm: 6.8750  loss: 0.5885  decode.loss_ce: 0.3979  decode.acc_seg: 81.8956  aux.loss_ce: 0.1906  aux.acc_seg: 82.0759
2024/10/28 09:06:57 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 09:06:57 - mmengine - INFO - Iter(train) [45000/80000]  base_lr: 1.1543e-04 lr: 1.1543e-04  eta: 15:52:58  time: 1.6130  data_time: 0.0105  memory: 6599  grad_norm: 6.5902  loss: 0.6739  decode.loss_ce: 0.4603  decode.acc_seg: 78.9910  aux.loss_ce: 0.2136  aux.acc_seg: 78.5879
2024/10/28 09:08:18 - mmengine - INFO - Iter(train) [45050/80000]  base_lr: 1.1534e-04 lr: 1.1534e-04  eta: 15:51:36  time: 1.6124  data_time: 0.0102  memory: 6599  grad_norm: 4.8583  loss: 0.6023  decode.loss_ce: 0.4127  decode.acc_seg: 68.0836  aux.loss_ce: 0.1896  aux.acc_seg: 67.5433
2024/10/28 09:09:39 - mmengine - INFO - Iter(train) [45100/80000]  base_lr: 1.1525e-04 lr: 1.1525e-04  eta: 15:50:13  time: 1.6121  data_time: 0.0105  memory: 6600  grad_norm: 7.1800  loss: 0.5582  decode.loss_ce: 0.3680  decode.acc_seg: 85.7402  aux.loss_ce: 0.1902  aux.acc_seg: 84.6738
2024/10/28 09:11:00 - mmengine - INFO - Iter(train) [45150/80000]  base_lr: 1.1516e-04 lr: 1.1516e-04  eta: 15:48:50  time: 1.6121  data_time: 0.0107  memory: 6599  grad_norm: 6.5659  loss: 0.4796  decode.loss_ce: 0.3294  decode.acc_seg: 84.0903  aux.loss_ce: 0.1502  aux.acc_seg: 86.0638
2024/10/28 09:12:21 - mmengine - INFO - Iter(train) [45200/80000]  base_lr: 1.1507e-04 lr: 1.1507e-04  eta: 15:47:27  time: 1.6107  data_time: 0.0109  memory: 6599  grad_norm: 6.6047  loss: 0.5556  decode.loss_ce: 0.3652  decode.acc_seg: 87.8375  aux.loss_ce: 0.1904  aux.acc_seg: 83.8848
2024/10/28 09:13:42 - mmengine - INFO - Iter(train) [45250/80000]  base_lr: 1.1497e-04 lr: 1.1497e-04  eta: 15:46:04  time: 1.6129  data_time: 0.0105  memory: 6598  grad_norm: 6.2732  loss: 0.5828  decode.loss_ce: 0.4107  decode.acc_seg: 77.7754  aux.loss_ce: 0.1721  aux.acc_seg: 79.6637
2024/10/28 09:15:03 - mmengine - INFO - Iter(train) [45300/80000]  base_lr: 1.1488e-04 lr: 1.1488e-04  eta: 15:44:41  time: 1.6129  data_time: 0.0106  memory: 6600  grad_norm: 6.5624  loss: 0.6675  decode.loss_ce: 0.4483  decode.acc_seg: 87.8367  aux.loss_ce: 0.2191  aux.acc_seg: 85.5377
2024/10/28 09:16:26 - mmengine - INFO - Iter(train) [45350/80000]  base_lr: 1.1478e-04 lr: 1.1478e-04  eta: 15:43:21  time: 1.6099  data_time: 0.0106  memory: 6600  grad_norm: 5.1725  loss: 0.5774  decode.loss_ce: 0.3864  decode.acc_seg: 86.2095  aux.loss_ce: 0.1909  aux.acc_seg: 84.0995
2024/10/28 09:17:47 - mmengine - INFO - Iter(train) [45400/80000]  base_lr: 1.1469e-04 lr: 1.1469e-04  eta: 15:41:59  time: 1.6138  data_time: 0.0109  memory: 6599  grad_norm: 5.9474  loss: 0.6310  decode.loss_ce: 0.4234  decode.acc_seg: 85.1858  aux.loss_ce: 0.2075  aux.acc_seg: 82.1981
2024/10/28 09:19:08 - mmengine - INFO - Iter(train) [45450/80000]  base_lr: 1.1459e-04 lr: 1.1459e-04  eta: 15:40:36  time: 1.6357  data_time: 0.0106  memory: 6600  grad_norm: 7.4373  loss: 0.5294  decode.loss_ce: 0.3625  decode.acc_seg: 85.4863  aux.loss_ce: 0.1669  aux.acc_seg: 85.0392
2024/10/28 09:20:29 - mmengine - INFO - Iter(train) [45500/80000]  base_lr: 1.1449e-04 lr: 1.1449e-04  eta: 15:39:13  time: 1.6131  data_time: 0.0107  memory: 6599  grad_norm: 6.5698  loss: 0.6174  decode.loss_ce: 0.4143  decode.acc_seg: 88.2152  aux.loss_ce: 0.2031  aux.acc_seg: 82.5018
2024/10/28 09:21:50 - mmengine - INFO - Iter(train) [45550/80000]  base_lr: 1.1439e-04 lr: 1.1439e-04  eta: 15:37:50  time: 1.6108  data_time: 0.0105  memory: 6600  grad_norm: 7.4152  loss: 0.5041  decode.loss_ce: 0.3368  decode.acc_seg: 86.6973  aux.loss_ce: 0.1673  aux.acc_seg: 85.2382
2024/10/28 09:23:11 - mmengine - INFO - Iter(train) [45600/80000]  base_lr: 1.1429e-04 lr: 1.1429e-04  eta: 15:36:27  time: 1.6157  data_time: 0.0105  memory: 6599  grad_norm: 7.5848  loss: 0.6379  decode.loss_ce: 0.4333  decode.acc_seg: 82.5298  aux.loss_ce: 0.2046  aux.acc_seg: 80.5463
2024/10/28 09:24:32 - mmengine - INFO - Iter(train) [45650/80000]  base_lr: 1.1419e-04 lr: 1.1419e-04  eta: 15:35:05  time: 1.6135  data_time: 0.0112  memory: 6599  grad_norm: 7.5658  loss: 0.5968  decode.loss_ce: 0.3907  decode.acc_seg: 76.8926  aux.loss_ce: 0.2061  aux.acc_seg: 67.0086
2024/10/28 09:25:52 - mmengine - INFO - Iter(train) [45700/80000]  base_lr: 1.1409e-04 lr: 1.1409e-04  eta: 15:33:41  time: 1.6120  data_time: 0.0103  memory: 6601  grad_norm: 6.1629  loss: 0.5958  decode.loss_ce: 0.3972  decode.acc_seg: 84.2383  aux.loss_ce: 0.1986  aux.acc_seg: 85.2678
2024/10/28 09:27:13 - mmengine - INFO - Iter(train) [45750/80000]  base_lr: 1.1399e-04 lr: 1.1399e-04  eta: 15:32:18  time: 1.6122  data_time: 0.0109  memory: 6600  grad_norm: 6.3453  loss: 0.6118  decode.loss_ce: 0.4063  decode.acc_seg: 83.4367  aux.loss_ce: 0.2055  aux.acc_seg: 78.4292
2024/10/28 09:28:34 - mmengine - INFO - Iter(train) [45800/80000]  base_lr: 1.1388e-04 lr: 1.1388e-04  eta: 15:30:55  time: 1.6109  data_time: 0.0105  memory: 6600  grad_norm: 5.8867  loss: 0.6453  decode.loss_ce: 0.4387  decode.acc_seg: 85.8993  aux.loss_ce: 0.2067  aux.acc_seg: 80.0781
2024/10/28 09:29:55 - mmengine - INFO - Iter(train) [45850/80000]  base_lr: 1.1378e-04 lr: 1.1378e-04  eta: 15:29:32  time: 1.6131  data_time: 0.0104  memory: 6598  grad_norm: 6.4183  loss: 0.6718  decode.loss_ce: 0.4535  decode.acc_seg: 74.2033  aux.loss_ce: 0.2184  aux.acc_seg: 79.0903
2024/10/28 09:31:15 - mmengine - INFO - Iter(train) [45900/80000]  base_lr: 1.1367e-04 lr: 1.1367e-04  eta: 15:28:09  time: 1.6105  data_time: 0.0105  memory: 6598  grad_norm: 7.4011  loss: 0.6112  decode.loss_ce: 0.4197  decode.acc_seg: 86.7350  aux.loss_ce: 0.1915  aux.acc_seg: 87.3188
2024/10/28 09:32:37 - mmengine - INFO - Iter(train) [45950/80000]  base_lr: 1.1357e-04 lr: 1.1357e-04  eta: 15:26:47  time: 1.6127  data_time: 0.0106  memory: 6602  grad_norm: 6.0234  loss: 0.6125  decode.loss_ce: 0.4041  decode.acc_seg: 87.3857  aux.loss_ce: 0.2084  aux.acc_seg: 87.4426
2024/10/28 09:33:58 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 09:33:58 - mmengine - INFO - Iter(train) [46000/80000]  base_lr: 1.1346e-04 lr: 1.1346e-04  eta: 15:25:24  time: 1.6119  data_time: 0.0108  memory: 6599  grad_norm: 5.8241  loss: 0.5753  decode.loss_ce: 0.3889  decode.acc_seg: 86.7926  aux.loss_ce: 0.1863  aux.acc_seg: 86.6273
2024/10/28 09:35:19 - mmengine - INFO - Iter(train) [46050/80000]  base_lr: 1.1336e-04 lr: 1.1336e-04  eta: 15:24:02  time: 1.6358  data_time: 0.0106  memory: 6601  grad_norm: 5.9055  loss: 0.5929  decode.loss_ce: 0.4068  decode.acc_seg: 87.1245  aux.loss_ce: 0.1861  aux.acc_seg: 84.9351
2024/10/28 09:36:40 - mmengine - INFO - Iter(train) [46100/80000]  base_lr: 1.1325e-04 lr: 1.1325e-04  eta: 15:22:39  time: 1.6097  data_time: 0.0100  memory: 6599  grad_norm: 4.8307  loss: 0.5319  decode.loss_ce: 0.3594  decode.acc_seg: 88.3968  aux.loss_ce: 0.1725  aux.acc_seg: 83.5887
2024/10/28 09:38:00 - mmengine - INFO - Iter(train) [46150/80000]  base_lr: 1.1314e-04 lr: 1.1314e-04  eta: 15:21:16  time: 1.6137  data_time: 0.0110  memory: 6600  grad_norm: 5.7679  loss: 0.5600  decode.loss_ce: 0.3716  decode.acc_seg: 82.0546  aux.loss_ce: 0.1884  aux.acc_seg: 79.9861
2024/10/28 09:39:21 - mmengine - INFO - Iter(train) [46200/80000]  base_lr: 1.1303e-04 lr: 1.1303e-04  eta: 15:19:52  time: 1.6135  data_time: 0.0131  memory: 6599  grad_norm: 8.6664  loss: 0.5744  decode.loss_ce: 0.3857  decode.acc_seg: 88.2313  aux.loss_ce: 0.1887  aux.acc_seg: 86.3906
2024/10/28 09:40:42 - mmengine - INFO - Iter(train) [46250/80000]  base_lr: 1.1292e-04 lr: 1.1292e-04  eta: 15:18:29  time: 1.6093  data_time: 0.0133  memory: 6599  grad_norm: 5.6544  loss: 0.5801  decode.loss_ce: 0.3915  decode.acc_seg: 85.3376  aux.loss_ce: 0.1886  aux.acc_seg: 78.1640
2024/10/28 09:42:02 - mmengine - INFO - Iter(train) [46300/80000]  base_lr: 1.1281e-04 lr: 1.1281e-04  eta: 15:17:06  time: 1.6125  data_time: 0.0136  memory: 6599  grad_norm: 5.2080  loss: 0.5592  decode.loss_ce: 0.3738  decode.acc_seg: 83.5974  aux.loss_ce: 0.1853  aux.acc_seg: 80.3487
2024/10/28 09:43:26 - mmengine - INFO - Iter(train) [46350/80000]  base_lr: 1.1269e-04 lr: 1.1269e-04  eta: 15:15:47  time: 1.6120  data_time: 0.0139  memory: 6599  grad_norm: 6.3684  loss: 0.5027  decode.loss_ce: 0.3454  decode.acc_seg: 89.3205  aux.loss_ce: 0.1574  aux.acc_seg: 88.5261
2024/10/28 09:44:47 - mmengine - INFO - Iter(train) [46400/80000]  base_lr: 1.1258e-04 lr: 1.1258e-04  eta: 15:14:24  time: 1.6130  data_time: 0.0140  memory: 6598  grad_norm: 5.4210  loss: 0.5978  decode.loss_ce: 0.4045  decode.acc_seg: 83.2025  aux.loss_ce: 0.1933  aux.acc_seg: 84.2909
2024/10/28 09:46:07 - mmengine - INFO - Iter(train) [46450/80000]  base_lr: 1.1247e-04 lr: 1.1247e-04  eta: 15:13:01  time: 1.6142  data_time: 0.0141  memory: 6598  grad_norm: 7.7351  loss: 0.5509  decode.loss_ce: 0.3704  decode.acc_seg: 86.8196  aux.loss_ce: 0.1805  aux.acc_seg: 85.0480
2024/10/28 09:47:29 - mmengine - INFO - Iter(train) [46500/80000]  base_lr: 1.1235e-04 lr: 1.1235e-04  eta: 15:11:39  time: 1.6108  data_time: 0.0105  memory: 6598  grad_norm: 5.7240  loss: 0.6307  decode.loss_ce: 0.4233  decode.acc_seg: 83.8837  aux.loss_ce: 0.2074  aux.acc_seg: 79.0744
2024/10/28 09:48:49 - mmengine - INFO - Iter(train) [46550/80000]  base_lr: 1.1224e-04 lr: 1.1224e-04  eta: 15:10:16  time: 1.6091  data_time: 0.0106  memory: 6598  grad_norm: 5.8035  loss: 0.5476  decode.loss_ce: 0.3681  decode.acc_seg: 78.8586  aux.loss_ce: 0.1796  aux.acc_seg: 75.0368
2024/10/28 09:50:10 - mmengine - INFO - Iter(train) [46600/80000]  base_lr: 1.1212e-04 lr: 1.1212e-04  eta: 15:08:53  time: 1.6074  data_time: 0.0105  memory: 6598  grad_norm: 7.8964  loss: 0.5968  decode.loss_ce: 0.4127  decode.acc_seg: 75.9084  aux.loss_ce: 0.1841  aux.acc_seg: 75.1819
2024/10/28 09:51:31 - mmengine - INFO - Iter(train) [46650/80000]  base_lr: 1.1200e-04 lr: 1.1200e-04  eta: 15:07:30  time: 1.6099  data_time: 0.0107  memory: 6599  grad_norm: 5.4019  loss: 0.5379  decode.loss_ce: 0.3771  decode.acc_seg: 87.5029  aux.loss_ce: 0.1608  aux.acc_seg: 87.3695
2024/10/28 09:52:51 - mmengine - INFO - Iter(train) [46700/80000]  base_lr: 1.1189e-04 lr: 1.1189e-04  eta: 15:06:07  time: 1.6351  data_time: 0.0102  memory: 6598  grad_norm: 4.7894  loss: 0.6616  decode.loss_ce: 0.4334  decode.acc_seg: 77.8449  aux.loss_ce: 0.2282  aux.acc_seg: 73.2570
2024/10/28 09:54:12 - mmengine - INFO - Iter(train) [46750/80000]  base_lr: 1.1177e-04 lr: 1.1177e-04  eta: 15:04:44  time: 1.6092  data_time: 0.0105  memory: 6600  grad_norm: 7.0962  loss: 0.4808  decode.loss_ce: 0.3278  decode.acc_seg: 90.8153  aux.loss_ce: 0.1530  aux.acc_seg: 89.3317
2024/10/28 09:55:33 - mmengine - INFO - Iter(train) [46800/80000]  base_lr: 1.1165e-04 lr: 1.1165e-04  eta: 15:03:21  time: 1.6091  data_time: 0.0108  memory: 6599  grad_norm: 4.7745  loss: 0.5050  decode.loss_ce: 0.3433  decode.acc_seg: 85.3269  aux.loss_ce: 0.1616  aux.acc_seg: 85.7878
2024/10/28 09:56:53 - mmengine - INFO - Iter(train) [46850/80000]  base_lr: 1.1153e-04 lr: 1.1153e-04  eta: 15:01:58  time: 1.6066  data_time: 0.0105  memory: 6599  grad_norm: 5.6876  loss: 0.6218  decode.loss_ce: 0.4209  decode.acc_seg: 86.1470  aux.loss_ce: 0.2009  aux.acc_seg: 84.1002
2024/10/28 09:58:14 - mmengine - INFO - Iter(train) [46900/80000]  base_lr: 1.1141e-04 lr: 1.1141e-04  eta: 15:00:34  time: 1.6069  data_time: 0.0107  memory: 6599  grad_norm: 7.0324  loss: 0.5970  decode.loss_ce: 0.4111  decode.acc_seg: 87.0486  aux.loss_ce: 0.1859  aux.acc_seg: 87.7376
2024/10/28 09:59:34 - mmengine - INFO - Iter(train) [46950/80000]  base_lr: 1.1128e-04 lr: 1.1128e-04  eta: 14:59:11  time: 1.6084  data_time: 0.0106  memory: 6598  grad_norm: 10.5705  loss: 0.4581  decode.loss_ce: 0.3102  decode.acc_seg: 89.5863  aux.loss_ce: 0.1479  aux.acc_seg: 85.8463
2024/10/28 10:00:55 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 10:00:55 - mmengine - INFO - Iter(train) [47000/80000]  base_lr: 1.1116e-04 lr: 1.1116e-04  eta: 14:57:48  time: 1.6072  data_time: 0.0110  memory: 6599  grad_norm: 5.5155  loss: 0.4529  decode.loss_ce: 0.3055  decode.acc_seg: 90.4089  aux.loss_ce: 0.1474  aux.acc_seg: 90.4692
2024/10/28 10:02:15 - mmengine - INFO - Iter(train) [47050/80000]  base_lr: 1.1104e-04 lr: 1.1104e-04  eta: 14:56:25  time: 1.6105  data_time: 0.0115  memory: 6601  grad_norm: 5.4933  loss: 0.6224  decode.loss_ce: 0.4135  decode.acc_seg: 87.5565  aux.loss_ce: 0.2089  aux.acc_seg: 85.9565
2024/10/28 10:03:36 - mmengine - INFO - Iter(train) [47100/80000]  base_lr: 1.1091e-04 lr: 1.1091e-04  eta: 14:55:01  time: 1.6090  data_time: 0.0106  memory: 6599  grad_norm: 5.2014  loss: 0.6947  decode.loss_ce: 0.4616  decode.acc_seg: 74.8445  aux.loss_ce: 0.2331  aux.acc_seg: 71.9858
2024/10/28 10:04:56 - mmengine - INFO - Iter(train) [47150/80000]  base_lr: 1.1079e-04 lr: 1.1079e-04  eta: 14:53:38  time: 1.6069  data_time: 0.0111  memory: 6600  grad_norm: 7.3872  loss: 0.6386  decode.loss_ce: 0.4311  decode.acc_seg: 71.0959  aux.loss_ce: 0.2075  aux.acc_seg: 70.6099
2024/10/28 10:06:17 - mmengine - INFO - Iter(train) [47200/80000]  base_lr: 1.1066e-04 lr: 1.1066e-04  eta: 14:52:16  time: 1.6084  data_time: 0.0115  memory: 6599  grad_norm: 5.9914  loss: 0.6697  decode.loss_ce: 0.4508  decode.acc_seg: 84.5507  aux.loss_ce: 0.2189  aux.acc_seg: 82.5262
2024/10/28 10:07:38 - mmengine - INFO - Iter(train) [47250/80000]  base_lr: 1.1054e-04 lr: 1.1054e-04  eta: 14:50:53  time: 1.6077  data_time: 0.0107  memory: 6599  grad_norm: 6.8015  loss: 0.5704  decode.loss_ce: 0.3895  decode.acc_seg: 79.1256  aux.loss_ce: 0.1809  aux.acc_seg: 77.2950
2024/10/28 10:08:58 - mmengine - INFO - Iter(train) [47300/80000]  base_lr: 1.1041e-04 lr: 1.1041e-04  eta: 14:49:30  time: 1.6089  data_time: 0.0108  memory: 6598  grad_norm: 7.1838  loss: 0.5879  decode.loss_ce: 0.4111  decode.acc_seg: 82.2327  aux.loss_ce: 0.1768  aux.acc_seg: 83.6964
2024/10/28 10:10:19 - mmengine - INFO - Iter(train) [47350/80000]  base_lr: 1.1028e-04 lr: 1.1028e-04  eta: 14:48:07  time: 1.6090  data_time: 0.0109  memory: 6599  grad_norm: 4.2082  loss: 0.6031  decode.loss_ce: 0.4095  decode.acc_seg: 82.6543  aux.loss_ce: 0.1935  aux.acc_seg: 79.3223
2024/10/28 10:11:40 - mmengine - INFO - Iter(train) [47400/80000]  base_lr: 1.1015e-04 lr: 1.1015e-04  eta: 14:46:44  time: 1.6093  data_time: 0.0112  memory: 6600  grad_norm: 4.9680  loss: 0.5502  decode.loss_ce: 0.3743  decode.acc_seg: 82.2706  aux.loss_ce: 0.1759  aux.acc_seg: 80.2747
2024/10/28 10:13:00 - mmengine - INFO - Iter(train) [47450/80000]  base_lr: 1.1002e-04 lr: 1.1002e-04  eta: 14:45:21  time: 1.6100  data_time: 0.0106  memory: 6598  grad_norm: 7.9796  loss: 0.5918  decode.loss_ce: 0.4099  decode.acc_seg: 78.9743  aux.loss_ce: 0.1819  aux.acc_seg: 79.3479
2024/10/28 10:14:22 - mmengine - INFO - Iter(train) [47500/80000]  base_lr: 1.0989e-04 lr: 1.0989e-04  eta: 14:43:59  time: 1.6143  data_time: 0.0107  memory: 6601  grad_norm: 4.8828  loss: 0.5662  decode.loss_ce: 0.3826  decode.acc_seg: 86.2024  aux.loss_ce: 0.1836  aux.acc_seg: 80.7908
2024/10/28 10:15:42 - mmengine - INFO - Iter(train) [47550/80000]  base_lr: 1.0976e-04 lr: 1.0976e-04  eta: 14:42:36  time: 1.6105  data_time: 0.0108  memory: 6599  grad_norm: 7.1021  loss: 0.6119  decode.loss_ce: 0.4121  decode.acc_seg: 85.3467  aux.loss_ce: 0.1998  aux.acc_seg: 81.4945
2024/10/28 10:17:03 - mmengine - INFO - Iter(train) [47600/80000]  base_lr: 1.0963e-04 lr: 1.0963e-04  eta: 14:41:13  time: 1.6108  data_time: 0.0111  memory: 6600  grad_norm: 5.8704  loss: 0.5788  decode.loss_ce: 0.3976  decode.acc_seg: 81.6636  aux.loss_ce: 0.1812  aux.acc_seg: 81.1399
2024/10/28 10:18:26 - mmengine - INFO - Iter(train) [47650/80000]  base_lr: 1.0949e-04 lr: 1.0949e-04  eta: 14:39:53  time: 1.6109  data_time: 0.0108  memory: 6600  grad_norm: 6.9089  loss: 0.5436  decode.loss_ce: 0.3795  decode.acc_seg: 89.5192  aux.loss_ce: 0.1641  aux.acc_seg: 90.2862
2024/10/28 10:19:47 - mmengine - INFO - Iter(train) [47700/80000]  base_lr: 1.0936e-04 lr: 1.0936e-04  eta: 14:38:31  time: 1.6367  data_time: 0.0103  memory: 6599  grad_norm: 4.1722  loss: 0.5327  decode.loss_ce: 0.3628  decode.acc_seg: 87.9498  aux.loss_ce: 0.1699  aux.acc_seg: 85.0473
2024/10/28 10:21:08 - mmengine - INFO - Iter(train) [47750/80000]  base_lr: 1.0923e-04 lr: 1.0923e-04  eta: 14:37:09  time: 1.6123  data_time: 0.0103  memory: 6599  grad_norm: 5.7410  loss: 0.5136  decode.loss_ce: 0.3467  decode.acc_seg: 81.4458  aux.loss_ce: 0.1668  aux.acc_seg: 75.4465
2024/10/28 10:22:29 - mmengine - INFO - Iter(train) [47800/80000]  base_lr: 1.0909e-04 lr: 1.0909e-04  eta: 14:35:46  time: 1.6091  data_time: 0.0106  memory: 6600  grad_norm: 6.2827  loss: 0.6709  decode.loss_ce: 0.4473  decode.acc_seg: 86.7445  aux.loss_ce: 0.2236  aux.acc_seg: 86.2704
2024/10/28 10:23:49 - mmengine - INFO - Iter(train) [47850/80000]  base_lr: 1.0896e-04 lr: 1.0896e-04  eta: 14:34:23  time: 1.6268  data_time: 0.0101  memory: 6602  grad_norm: 6.6545  loss: 0.5064  decode.loss_ce: 0.3496  decode.acc_seg: 78.4435  aux.loss_ce: 0.1567  aux.acc_seg: 80.4931
2024/10/28 10:25:10 - mmengine - INFO - Iter(train) [47900/80000]  base_lr: 1.0882e-04 lr: 1.0882e-04  eta: 14:33:00  time: 1.6085  data_time: 0.0099  memory: 6598  grad_norm: 6.5098  loss: 0.5603  decode.loss_ce: 0.3850  decode.acc_seg: 83.1881  aux.loss_ce: 0.1753  aux.acc_seg: 82.9139
2024/10/28 10:26:31 - mmengine - INFO - Iter(train) [47950/80000]  base_lr: 1.0868e-04 lr: 1.0868e-04  eta: 14:31:38  time: 1.6099  data_time: 0.0104  memory: 6598  grad_norm: 5.4984  loss: 0.5544  decode.loss_ce: 0.3820  decode.acc_seg: 87.1863  aux.loss_ce: 0.1723  aux.acc_seg: 82.7431
2024/10/28 10:27:51 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 10:27:51 - mmengine - INFO - Iter(train) [48000/80000]  base_lr: 1.0854e-04 lr: 1.0854e-04  eta: 14:30:14  time: 1.6044  data_time: 0.0113  memory: 6598  grad_norm: 8.0653  loss: 0.6426  decode.loss_ce: 0.4348  decode.acc_seg: 78.1192  aux.loss_ce: 0.2078  aux.acc_seg: 79.8274
2024/10/28 10:27:52 - mmengine - INFO - Saving checkpoint at 48000 iterations
2024/10/28 10:27:57 - mmengine - INFO - Iter(val) [ 50/500]    eta: 0:00:13  time: 0.0284  data_time: 0.0013  memory: 1007  
2024/10/28 10:27:58 - mmengine - INFO - Iter(val) [100/500]    eta: 0:00:11  time: 0.0278  data_time: 0.0011  memory: 1077  
2024/10/28 10:28:00 - mmengine - INFO - Iter(val) [150/500]    eta: 0:00:10  time: 0.0284  data_time: 0.0012  memory: 792  
2024/10/28 10:28:01 - mmengine - INFO - Iter(val) [200/500]    eta: 0:00:08  time: 0.0282  data_time: 0.0012  memory: 825  
2024/10/28 10:28:03 - mmengine - INFO - Iter(val) [250/500]    eta: 0:00:07  time: 0.0284  data_time: 0.0013  memory: 865  
2024/10/28 10:28:04 - mmengine - INFO - Iter(val) [300/500]    eta: 0:00:05  time: 0.0286  data_time: 0.0014  memory: 1988  
2024/10/28 10:28:06 - mmengine - INFO - Iter(val) [350/500]    eta: 0:00:04  time: 0.0280  data_time: 0.0011  memory: 791  
2024/10/28 10:28:07 - mmengine - INFO - Iter(val) [400/500]    eta: 0:00:02  time: 0.0285  data_time: 0.0012  memory: 863  
2024/10/28 10:28:08 - mmengine - INFO - Iter(val) [450/500]    eta: 0:00:01  time: 0.0285  data_time: 0.0012  memory: 798  
2024/10/28 10:28:10 - mmengine - INFO - Iter(val) [500/500]    eta: 0:00:00  time: 0.0287  data_time: 0.0013  memory: 847  
2024/10/28 10:28:11 - mmengine - INFO - per class results:
2024/10/28 10:28:11 - mmengine - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 65.43 |  81.4 |
|       building      | 75.17 | 89.23 |
|         sky         | 88.58 | 95.18 |
|        floor        | 70.16 | 86.02 |
|         tree        | 65.04 | 82.44 |
|       ceiling       | 75.96 | 89.53 |
|         road        | 77.63 | 87.05 |
|         bed         | 77.44 | 86.62 |
|      windowpane     | 49.19 | 63.44 |
|        grass        | 61.83 | 79.72 |
|       cabinet       | 49.47 | 64.92 |
|       sidewalk      | 55.81 | 69.58 |
|        person       | 59.43 | 77.98 |
|        earth        | 28.46 | 38.13 |
|         door        |  33.2 | 47.58 |
|        table        | 41.94 | 56.49 |
|       mountain      | 48.43 | 64.89 |
|        plant        |  42.8 | 57.81 |
|       curtain       | 54.81 | 72.69 |
|        chair        | 37.47 | 46.86 |
|         car         |  68.8 | 81.28 |
|        water        | 47.29 | 63.36 |
|       painting      | 49.82 | 64.43 |
|         sofa        | 53.88 | 70.14 |
|        shelf        | 26.29 | 43.46 |
|        house        | 29.64 | 37.06 |
|         sea         | 46.88 | 75.86 |
|        mirror       | 51.82 | 59.56 |
|         rug         | 49.82 | 61.12 |
|        field        | 22.49 | 37.59 |
|       armchair      | 34.87 |  55.7 |
|         seat        | 55.02 | 74.27 |
|        fence        | 32.57 | 49.86 |
|         desk        | 34.22 | 50.82 |
|         rock        | 29.01 | 47.51 |
|       wardrobe      |  38.6 | 60.33 |
|         lamp        | 27.91 | 34.12 |
|       bathtub       |  65.1 |  78.5 |
|       railing       | 21.39 | 26.52 |
|       cushion       | 27.14 |  32.7 |
|         base        | 15.43 | 26.67 |
|         box         | 11.29 | 13.32 |
|        column       | 24.05 |  48.8 |
|      signboard      | 17.64 | 21.59 |
|   chest of drawers  |  34.0 | 45.03 |
|       counter       | 31.27 | 42.31 |
|         sand        | 32.65 | 45.51 |
|         sink        | 51.07 | 59.65 |
|      skyscraper     | 43.92 | 53.59 |
|      fireplace      | 60.03 | 70.89 |
|     refrigerator    | 61.23 | 74.48 |
|      grandstand     | 32.42 | 66.87 |
|         path        | 12.87 |  26.9 |
|        stairs       | 25.75 | 32.17 |
|        runway       |  56.2 | 76.77 |
|         case        | 37.92 | 65.79 |
|      pool table     | 72.81 | 82.22 |
|        pillow       | 35.91 | 44.55 |
|     screen door     | 54.37 | 58.82 |
|       stairway      | 25.25 | 31.96 |
|        river        | 11.91 | 22.89 |
|        bridge       | 22.32 | 29.56 |
|       bookcase      | 28.71 | 44.49 |
|        blind        | 29.44 | 36.81 |
|     coffee table    | 49.01 | 66.67 |
|        toilet       |  52.0 | 65.58 |
|        flower       | 22.61 | 36.92 |
|         book        | 29.32 | 42.54 |
|         hill        |  9.22 | 21.61 |
|        bench        | 34.67 | 46.55 |
|      countertop     | 44.59 | 54.48 |
|        stove        |  60.1 | 70.09 |
|         palm        | 34.34 | 46.77 |
|    kitchen island   | 25.66 | 52.32 |
|       computer      | 30.95 | 36.13 |
|     swivel chair    | 34.22 | 51.51 |
|         boat        | 40.77 | 74.25 |
|         bar         | 35.92 | 38.47 |
|    arcade machine   | 56.89 | 65.43 |
|        hovel        | 35.85 | 42.22 |
|         bus         | 49.57 | 73.17 |
|        towel        | 32.69 | 39.85 |
|        light        |  9.26 | 10.14 |
|        truck        |  4.93 |  5.92 |
|        tower        | 29.49 | 76.75 |
|      chandelier     | 40.51 | 51.18 |
|        awning       | 11.55 | 13.45 |
|     streetlight     |  3.41 |  4.04 |
|        booth        | 22.72 | 69.04 |
| television receiver | 52.19 | 64.96 |
|       airplane      |  42.7 | 51.52 |
|      dirt track     |  3.95 | 35.39 |
|       apparel       | 27.16 | 33.95 |
|         pole        |  7.01 | 11.53 |
|         land        |  2.03 |  2.7  |
|      bannister      |  0.38 |  0.48 |
|      escalator      | 21.84 | 29.54 |
|       ottoman       | 28.48 | 41.66 |
|        bottle       | 25.57 | 39.74 |
|        buffet       | 43.51 |  46.9 |
|        poster       |  9.28 | 11.59 |
|        stage        | 10.76 | 20.75 |
|         van         | 22.73 | 27.28 |
|         ship        | 15.38 | 18.05 |
|       fountain      | 17.32 | 17.94 |
|    conveyer belt    |  58.6 |  77.2 |
|        canopy       | 18.68 | 26.86 |
|        washer       | 53.62 | 59.77 |
|      plaything      |  7.72 | 11.19 |
|    swimming pool    | 68.84 | 73.37 |
|        stool        |  17.1 | 27.41 |
|        barrel       | 20.66 | 65.07 |
|        basket       | 15.04 | 18.76 |
|      waterfall      | 24.62 | 34.96 |
|         tent        | 78.18 |  92.5 |
|         bag         |  4.56 |  5.43 |
|       minibike      | 44.86 | 63.04 |
|        cradle       | 65.29 | 85.58 |
|         oven        | 24.01 | 51.14 |
|         ball        | 28.59 | 32.31 |
|         food        | 23.26 | 27.14 |
|         step        |  1.61 |  1.78 |
|         tank        | 33.23 | 34.77 |
|      trade name     |  9.5  | 10.17 |
|      microwave      |  31.0 | 34.28 |
|         pot         | 18.87 | 21.07 |
|        animal       | 40.01 | 47.31 |
|       bicycle       | 32.67 | 55.95 |
|         lake        | 49.84 | 60.45 |
|      dishwasher     | 47.49 |  54.5 |
|        screen       | 52.75 | 66.34 |
|       blanket       |  1.21 |  1.36 |
|      sculpture      | 36.39 | 43.21 |
|         hood        | 41.33 | 48.18 |
|        sconce       |  12.1 | 12.63 |
|         vase        |  14.9 | 20.98 |
|    traffic light    | 11.35 | 16.61 |
|         tray        |  0.61 |  1.14 |
|        ashcan       | 17.52 | 27.03 |
|         fan         | 24.91 | 33.51 |
|         pier        | 22.44 | 28.32 |
|      crt screen     |  9.36 | 13.32 |
|        plate        | 16.74 | 20.51 |
|       monitor       |  8.98 | 10.54 |
|    bulletin board   |  28.0 | 33.69 |
|        shower       |  0.0  |  0.0  |
|       radiator      | 28.66 | 33.97 |
|        glass        |  2.82 |  3.02 |
|        clock        |  6.68 |  8.37 |
|         flag        | 22.58 | 23.06 |
+---------------------+-------+-------+
2024/10/28 10:28:11 - mmengine - INFO - Iter(val) [500/500]    aAcc: 74.9600  mIoU: 34.0500  mAcc: 45.2700  data_time: 0.0013  time: 0.0284
2024/10/28 10:29:32 - mmengine - INFO - Iter(train) [48050/80000]  base_lr: 1.0840e-04 lr: 1.0840e-04  eta: 14:28:53  time: 1.6091  data_time: 0.0110  memory: 6600  grad_norm: 7.0932  loss: 0.6394  decode.loss_ce: 0.4365  decode.acc_seg: 82.7017  aux.loss_ce: 0.2029  aux.acc_seg: 82.4663
2024/10/28 10:30:52 - mmengine - INFO - Iter(train) [48100/80000]  base_lr: 1.0827e-04 lr: 1.0827e-04  eta: 14:27:30  time: 1.6065  data_time: 0.0112  memory: 6600  grad_norm: 6.2911  loss: 0.5953  decode.loss_ce: 0.4113  decode.acc_seg: 89.5361  aux.loss_ce: 0.1840  aux.acc_seg: 90.2505
2024/10/28 10:32:13 - mmengine - INFO - Iter(train) [48150/80000]  base_lr: 1.0812e-04 lr: 1.0812e-04  eta: 14:26:07  time: 1.6058  data_time: 0.0112  memory: 6598  grad_norm: 6.6444  loss: 0.6257  decode.loss_ce: 0.4195  decode.acc_seg: 90.5142  aux.loss_ce: 0.2062  aux.acc_seg: 84.3096
2024/10/28 10:33:33 - mmengine - INFO - Iter(train) [48200/80000]  base_lr: 1.0798e-04 lr: 1.0798e-04  eta: 14:24:44  time: 1.6083  data_time: 0.0110  memory: 6598  grad_norm: 6.6642  loss: 0.6899  decode.loss_ce: 0.4649  decode.acc_seg: 81.0620  aux.loss_ce: 0.2250  aux.acc_seg: 83.5870
2024/10/28 10:34:54 - mmengine - INFO - Iter(train) [48250/80000]  base_lr: 1.0784e-04 lr: 1.0784e-04  eta: 14:23:21  time: 1.6061  data_time: 0.0109  memory: 6600  grad_norm: 5.5166  loss: 0.5365  decode.loss_ce: 0.3672  decode.acc_seg: 80.4684  aux.loss_ce: 0.1693  aux.acc_seg: 77.0134
2024/10/28 10:36:14 - mmengine - INFO - Iter(train) [48300/80000]  base_lr: 1.0770e-04 lr: 1.0770e-04  eta: 14:21:58  time: 1.6060  data_time: 0.0109  memory: 6600  grad_norm: 4.5745  loss: 0.5383  decode.loss_ce: 0.3712  decode.acc_seg: 90.1550  aux.loss_ce: 0.1670  aux.acc_seg: 89.7131
2024/10/28 10:37:35 - mmengine - INFO - Iter(train) [48350/80000]  base_lr: 1.0756e-04 lr: 1.0756e-04  eta: 14:20:36  time: 1.6065  data_time: 0.0107  memory: 6598  grad_norm: 6.9015  loss: 0.6227  decode.loss_ce: 0.4123  decode.acc_seg: 82.6422  aux.loss_ce: 0.2104  aux.acc_seg: 77.0167
2024/10/28 10:38:56 - mmengine - INFO - Iter(train) [48400/80000]  base_lr: 1.0741e-04 lr: 1.0741e-04  eta: 14:19:13  time: 1.6090  data_time: 0.0110  memory: 6598  grad_norm: 6.5764  loss: 0.6047  decode.loss_ce: 0.4128  decode.acc_seg: 84.0841  aux.loss_ce: 0.1919  aux.acc_seg: 82.5442
2024/10/28 10:40:16 - mmengine - INFO - Iter(train) [48450/80000]  base_lr: 1.0727e-04 lr: 1.0727e-04  eta: 14:17:50  time: 1.6093  data_time: 0.0135  memory: 6600  grad_norm: 6.2603  loss: 0.6279  decode.loss_ce: 0.4231  decode.acc_seg: 78.0683  aux.loss_ce: 0.2049  aux.acc_seg: 71.9039
2024/10/28 10:41:37 - mmengine - INFO - Iter(train) [48500/80000]  base_lr: 1.0712e-04 lr: 1.0712e-04  eta: 14:16:28  time: 1.6137  data_time: 0.0140  memory: 6600  grad_norm: 5.9083  loss: 0.4887  decode.loss_ce: 0.3309  decode.acc_seg: 86.6932  aux.loss_ce: 0.1578  aux.acc_seg: 80.8158
2024/10/28 10:42:58 - mmengine - INFO - Iter(train) [48550/80000]  base_lr: 1.0698e-04 lr: 1.0698e-04  eta: 14:15:05  time: 1.6095  data_time: 0.0137  memory: 6601  grad_norm: 5.4057  loss: 0.5495  decode.loss_ce: 0.3739  decode.acc_seg: 78.3397  aux.loss_ce: 0.1756  aux.acc_seg: 76.3593
2024/10/28 10:44:19 - mmengine - INFO - Iter(train) [48600/80000]  base_lr: 1.0683e-04 lr: 1.0683e-04  eta: 14:13:42  time: 1.6089  data_time: 0.0136  memory: 6599  grad_norm: 8.4100  loss: 0.5865  decode.loss_ce: 0.4001  decode.acc_seg: 84.9354  aux.loss_ce: 0.1864  aux.acc_seg: 85.4991
2024/10/28 10:45:39 - mmengine - INFO - Iter(train) [48650/80000]  base_lr: 1.0668e-04 lr: 1.0668e-04  eta: 14:12:20  time: 1.6102  data_time: 0.0137  memory: 6599  grad_norm: 5.0701  loss: 0.5640  decode.loss_ce: 0.3750  decode.acc_seg: 85.9404  aux.loss_ce: 0.1889  aux.acc_seg: 85.7069
2024/10/28 10:47:00 - mmengine - INFO - Iter(train) [48700/80000]  base_lr: 1.0653e-04 lr: 1.0653e-04  eta: 14:10:57  time: 1.6081  data_time: 0.0137  memory: 6598  grad_norm: 4.2278  loss: 0.4682  decode.loss_ce: 0.3119  decode.acc_seg: 88.4711  aux.loss_ce: 0.1563  aux.acc_seg: 87.4948
2024/10/28 10:48:21 - mmengine - INFO - Iter(train) [48750/80000]  base_lr: 1.0638e-04 lr: 1.0638e-04  eta: 14:09:35  time: 1.6107  data_time: 0.0137  memory: 6598  grad_norm: 6.6469  loss: 0.5021  decode.loss_ce: 0.3396  decode.acc_seg: 88.2930  aux.loss_ce: 0.1626  aux.acc_seg: 87.9054
2024/10/28 10:49:42 - mmengine - INFO - Iter(train) [48800/80000]  base_lr: 1.0623e-04 lr: 1.0623e-04  eta: 14:08:12  time: 1.6250  data_time: 0.0134  memory: 6602  grad_norm: 5.4687  loss: 0.5337  decode.loss_ce: 0.3574  decode.acc_seg: 80.3898  aux.loss_ce: 0.1763  aux.acc_seg: 75.8625
2024/10/28 10:51:02 - mmengine - INFO - Iter(train) [48850/80000]  base_lr: 1.0608e-04 lr: 1.0608e-04  eta: 14:06:49  time: 1.6104  data_time: 0.0139  memory: 6600  grad_norm: 6.1221  loss: 0.5538  decode.loss_ce: 0.3809  decode.acc_seg: 83.2048  aux.loss_ce: 0.1730  aux.acc_seg: 84.7746
2024/10/28 10:52:28 - mmengine - INFO - Iter(train) [48900/80000]  base_lr: 1.0593e-04 lr: 1.0593e-04  eta: 14:05:33  time: 1.6103  data_time: 0.0136  memory: 6598  grad_norm: 5.2606  loss: 0.5070  decode.loss_ce: 0.3516  decode.acc_seg: 85.8054  aux.loss_ce: 0.1554  aux.acc_seg: 85.8672
2024/10/28 10:53:49 - mmengine - INFO - Iter(train) [48950/80000]  base_lr: 1.0578e-04 lr: 1.0578e-04  eta: 14:04:10  time: 1.6103  data_time: 0.0138  memory: 6599  grad_norm: 5.0096  loss: 0.5416  decode.loss_ce: 0.3686  decode.acc_seg: 79.2105  aux.loss_ce: 0.1730  aux.acc_seg: 78.4895
2024/10/28 10:55:09 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 10:55:09 - mmengine - INFO - Iter(train) [49000/80000]  base_lr: 1.0563e-04 lr: 1.0563e-04  eta: 14:02:47  time: 1.6114  data_time: 0.0139  memory: 6599  grad_norm: 5.8295  loss: 0.6038  decode.loss_ce: 0.4173  decode.acc_seg: 86.3710  aux.loss_ce: 0.1864  aux.acc_seg: 83.6684
2024/10/28 10:56:30 - mmengine - INFO - Iter(train) [49050/80000]  base_lr: 1.0547e-04 lr: 1.0547e-04  eta: 14:01:25  time: 1.6093  data_time: 0.0139  memory: 6599  grad_norm: 6.1734  loss: 0.5620  decode.loss_ce: 0.3806  decode.acc_seg: 81.1636  aux.loss_ce: 0.1814  aux.acc_seg: 81.3200
2024/10/28 10:57:51 - mmengine - INFO - Iter(train) [49100/80000]  base_lr: 1.0532e-04 lr: 1.0532e-04  eta: 14:00:02  time: 1.6141  data_time: 0.0144  memory: 6600  grad_norm: 8.8636  loss: 0.6542  decode.loss_ce: 0.4486  decode.acc_seg: 82.8851  aux.loss_ce: 0.2056  aux.acc_seg: 80.4438
2024/10/28 10:59:12 - mmengine - INFO - Iter(train) [49150/80000]  base_lr: 1.0517e-04 lr: 1.0517e-04  eta: 13:58:41  time: 1.6142  data_time: 0.0140  memory: 6599  grad_norm: 6.8736  loss: 0.5073  decode.loss_ce: 0.3361  decode.acc_seg: 88.2376  aux.loss_ce: 0.1712  aux.acc_seg: 78.9441
2024/10/28 11:00:33 - mmengine - INFO - Iter(train) [49200/80000]  base_lr: 1.0501e-04 lr: 1.0501e-04  eta: 13:57:18  time: 1.6124  data_time: 0.0141  memory: 6599  grad_norm: 5.6447  loss: 0.5426  decode.loss_ce: 0.3691  decode.acc_seg: 78.1215  aux.loss_ce: 0.1735  aux.acc_seg: 79.4426
2024/10/28 11:01:54 - mmengine - INFO - Iter(train) [49250/80000]  base_lr: 1.0485e-04 lr: 1.0485e-04  eta: 13:55:55  time: 1.6121  data_time: 0.0139  memory: 6598  grad_norm: 5.3084  loss: 0.5431  decode.loss_ce: 0.3799  decode.acc_seg: 91.8827  aux.loss_ce: 0.1632  aux.acc_seg: 90.1324
2024/10/28 11:03:15 - mmengine - INFO - Iter(train) [49300/80000]  base_lr: 1.0470e-04 lr: 1.0470e-04  eta: 13:54:34  time: 1.6111  data_time: 0.0140  memory: 6598  grad_norm: 6.6963  loss: 0.6218  decode.loss_ce: 0.4129  decode.acc_seg: 91.3660  aux.loss_ce: 0.2089  aux.acc_seg: 91.6173
2024/10/28 11:04:36 - mmengine - INFO - Iter(train) [49350/80000]  base_lr: 1.0454e-04 lr: 1.0454e-04  eta: 13:53:11  time: 1.6124  data_time: 0.0140  memory: 6599  grad_norm: 7.1628  loss: 0.4850  decode.loss_ce: 0.3338  decode.acc_seg: 91.5230  aux.loss_ce: 0.1513  aux.acc_seg: 92.6235
2024/10/28 11:05:57 - mmengine - INFO - Iter(train) [49400/80000]  base_lr: 1.0438e-04 lr: 1.0438e-04  eta: 13:51:49  time: 1.6138  data_time: 0.0138  memory: 6598  grad_norm: 5.0314  loss: 0.4758  decode.loss_ce: 0.3259  decode.acc_seg: 86.7504  aux.loss_ce: 0.1499  aux.acc_seg: 88.2236
2024/10/28 11:07:17 - mmengine - INFO - Iter(train) [49450/80000]  base_lr: 1.0422e-04 lr: 1.0422e-04  eta: 13:50:26  time: 1.6115  data_time: 0.0142  memory: 6599  grad_norm: 5.8625  loss: 0.5503  decode.loss_ce: 0.3638  decode.acc_seg: 82.1569  aux.loss_ce: 0.1865  aux.acc_seg: 77.4853
2024/10/28 11:08:38 - mmengine - INFO - Iter(train) [49500/80000]  base_lr: 1.0406e-04 lr: 1.0406e-04  eta: 13:49:04  time: 1.6124  data_time: 0.0141  memory: 6598  grad_norm: 7.6934  loss: 0.5872  decode.loss_ce: 0.3939  decode.acc_seg: 84.8039  aux.loss_ce: 0.1933  aux.acc_seg: 75.7983
2024/10/28 11:09:59 - mmengine - INFO - Iter(train) [49550/80000]  base_lr: 1.0390e-04 lr: 1.0390e-04  eta: 13:47:42  time: 1.6144  data_time: 0.0137  memory: 6599  grad_norm: 7.4846  loss: 0.6792  decode.loss_ce: 0.4554  decode.acc_seg: 82.5072  aux.loss_ce: 0.2238  aux.acc_seg: 76.0835
2024/10/28 11:11:20 - mmengine - INFO - Iter(train) [49600/80000]  base_lr: 1.0374e-04 lr: 1.0374e-04  eta: 13:46:19  time: 1.6081  data_time: 0.0134  memory: 6600  grad_norm: 7.9866  loss: 0.6089  decode.loss_ce: 0.4219  decode.acc_seg: 72.8986  aux.loss_ce: 0.1870  aux.acc_seg: 75.6504
2024/10/28 11:12:40 - mmengine - INFO - Iter(train) [49650/80000]  base_lr: 1.0358e-04 lr: 1.0358e-04  eta: 13:44:56  time: 1.6110  data_time: 0.0137  memory: 6600  grad_norm: 6.2153  loss: 0.5859  decode.loss_ce: 0.3985  decode.acc_seg: 87.6713  aux.loss_ce: 0.1874  aux.acc_seg: 77.7252
2024/10/28 11:14:01 - mmengine - INFO - Iter(train) [49700/80000]  base_lr: 1.0342e-04 lr: 1.0342e-04  eta: 13:43:34  time: 1.6110  data_time: 0.0133  memory: 6599  grad_norm: 5.3686  loss: 0.5522  decode.loss_ce: 0.3727  decode.acc_seg: 85.1444  aux.loss_ce: 0.1795  aux.acc_seg: 88.7140
2024/10/28 11:15:22 - mmengine - INFO - Iter(train) [49750/80000]  base_lr: 1.0325e-04 lr: 1.0325e-04  eta: 13:42:11  time: 1.6120  data_time: 0.0137  memory: 6598  grad_norm: 6.5489  loss: 0.6159  decode.loss_ce: 0.4218  decode.acc_seg: 84.7855  aux.loss_ce: 0.1941  aux.acc_seg: 85.1853
2024/10/28 11:16:43 - mmengine - INFO - Iter(train) [49800/80000]  base_lr: 1.0309e-04 lr: 1.0309e-04  eta: 13:40:49  time: 1.6082  data_time: 0.0129  memory: 6600  grad_norm: 4.9725  loss: 0.5925  decode.loss_ce: 0.4081  decode.acc_seg: 80.1688  aux.loss_ce: 0.1845  aux.acc_seg: 81.2676
2024/10/28 11:18:03 - mmengine - INFO - Iter(train) [49850/80000]  base_lr: 1.0293e-04 lr: 1.0293e-04  eta: 13:39:26  time: 1.6088  data_time: 0.0132  memory: 6600  grad_norm: 6.5158  loss: 0.5581  decode.loss_ce: 0.3778  decode.acc_seg: 83.1351  aux.loss_ce: 0.1803  aux.acc_seg: 85.0965
2024/10/28 11:19:26 - mmengine - INFO - Iter(train) [49900/80000]  base_lr: 1.0276e-04 lr: 1.0276e-04  eta: 13:38:06  time: 1.6102  data_time: 0.0130  memory: 6599  grad_norm: 8.0192  loss: 0.6479  decode.loss_ce: 0.4317  decode.acc_seg: 73.9739  aux.loss_ce: 0.2162  aux.acc_seg: 73.0915
2024/10/28 11:20:47 - mmengine - INFO - Iter(train) [49950/80000]  base_lr: 1.0260e-04 lr: 1.0260e-04  eta: 13:36:44  time: 1.6117  data_time: 0.0131  memory: 6599  grad_norm: 5.8384  loss: 0.5349  decode.loss_ce: 0.3677  decode.acc_seg: 86.5900  aux.loss_ce: 0.1672  aux.acc_seg: 84.5928
2024/10/28 11:22:07 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 11:22:07 - mmengine - INFO - Iter(train) [50000/80000]  base_lr: 1.0243e-04 lr: 1.0243e-04  eta: 13:35:21  time: 1.6093  data_time: 0.0127  memory: 6599  grad_norm: 6.8681  loss: 0.5364  decode.loss_ce: 0.3664  decode.acc_seg: 89.3816  aux.loss_ce: 0.1700  aux.acc_seg: 88.1032
2024/10/28 11:23:28 - mmengine - INFO - Iter(train) [50050/80000]  base_lr: 1.0226e-04 lr: 1.0226e-04  eta: 13:33:58  time: 1.6095  data_time: 0.0128  memory: 6598  grad_norm: 4.4595  loss: 0.5457  decode.loss_ce: 0.3837  decode.acc_seg: 85.0275  aux.loss_ce: 0.1620  aux.acc_seg: 84.3338
2024/10/28 11:24:48 - mmengine - INFO - Iter(train) [50100/80000]  base_lr: 1.0210e-04 lr: 1.0210e-04  eta: 13:32:36  time: 1.6094  data_time: 0.0136  memory: 6600  grad_norm: 4.5875  loss: 0.5736  decode.loss_ce: 0.3798  decode.acc_seg: 89.4877  aux.loss_ce: 0.1938  aux.acc_seg: 89.7999
2024/10/28 11:26:09 - mmengine - INFO - Iter(train) [50150/80000]  base_lr: 1.0193e-04 lr: 1.0193e-04  eta: 13:31:13  time: 1.6135  data_time: 0.0134  memory: 6598  grad_norm: 6.9270  loss: 0.5220  decode.loss_ce: 0.3478  decode.acc_seg: 86.9796  aux.loss_ce: 0.1741  aux.acc_seg: 87.3720
2024/10/28 11:27:30 - mmengine - INFO - Iter(train) [50200/80000]  base_lr: 1.0176e-04 lr: 1.0176e-04  eta: 13:29:51  time: 1.6117  data_time: 0.0131  memory: 6600  grad_norm: 6.9991  loss: 0.5304  decode.loss_ce: 0.3628  decode.acc_seg: 89.3348  aux.loss_ce: 0.1676  aux.acc_seg: 89.3616
2024/10/28 11:28:51 - mmengine - INFO - Iter(train) [50250/80000]  base_lr: 1.0159e-04 lr: 1.0159e-04  eta: 13:28:29  time: 1.6220  data_time: 0.0133  memory: 6599  grad_norm: 5.5482  loss: 0.5774  decode.loss_ce: 0.3875  decode.acc_seg: 87.2336  aux.loss_ce: 0.1899  aux.acc_seg: 89.3537
2024/10/28 11:30:12 - mmengine - INFO - Iter(train) [50300/80000]  base_lr: 1.0142e-04 lr: 1.0142e-04  eta: 13:27:07  time: 1.6113  data_time: 0.0135  memory: 6599  grad_norm: 4.6385  loss: 0.5153  decode.loss_ce: 0.3489  decode.acc_seg: 86.5440  aux.loss_ce: 0.1664  aux.acc_seg: 82.9537
2024/10/28 11:31:33 - mmengine - INFO - Iter(train) [50350/80000]  base_lr: 1.0125e-04 lr: 1.0125e-04  eta: 13:25:45  time: 1.6118  data_time: 0.0132  memory: 6598  grad_norm: 5.5391  loss: 0.5707  decode.loss_ce: 0.3901  decode.acc_seg: 82.2848  aux.loss_ce: 0.1807  aux.acc_seg: 79.8393
2024/10/28 11:32:54 - mmengine - INFO - Iter(train) [50400/80000]  base_lr: 1.0108e-04 lr: 1.0108e-04  eta: 13:24:23  time: 1.6098  data_time: 0.0133  memory: 6599  grad_norm: 6.2960  loss: 0.5702  decode.loss_ce: 0.3893  decode.acc_seg: 81.8924  aux.loss_ce: 0.1809  aux.acc_seg: 79.9559
2024/10/28 11:34:15 - mmengine - INFO - Iter(train) [50450/80000]  base_lr: 1.0090e-04 lr: 1.0090e-04  eta: 13:23:00  time: 1.6131  data_time: 0.0136  memory: 6599  grad_norm: 6.4833  loss: 0.5728  decode.loss_ce: 0.3884  decode.acc_seg: 89.1908  aux.loss_ce: 0.1843  aux.acc_seg: 88.1366
2024/10/28 11:35:36 - mmengine - INFO - Iter(train) [50500/80000]  base_lr: 1.0073e-04 lr: 1.0073e-04  eta: 13:21:38  time: 1.6139  data_time: 0.0138  memory: 6599  grad_norm: 5.3277  loss: 0.5655  decode.loss_ce: 0.3932  decode.acc_seg: 80.3829  aux.loss_ce: 0.1722  aux.acc_seg: 81.6284
2024/10/28 11:36:57 - mmengine - INFO - Iter(train) [50550/80000]  base_lr: 1.0056e-04 lr: 1.0056e-04  eta: 13:20:15  time: 1.6124  data_time: 0.0133  memory: 6599  grad_norm: 5.0990  loss: 0.5232  decode.loss_ce: 0.3595  decode.acc_seg: 91.5421  aux.loss_ce: 0.1637  aux.acc_seg: 91.1353
2024/10/28 11:38:17 - mmengine - INFO - Iter(train) [50600/80000]  base_lr: 1.0038e-04 lr: 1.0038e-04  eta: 13:18:53  time: 1.6104  data_time: 0.0139  memory: 6599  grad_norm: 5.7120  loss: 0.5452  decode.loss_ce: 0.3707  decode.acc_seg: 86.2364  aux.loss_ce: 0.1744  aux.acc_seg: 87.7985
2024/10/28 11:39:38 - mmengine - INFO - Iter(train) [50650/80000]  base_lr: 1.0021e-04 lr: 1.0021e-04  eta: 13:17:31  time: 1.6100  data_time: 0.0135  memory: 6599  grad_norm: 8.5784  loss: 0.5401  decode.loss_ce: 0.3764  decode.acc_seg: 90.0865  aux.loss_ce: 0.1637  aux.acc_seg: 90.1824
2024/10/28 11:40:59 - mmengine - INFO - Iter(train) [50700/80000]  base_lr: 1.0003e-04 lr: 1.0003e-04  eta: 13:16:08  time: 1.6092  data_time: 0.0138  memory: 6599  grad_norm: 4.8323  loss: 0.4973  decode.loss_ce: 0.3409  decode.acc_seg: 81.8335  aux.loss_ce: 0.1564  aux.acc_seg: 82.4676
2024/10/28 11:42:20 - mmengine - INFO - Iter(train) [50750/80000]  base_lr: 9.9859e-05 lr: 9.9859e-05  eta: 13:14:46  time: 1.6092  data_time: 0.0133  memory: 6600  grad_norm: 5.1811  loss: 0.5259  decode.loss_ce: 0.3472  decode.acc_seg: 88.4626  aux.loss_ce: 0.1787  aux.acc_seg: 84.3318
2024/10/28 11:43:40 - mmengine - INFO - Iter(train) [50800/80000]  base_lr: 9.9682e-05 lr: 9.9682e-05  eta: 13:13:24  time: 1.6091  data_time: 0.0137  memory: 6599  grad_norm: 6.1143  loss: 0.6540  decode.loss_ce: 0.4474  decode.acc_seg: 82.7467  aux.loss_ce: 0.2066  aux.acc_seg: 83.3224
2024/10/28 11:45:01 - mmengine - INFO - Iter(train) [50850/80000]  base_lr: 9.9505e-05 lr: 9.9505e-05  eta: 13:12:02  time: 1.6376  data_time: 0.0136  memory: 6598  grad_norm: 5.0682  loss: 0.5097  decode.loss_ce: 0.3592  decode.acc_seg: 86.2974  aux.loss_ce: 0.1506  aux.acc_seg: 87.5362
2024/10/28 11:46:22 - mmengine - INFO - Iter(train) [50900/80000]  base_lr: 9.9328e-05 lr: 9.9328e-05  eta: 13:10:39  time: 1.6084  data_time: 0.0116  memory: 6600  grad_norm: 5.8654  loss: 0.5718  decode.loss_ce: 0.3916  decode.acc_seg: 73.3988  aux.loss_ce: 0.1802  aux.acc_seg: 76.4111
2024/10/28 11:47:42 - mmengine - INFO - Iter(train) [50950/80000]  base_lr: 9.9149e-05 lr: 9.9149e-05  eta: 13:09:17  time: 1.6077  data_time: 0.0115  memory: 6599  grad_norm: 7.0524  loss: 0.5389  decode.loss_ce: 0.3580  decode.acc_seg: 83.7068  aux.loss_ce: 0.1810  aux.acc_seg: 84.4512
2024/10/28 11:49:03 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 11:49:03 - mmengine - INFO - Iter(train) [51000/80000]  base_lr: 9.8970e-05 lr: 9.8970e-05  eta: 13:07:54  time: 1.6079  data_time: 0.0115  memory: 6600  grad_norm: 5.4174  loss: 0.5044  decode.loss_ce: 0.3390  decode.acc_seg: 85.7929  aux.loss_ce: 0.1654  aux.acc_seg: 86.7007
2024/10/28 11:50:25 - mmengine - INFO - Iter(train) [51050/80000]  base_lr: 9.8791e-05 lr: 9.8791e-05  eta: 13:06:33  time: 1.6074  data_time: 0.0120  memory: 6598  grad_norm: 5.0289  loss: 0.5445  decode.loss_ce: 0.3659  decode.acc_seg: 85.0099  aux.loss_ce: 0.1786  aux.acc_seg: 85.8035
2024/10/28 11:51:46 - mmengine - INFO - Iter(train) [51100/80000]  base_lr: 9.8611e-05 lr: 9.8611e-05  eta: 13:05:11  time: 1.6077  data_time: 0.0111  memory: 6598  grad_norm: 5.2193  loss: 0.5447  decode.loss_ce: 0.3708  decode.acc_seg: 91.1137  aux.loss_ce: 0.1739  aux.acc_seg: 89.9914
2024/10/28 11:53:06 - mmengine - INFO - Iter(train) [51150/80000]  base_lr: 9.8430e-05 lr: 9.8430e-05  eta: 13:03:48  time: 1.6087  data_time: 0.0115  memory: 6599  grad_norm: 5.8609  loss: 0.5611  decode.loss_ce: 0.3902  decode.acc_seg: 87.4152  aux.loss_ce: 0.1709  aux.acc_seg: 85.2242
2024/10/28 11:54:27 - mmengine - INFO - Iter(train) [51200/80000]  base_lr: 9.8249e-05 lr: 9.8249e-05  eta: 13:02:25  time: 1.6092  data_time: 0.0115  memory: 6599  grad_norm: 5.1136  loss: 0.5106  decode.loss_ce: 0.3511  decode.acc_seg: 85.9522  aux.loss_ce: 0.1594  aux.acc_seg: 83.3252
2024/10/28 11:55:48 - mmengine - INFO - Iter(train) [51250/80000]  base_lr: 9.8067e-05 lr: 9.8067e-05  eta: 13:01:04  time: 1.6078  data_time: 0.0112  memory: 6600  grad_norm: 5.7776  loss: 0.5116  decode.loss_ce: 0.3482  decode.acc_seg: 82.5741  aux.loss_ce: 0.1634  aux.acc_seg: 83.3763
2024/10/28 11:57:08 - mmengine - INFO - Iter(train) [51300/80000]  base_lr: 9.7885e-05 lr: 9.7885e-05  eta: 12:59:41  time: 1.6094  data_time: 0.0114  memory: 6599  grad_norm: 6.9850  loss: 0.6517  decode.loss_ce: 0.4431  decode.acc_seg: 87.8178  aux.loss_ce: 0.2086  aux.acc_seg: 86.3416
2024/10/28 11:58:29 - mmengine - INFO - Iter(train) [51350/80000]  base_lr: 9.7702e-05 lr: 9.7702e-05  eta: 12:58:19  time: 1.6092  data_time: 0.0111  memory: 6598  grad_norm: 7.6623  loss: 0.6105  decode.loss_ce: 0.4164  decode.acc_seg: 85.2186  aux.loss_ce: 0.1941  aux.acc_seg: 80.3668
2024/10/28 11:59:50 - mmengine - INFO - Iter(train) [51400/80000]  base_lr: 9.7518e-05 lr: 9.7518e-05  eta: 12:56:56  time: 1.6093  data_time: 0.0114  memory: 6598  grad_norm: 7.5909  loss: 0.4860  decode.loss_ce: 0.3236  decode.acc_seg: 86.3797  aux.loss_ce: 0.1624  aux.acc_seg: 82.9886
2024/10/28 12:01:11 - mmengine - INFO - Iter(train) [51450/80000]  base_lr: 9.7334e-05 lr: 9.7334e-05  eta: 12:55:35  time: 1.6153  data_time: 0.0138  memory: 6599  grad_norm: 5.4851  loss: 0.5900  decode.loss_ce: 0.4008  decode.acc_seg: 91.7354  aux.loss_ce: 0.1892  aux.acc_seg: 86.7157
2024/10/28 12:02:32 - mmengine - INFO - Iter(train) [51500/80000]  base_lr: 9.7149e-05 lr: 9.7149e-05  eta: 12:54:12  time: 1.6335  data_time: 0.0136  memory: 6600  grad_norm: 5.3972  loss: 0.5630  decode.loss_ce: 0.3857  decode.acc_seg: 82.4134  aux.loss_ce: 0.1773  aux.acc_seg: 83.2702
2024/10/28 12:03:53 - mmengine - INFO - Iter(train) [51550/80000]  base_lr: 9.6964e-05 lr: 9.6964e-05  eta: 12:52:51  time: 1.6123  data_time: 0.0143  memory: 6598  grad_norm: 6.0632  loss: 0.5705  decode.loss_ce: 0.3832  decode.acc_seg: 78.5326  aux.loss_ce: 0.1873  aux.acc_seg: 77.2319
2024/10/28 12:05:14 - mmengine - INFO - Iter(train) [51600/80000]  base_lr: 9.6778e-05 lr: 9.6778e-05  eta: 12:51:28  time: 1.6164  data_time: 0.0143  memory: 6600  grad_norm: 5.2751  loss: 0.6420  decode.loss_ce: 0.4352  decode.acc_seg: 86.3266  aux.loss_ce: 0.2067  aux.acc_seg: 82.4263
2024/10/28 12:06:35 - mmengine - INFO - Iter(train) [51650/80000]  base_lr: 9.6592e-05 lr: 9.6592e-05  eta: 12:50:06  time: 1.6110  data_time: 0.0139  memory: 6600  grad_norm: 5.1991  loss: 0.4702  decode.loss_ce: 0.3191  decode.acc_seg: 90.9207  aux.loss_ce: 0.1511  aux.acc_seg: 91.4812
2024/10/28 12:07:55 - mmengine - INFO - Iter(train) [51700/80000]  base_lr: 9.6405e-05 lr: 9.6405e-05  eta: 12:48:44  time: 1.6153  data_time: 0.0138  memory: 6599  grad_norm: 6.4279  loss: 0.5456  decode.loss_ce: 0.3634  decode.acc_seg: 89.7513  aux.loss_ce: 0.1822  aux.acc_seg: 87.8516
2024/10/28 12:09:16 - mmengine - INFO - Iter(train) [51750/80000]  base_lr: 9.6217e-05 lr: 9.6217e-05  eta: 12:47:22  time: 1.6109  data_time: 0.0136  memory: 6599  grad_norm: 4.6781  loss: 0.5446  decode.loss_ce: 0.3784  decode.acc_seg: 85.0124  aux.loss_ce: 0.1662  aux.acc_seg: 83.2698
2024/10/28 12:10:37 - mmengine - INFO - Iter(train) [51800/80000]  base_lr: 9.6029e-05 lr: 9.6029e-05  eta: 12:46:00  time: 1.6111  data_time: 0.0135  memory: 6599  grad_norm: 6.9174  loss: 0.5104  decode.loss_ce: 0.3456  decode.acc_seg: 86.1837  aux.loss_ce: 0.1648  aux.acc_seg: 80.8731
2024/10/28 12:11:58 - mmengine - INFO - Iter(train) [51850/80000]  base_lr: 9.5840e-05 lr: 9.5840e-05  eta: 12:44:37  time: 1.6121  data_time: 0.0138  memory: 6598  grad_norm: 6.4796  loss: 0.5776  decode.loss_ce: 0.3891  decode.acc_seg: 86.9742  aux.loss_ce: 0.1885  aux.acc_seg: 86.6971
2024/10/28 12:13:19 - mmengine - INFO - Iter(train) [51900/80000]  base_lr: 9.5651e-05 lr: 9.5651e-05  eta: 12:43:15  time: 1.6109  data_time: 0.0137  memory: 6599  grad_norm: 5.1298  loss: 0.5648  decode.loss_ce: 0.3801  decode.acc_seg: 82.7336  aux.loss_ce: 0.1847  aux.acc_seg: 78.3322
2024/10/28 12:14:39 - mmengine - INFO - Iter(train) [51950/80000]  base_lr: 9.5461e-05 lr: 9.5461e-05  eta: 12:41:53  time: 1.6112  data_time: 0.0138  memory: 6600  grad_norm: 5.6827  loss: 0.4573  decode.loss_ce: 0.3122  decode.acc_seg: 88.7686  aux.loss_ce: 0.1452  aux.acc_seg: 81.5652
2024/10/28 12:16:00 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 12:16:00 - mmengine - INFO - Iter(train) [52000/80000]  base_lr: 9.5271e-05 lr: 9.5271e-05  eta: 12:40:31  time: 1.6125  data_time: 0.0145  memory: 6599  grad_norm: 5.4487  loss: 0.5680  decode.loss_ce: 0.3846  decode.acc_seg: 86.2355  aux.loss_ce: 0.1833  aux.acc_seg: 81.2616
2024/10/28 12:17:21 - mmengine - INFO - Iter(train) [52050/80000]  base_lr: 9.5080e-05 lr: 9.5080e-05  eta: 12:39:09  time: 1.6128  data_time: 0.0139  memory: 6599  grad_norm: 6.4833  loss: 0.5459  decode.loss_ce: 0.3679  decode.acc_seg: 82.7809  aux.loss_ce: 0.1781  aux.acc_seg: 82.1323
2024/10/28 12:18:42 - mmengine - INFO - Iter(train) [52100/80000]  base_lr: 9.4889e-05 lr: 9.4889e-05  eta: 12:37:47  time: 1.6097  data_time: 0.0134  memory: 6598  grad_norm: 5.6207  loss: 0.5041  decode.loss_ce: 0.3406  decode.acc_seg: 82.6509  aux.loss_ce: 0.1635  aux.acc_seg: 83.8352
2024/10/28 12:20:03 - mmengine - INFO - Iter(train) [52150/80000]  base_lr: 9.4697e-05 lr: 9.4697e-05  eta: 12:36:24  time: 1.6143  data_time: 0.0120  memory: 6598  grad_norm: 5.8656  loss: 0.4984  decode.loss_ce: 0.3420  decode.acc_seg: 85.5627  aux.loss_ce: 0.1564  aux.acc_seg: 86.7763
2024/10/28 12:21:26 - mmengine - INFO - Iter(train) [52200/80000]  base_lr: 9.4504e-05 lr: 9.4504e-05  eta: 12:35:05  time: 1.6075  data_time: 0.0118  memory: 6598  grad_norm: 4.8779  loss: 0.4954  decode.loss_ce: 0.3308  decode.acc_seg: 86.1142  aux.loss_ce: 0.1646  aux.acc_seg: 86.1023
2024/10/28 12:22:47 - mmengine - INFO - Iter(train) [52250/80000]  base_lr: 9.4311e-05 lr: 9.4311e-05  eta: 12:33:43  time: 1.6083  data_time: 0.0114  memory: 6598  grad_norm: 5.3024  loss: 0.5215  decode.loss_ce: 0.3629  decode.acc_seg: 83.5087  aux.loss_ce: 0.1586  aux.acc_seg: 81.0660
2024/10/28 12:24:07 - mmengine - INFO - Iter(train) [52300/80000]  base_lr: 9.4118e-05 lr: 9.4118e-05  eta: 12:32:20  time: 1.6100  data_time: 0.0113  memory: 6599  grad_norm: 5.5688  loss: 0.5122  decode.loss_ce: 0.3543  decode.acc_seg: 90.6301  aux.loss_ce: 0.1580  aux.acc_seg: 91.3837
2024/10/28 12:25:28 - mmengine - INFO - Iter(train) [52350/80000]  base_lr: 9.3924e-05 lr: 9.3924e-05  eta: 12:30:58  time: 1.6091  data_time: 0.0116  memory: 6599  grad_norm: 4.1241  loss: 0.5568  decode.loss_ce: 0.3831  decode.acc_seg: 83.7733  aux.loss_ce: 0.1737  aux.acc_seg: 84.8447
2024/10/28 12:26:49 - mmengine - INFO - Iter(train) [52400/80000]  base_lr: 9.3729e-05 lr: 9.3729e-05  eta: 12:29:36  time: 1.6105  data_time: 0.0111  memory: 6599  grad_norm: 5.3376  loss: 0.4934  decode.loss_ce: 0.3372  decode.acc_seg: 86.4366  aux.loss_ce: 0.1562  aux.acc_seg: 85.4806
2024/10/28 12:28:09 - mmengine - INFO - Iter(train) [52450/80000]  base_lr: 9.3534e-05 lr: 9.3534e-05  eta: 12:28:13  time: 1.6095  data_time: 0.0112  memory: 6599  grad_norm: 6.0864  loss: 0.4560  decode.loss_ce: 0.3055  decode.acc_seg: 85.7854  aux.loss_ce: 0.1505  aux.acc_seg: 71.0877
2024/10/28 12:29:30 - mmengine - INFO - Iter(train) [52500/80000]  base_lr: 9.3338e-05 lr: 9.3338e-05  eta: 12:26:51  time: 1.6096  data_time: 0.0115  memory: 6601  grad_norm: 4.4150  loss: 0.5468  decode.loss_ce: 0.3626  decode.acc_seg: 85.7372  aux.loss_ce: 0.1843  aux.acc_seg: 79.3338
2024/10/28 12:30:51 - mmengine - INFO - Iter(train) [52550/80000]  base_lr: 9.3142e-05 lr: 9.3142e-05  eta: 12:25:29  time: 1.6081  data_time: 0.0116  memory: 6598  grad_norm: 8.1754  loss: 0.5642  decode.loss_ce: 0.3837  decode.acc_seg: 78.7091  aux.loss_ce: 0.1805  aux.acc_seg: 77.0589
2024/10/28 12:32:11 - mmengine - INFO - Iter(train) [52600/80000]  base_lr: 9.2945e-05 lr: 9.2945e-05  eta: 12:24:07  time: 1.6069  data_time: 0.0119  memory: 6599  grad_norm: 5.8866  loss: 0.4795  decode.loss_ce: 0.3319  decode.acc_seg: 86.4989  aux.loss_ce: 0.1477  aux.acc_seg: 88.0250
2024/10/28 12:33:32 - mmengine - INFO - Iter(train) [52650/80000]  base_lr: 9.2748e-05 lr: 9.2748e-05  eta: 12:22:44  time: 1.6106  data_time: 0.0115  memory: 6598  grad_norm: 4.1862  loss: 0.5349  decode.loss_ce: 0.3675  decode.acc_seg: 86.6028  aux.loss_ce: 0.1674  aux.acc_seg: 86.5895
2024/10/28 12:34:53 - mmengine - INFO - Iter(train) [52700/80000]  base_lr: 9.2550e-05 lr: 9.2550e-05  eta: 12:21:22  time: 1.6096  data_time: 0.0106  memory: 6598  grad_norm: 5.3892  loss: 0.5160  decode.loss_ce: 0.3543  decode.acc_seg: 84.6780  aux.loss_ce: 0.1617  aux.acc_seg: 85.4990
2024/10/28 12:36:13 - mmengine - INFO - Iter(train) [52750/80000]  base_lr: 9.2352e-05 lr: 9.2352e-05  eta: 12:20:00  time: 1.6129  data_time: 0.0107  memory: 6598  grad_norm: 6.0265  loss: 0.5094  decode.loss_ce: 0.3398  decode.acc_seg: 85.1469  aux.loss_ce: 0.1696  aux.acc_seg: 80.5207
2024/10/28 12:37:34 - mmengine - INFO - Iter(train) [52800/80000]  base_lr: 9.2154e-05 lr: 9.2154e-05  eta: 12:18:38  time: 1.6101  data_time: 0.0106  memory: 6600  grad_norm: 4.6949  loss: 0.4565  decode.loss_ce: 0.3094  decode.acc_seg: 87.5717  aux.loss_ce: 0.1471  aux.acc_seg: 86.6855
2024/10/28 12:38:55 - mmengine - INFO - Iter(train) [52850/80000]  base_lr: 9.1954e-05 lr: 9.1954e-05  eta: 12:17:15  time: 1.6106  data_time: 0.0107  memory: 6598  grad_norm: 6.7662  loss: 0.6048  decode.loss_ce: 0.4065  decode.acc_seg: 83.9867  aux.loss_ce: 0.1982  aux.acc_seg: 80.3509
2024/10/28 12:40:16 - mmengine - INFO - Iter(train) [52900/80000]  base_lr: 9.1755e-05 lr: 9.1755e-05  eta: 12:15:53  time: 1.6127  data_time: 0.0108  memory: 6598  grad_norm: 9.0912  loss: 0.6592  decode.loss_ce: 0.4385  decode.acc_seg: 85.4860  aux.loss_ce: 0.2208  aux.acc_seg: 86.4605
2024/10/28 12:41:36 - mmengine - INFO - Iter(train) [52950/80000]  base_lr: 9.1555e-05 lr: 9.1555e-05  eta: 12:14:31  time: 1.6113  data_time: 0.0108  memory: 6600  grad_norm: 6.2401  loss: 0.5064  decode.loss_ce: 0.3477  decode.acc_seg: 88.1699  aux.loss_ce: 0.1586  aux.acc_seg: 88.2316
2024/10/28 12:42:57 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 12:42:57 - mmengine - INFO - Iter(train) [53000/80000]  base_lr: 9.1354e-05 lr: 9.1354e-05  eta: 12:13:09  time: 1.6106  data_time: 0.0105  memory: 6599  grad_norm: 4.8358  loss: 0.5556  decode.loss_ce: 0.3718  decode.acc_seg: 88.6964  aux.loss_ce: 0.1837  aux.acc_seg: 86.6209
2024/10/28 12:44:18 - mmengine - INFO - Iter(train) [53050/80000]  base_lr: 9.1153e-05 lr: 9.1153e-05  eta: 12:11:47  time: 1.6090  data_time: 0.0104  memory: 6599  grad_norm: 6.4378  loss: 0.5547  decode.loss_ce: 0.3765  decode.acc_seg: 86.4067  aux.loss_ce: 0.1782  aux.acc_seg: 87.8186
2024/10/28 12:45:38 - mmengine - INFO - Iter(train) [53100/80000]  base_lr: 9.0951e-05 lr: 9.0951e-05  eta: 12:10:25  time: 1.6227  data_time: 0.0104  memory: 6599  grad_norm: 4.9320  loss: 0.4585  decode.loss_ce: 0.3094  decode.acc_seg: 87.9797  aux.loss_ce: 0.1492  aux.acc_seg: 87.4882
2024/10/28 12:46:59 - mmengine - INFO - Iter(train) [53150/80000]  base_lr: 9.0749e-05 lr: 9.0749e-05  eta: 12:09:02  time: 1.6102  data_time: 0.0103  memory: 6599  grad_norm: 5.4238  loss: 0.5077  decode.loss_ce: 0.3497  decode.acc_seg: 84.6708  aux.loss_ce: 0.1580  aux.acc_seg: 84.2293
2024/10/28 12:48:19 - mmengine - INFO - Iter(train) [53200/80000]  base_lr: 9.0547e-05 lr: 9.0547e-05  eta: 12:07:40  time: 1.6112  data_time: 0.0106  memory: 6600  grad_norm: 7.5416  loss: 0.5034  decode.loss_ce: 0.3440  decode.acc_seg: 89.4665  aux.loss_ce: 0.1594  aux.acc_seg: 86.9987
2024/10/28 12:49:40 - mmengine - INFO - Iter(train) [53250/80000]  base_lr: 9.0344e-05 lr: 9.0344e-05  eta: 12:06:18  time: 1.6079  data_time: 0.0110  memory: 6598  grad_norm: 4.3491  loss: 0.5814  decode.loss_ce: 0.3963  decode.acc_seg: 81.7146  aux.loss_ce: 0.1851  aux.acc_seg: 83.0760
2024/10/28 12:51:01 - mmengine - INFO - Iter(train) [53300/80000]  base_lr: 9.0140e-05 lr: 9.0140e-05  eta: 12:04:56  time: 1.6106  data_time: 0.0107  memory: 6598  grad_norm: 4.6815  loss: 0.5272  decode.loss_ce: 0.3574  decode.acc_seg: 84.0720  aux.loss_ce: 0.1698  aux.acc_seg: 84.2035
2024/10/28 12:52:21 - mmengine - INFO - Iter(train) [53350/80000]  base_lr: 8.9936e-05 lr: 8.9936e-05  eta: 12:03:34  time: 1.6102  data_time: 0.0105  memory: 6598  grad_norm: 4.2370  loss: 0.5300  decode.loss_ce: 0.3672  decode.acc_seg: 83.6219  aux.loss_ce: 0.1627  aux.acc_seg: 81.0067
2024/10/28 12:53:42 - mmengine - INFO - Iter(train) [53400/80000]  base_lr: 8.9732e-05 lr: 8.9732e-05  eta: 12:02:11  time: 1.6099  data_time: 0.0105  memory: 6598  grad_norm: 6.2567  loss: 0.4614  decode.loss_ce: 0.3168  decode.acc_seg: 87.7145  aux.loss_ce: 0.1446  aux.acc_seg: 87.7981
2024/10/28 12:55:03 - mmengine - INFO - Iter(train) [53450/80000]  base_lr: 8.9527e-05 lr: 8.9527e-05  eta: 12:00:50  time: 1.6114  data_time: 0.0108  memory: 6599  grad_norm: 4.6959  loss: 0.4723  decode.loss_ce: 0.3175  decode.acc_seg: 79.0559  aux.loss_ce: 0.1548  aux.acc_seg: 77.5503
2024/10/28 12:56:26 - mmengine - INFO - Iter(train) [53500/80000]  base_lr: 8.9321e-05 lr: 8.9321e-05  eta: 11:59:30  time: 1.6092  data_time: 0.0107  memory: 6602  grad_norm: 5.3948  loss: 0.5219  decode.loss_ce: 0.3508  decode.acc_seg: 92.0504  aux.loss_ce: 0.1711  aux.acc_seg: 91.5927
2024/10/28 12:57:47 - mmengine - INFO - Iter(train) [53550/80000]  base_lr: 8.9116e-05 lr: 8.9116e-05  eta: 11:58:07  time: 1.6103  data_time: 0.0107  memory: 6600  grad_norm: 7.0223  loss: 0.4842  decode.loss_ce: 0.3303  decode.acc_seg: 92.7394  aux.loss_ce: 0.1539  aux.acc_seg: 91.4623
2024/10/28 12:59:08 - mmengine - INFO - Iter(train) [53600/80000]  base_lr: 8.8909e-05 lr: 8.8909e-05  eta: 11:56:45  time: 1.6106  data_time: 0.0106  memory: 6598  grad_norm: 5.1315  loss: 0.5646  decode.loss_ce: 0.3890  decode.acc_seg: 71.8418  aux.loss_ce: 0.1756  aux.acc_seg: 72.6385
2024/10/28 13:00:28 - mmengine - INFO - Iter(train) [53650/80000]  base_lr: 8.8703e-05 lr: 8.8703e-05  eta: 11:55:23  time: 1.6115  data_time: 0.0107  memory: 6599  grad_norm: 4.0779  loss: 0.5619  decode.loss_ce: 0.3757  decode.acc_seg: 85.8379  aux.loss_ce: 0.1863  aux.acc_seg: 82.2203
2024/10/28 13:01:49 - mmengine - INFO - Iter(train) [53700/80000]  base_lr: 8.8496e-05 lr: 8.8496e-05  eta: 11:54:01  time: 1.6074  data_time: 0.0107  memory: 6599  grad_norm: 6.1916  loss: 0.5198  decode.loss_ce: 0.3440  decode.acc_seg: 89.5176  aux.loss_ce: 0.1758  aux.acc_seg: 86.8341
2024/10/28 13:03:09 - mmengine - INFO - Iter(train) [53750/80000]  base_lr: 8.8288e-05 lr: 8.8288e-05  eta: 11:52:39  time: 1.6087  data_time: 0.0107  memory: 6599  grad_norm: 10.3448  loss: 0.6597  decode.loss_ce: 0.4683  decode.acc_seg: 86.0470  aux.loss_ce: 0.1913  aux.acc_seg: 87.8191
2024/10/28 13:04:32 - mmengine - INFO - Iter(train) [53800/80000]  base_lr: 8.8080e-05 lr: 8.8080e-05  eta: 11:51:18  time: 1.6089  data_time: 0.0105  memory: 6599  grad_norm: 4.8462  loss: 0.4672  decode.loss_ce: 0.3211  decode.acc_seg: 89.3379  aux.loss_ce: 0.1461  aux.acc_seg: 89.5749
2024/10/28 13:05:53 - mmengine - INFO - Iter(train) [53850/80000]  base_lr: 8.7872e-05 lr: 8.7872e-05  eta: 11:49:56  time: 1.6103  data_time: 0.0105  memory: 6598  grad_norm: 4.4470  loss: 0.4956  decode.loss_ce: 0.3269  decode.acc_seg: 91.2424  aux.loss_ce: 0.1687  aux.acc_seg: 90.6636
2024/10/28 13:07:14 - mmengine - INFO - Iter(train) [53900/80000]  base_lr: 8.7663e-05 lr: 8.7663e-05  eta: 11:48:35  time: 1.6109  data_time: 0.0108  memory: 6599  grad_norm: 4.1355  loss: 0.5032  decode.loss_ce: 0.3379  decode.acc_seg: 88.3572  aux.loss_ce: 0.1653  aux.acc_seg: 80.0041
2024/10/28 13:08:35 - mmengine - INFO - Iter(train) [53950/80000]  base_lr: 8.7453e-05 lr: 8.7453e-05  eta: 11:47:13  time: 1.6115  data_time: 0.0107  memory: 6598  grad_norm: 5.5844  loss: 0.5578  decode.loss_ce: 0.3836  decode.acc_seg: 81.8049  aux.loss_ce: 0.1742  aux.acc_seg: 80.1681
2024/10/28 13:09:56 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 13:09:56 - mmengine - INFO - Iter(train) [54000/80000]  base_lr: 8.7244e-05 lr: 8.7244e-05  eta: 11:45:51  time: 1.6112  data_time: 0.0113  memory: 6600  grad_norm: 5.9909  loss: 0.5359  decode.loss_ce: 0.3677  decode.acc_seg: 87.2128  aux.loss_ce: 0.1682  aux.acc_seg: 83.5803
2024/10/28 13:11:16 - mmengine - INFO - Iter(train) [54050/80000]  base_lr: 8.7033e-05 lr: 8.7033e-05  eta: 11:44:28  time: 1.6096  data_time: 0.0105  memory: 6600  grad_norm: 4.4856  loss: 0.5005  decode.loss_ce: 0.3324  decode.acc_seg: 88.8018  aux.loss_ce: 0.1681  aux.acc_seg: 85.1376
2024/10/28 13:12:37 - mmengine - INFO - Iter(train) [54100/80000]  base_lr: 8.6823e-05 lr: 8.6823e-05  eta: 11:43:06  time: 1.6124  data_time: 0.0110  memory: 6598  grad_norm: 6.2102  loss: 0.5039  decode.loss_ce: 0.3299  decode.acc_seg: 82.9253  aux.loss_ce: 0.1740  aux.acc_seg: 81.0805
2024/10/28 13:13:58 - mmengine - INFO - Iter(train) [54150/80000]  base_lr: 8.6612e-05 lr: 8.6612e-05  eta: 11:41:44  time: 1.6102  data_time: 0.0100  memory: 6598  grad_norm: 5.8237  loss: 0.5754  decode.loss_ce: 0.3865  decode.acc_seg: 83.9015  aux.loss_ce: 0.1890  aux.acc_seg: 85.3524
2024/10/28 13:15:18 - mmengine - INFO - Iter(train) [54200/80000]  base_lr: 8.6401e-05 lr: 8.6401e-05  eta: 11:40:22  time: 1.6147  data_time: 0.0101  memory: 6599  grad_norm: 5.4278  loss: 0.5890  decode.loss_ce: 0.3992  decode.acc_seg: 80.6565  aux.loss_ce: 0.1898  aux.acc_seg: 81.5083
2024/10/28 13:16:39 - mmengine - INFO - Iter(train) [54250/80000]  base_lr: 8.6189e-05 lr: 8.6189e-05  eta: 11:39:00  time: 1.6305  data_time: 0.0099  memory: 6598  grad_norm: 5.1298  loss: 0.4738  decode.loss_ce: 0.3291  decode.acc_seg: 89.3691  aux.loss_ce: 0.1447  aux.acc_seg: 89.9977
2024/10/28 13:18:00 - mmengine - INFO - Iter(train) [54300/80000]  base_lr: 8.5977e-05 lr: 8.5977e-05  eta: 11:37:38  time: 1.6085  data_time: 0.0101  memory: 6598  grad_norm: 5.1776  loss: 0.5636  decode.loss_ce: 0.3780  decode.acc_seg: 84.3193  aux.loss_ce: 0.1856  aux.acc_seg: 85.6067
2024/10/28 13:19:21 - mmengine - INFO - Iter(train) [54350/80000]  base_lr: 8.5764e-05 lr: 8.5764e-05  eta: 11:36:16  time: 1.6209  data_time: 0.0098  memory: 6599  grad_norm: 4.7373  loss: 0.5514  decode.loss_ce: 0.3663  decode.acc_seg: 77.2725  aux.loss_ce: 0.1851  aux.acc_seg: 76.4341
2024/10/28 13:20:42 - mmengine - INFO - Iter(train) [54400/80000]  base_lr: 8.5551e-05 lr: 8.5551e-05  eta: 11:34:54  time: 1.6082  data_time: 0.0119  memory: 6600  grad_norm: 4.9311  loss: 0.5763  decode.loss_ce: 0.4047  decode.acc_seg: 83.3402  aux.loss_ce: 0.1716  aux.acc_seg: 84.1144
2024/10/28 13:22:02 - mmengine - INFO - Iter(train) [54450/80000]  base_lr: 8.5338e-05 lr: 8.5338e-05  eta: 11:33:32  time: 1.6090  data_time: 0.0108  memory: 6598  grad_norm: 6.6795  loss: 0.5611  decode.loss_ce: 0.3773  decode.acc_seg: 82.3227  aux.loss_ce: 0.1838  aux.acc_seg: 81.3357
2024/10/28 13:23:26 - mmengine - INFO - Iter(train) [54500/80000]  base_lr: 8.5124e-05 lr: 8.5124e-05  eta: 11:32:12  time: 1.6100  data_time: 0.0108  memory: 6598  grad_norm: 5.9056  loss: 0.4884  decode.loss_ce: 0.3376  decode.acc_seg: 86.8915  aux.loss_ce: 0.1508  aux.acc_seg: 85.8646
2024/10/28 13:24:46 - mmengine - INFO - Iter(train) [54550/80000]  base_lr: 8.4910e-05 lr: 8.4910e-05  eta: 11:30:50  time: 1.6117  data_time: 0.0111  memory: 6599  grad_norm: 4.8791  loss: 0.4626  decode.loss_ce: 0.3116  decode.acc_seg: 90.5635  aux.loss_ce: 0.1510  aux.acc_seg: 89.3715
2024/10/28 13:26:07 - mmengine - INFO - Iter(train) [54600/80000]  base_lr: 8.4695e-05 lr: 8.4695e-05  eta: 11:29:28  time: 1.6103  data_time: 0.0109  memory: 6598  grad_norm: 5.7798  loss: 0.5199  decode.loss_ce: 0.3576  decode.acc_seg: 81.9592  aux.loss_ce: 0.1623  aux.acc_seg: 82.6757
2024/10/28 13:27:28 - mmengine - INFO - Iter(train) [54650/80000]  base_lr: 8.4480e-05 lr: 8.4480e-05  eta: 11:28:06  time: 1.6088  data_time: 0.0108  memory: 6598  grad_norm: 4.2551  loss: 0.5835  decode.loss_ce: 0.3952  decode.acc_seg: 87.7163  aux.loss_ce: 0.1883  aux.acc_seg: 85.3163
2024/10/28 13:28:48 - mmengine - INFO - Iter(train) [54700/80000]  base_lr: 8.4265e-05 lr: 8.4265e-05  eta: 11:26:44  time: 1.6102  data_time: 0.0111  memory: 6600  grad_norm: 5.5478  loss: 0.5676  decode.loss_ce: 0.4004  decode.acc_seg: 83.3074  aux.loss_ce: 0.1672  aux.acc_seg: 82.5084
2024/10/28 13:30:09 - mmengine - INFO - Iter(train) [54750/80000]  base_lr: 8.4049e-05 lr: 8.4049e-05  eta: 11:25:22  time: 1.6095  data_time: 0.0107  memory: 6600  grad_norm: 3.8852  loss: 0.5066  decode.loss_ce: 0.3384  decode.acc_seg: 85.5763  aux.loss_ce: 0.1682  aux.acc_seg: 84.0875
2024/10/28 13:31:29 - mmengine - INFO - Iter(train) [54800/80000]  base_lr: 8.3833e-05 lr: 8.3833e-05  eta: 11:24:00  time: 1.6086  data_time: 0.0104  memory: 6600  grad_norm: 7.8573  loss: 0.5089  decode.loss_ce: 0.3504  decode.acc_seg: 79.8585  aux.loss_ce: 0.1585  aux.acc_seg: 76.4289
2024/10/28 13:32:50 - mmengine - INFO - Iter(train) [54850/80000]  base_lr: 8.3617e-05 lr: 8.3617e-05  eta: 11:22:37  time: 1.6085  data_time: 0.0104  memory: 6599  grad_norm: 7.7806  loss: 0.4886  decode.loss_ce: 0.3329  decode.acc_seg: 90.9621  aux.loss_ce: 0.1557  aux.acc_seg: 89.4888
2024/10/28 13:34:11 - mmengine - INFO - Iter(train) [54900/80000]  base_lr: 8.3400e-05 lr: 8.3400e-05  eta: 11:21:16  time: 1.6099  data_time: 0.0104  memory: 6600  grad_norm: 7.4238  loss: 0.5835  decode.loss_ce: 0.3920  decode.acc_seg: 80.0154  aux.loss_ce: 0.1915  aux.acc_seg: 79.0037
2024/10/28 13:35:31 - mmengine - INFO - Iter(train) [54950/80000]  base_lr: 8.3183e-05 lr: 8.3183e-05  eta: 11:19:54  time: 1.6079  data_time: 0.0107  memory: 6600  grad_norm: 4.9628  loss: 0.3961  decode.loss_ce: 0.2765  decode.acc_seg: 84.6020  aux.loss_ce: 0.1196  aux.acc_seg: 83.3441
2024/10/28 13:36:52 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 13:36:52 - mmengine - INFO - Iter(train) [55000/80000]  base_lr: 8.2965e-05 lr: 8.2965e-05  eta: 11:18:32  time: 1.6090  data_time: 0.0106  memory: 6600  grad_norm: 6.3797  loss: 0.6168  decode.loss_ce: 0.4185  decode.acc_seg: 87.9312  aux.loss_ce: 0.1982  aux.acc_seg: 85.7820
2024/10/28 13:38:13 - mmengine - INFO - Iter(train) [55050/80000]  base_lr: 8.2748e-05 lr: 8.2748e-05  eta: 11:17:10  time: 1.6125  data_time: 0.0105  memory: 6599  grad_norm: 4.6052  loss: 0.5177  decode.loss_ce: 0.3561  decode.acc_seg: 81.3965  aux.loss_ce: 0.1616  aux.acc_seg: 79.9390
2024/10/28 13:39:33 - mmengine - INFO - Iter(train) [55100/80000]  base_lr: 8.2529e-05 lr: 8.2529e-05  eta: 11:15:48  time: 1.6114  data_time: 0.0105  memory: 6597  grad_norm: 4.4416  loss: 0.4830  decode.loss_ce: 0.3272  decode.acc_seg: 92.6964  aux.loss_ce: 0.1558  aux.acc_seg: 92.7460
2024/10/28 13:40:54 - mmengine - INFO - Iter(train) [55150/80000]  base_lr: 8.2311e-05 lr: 8.2311e-05  eta: 11:14:26  time: 1.6093  data_time: 0.0108  memory: 6598  grad_norm: 4.9265  loss: 0.4623  decode.loss_ce: 0.3161  decode.acc_seg: 87.3204  aux.loss_ce: 0.1462  aux.acc_seg: 85.9464
2024/10/28 13:42:15 - mmengine - INFO - Iter(train) [55200/80000]  base_lr: 8.2092e-05 lr: 8.2092e-05  eta: 11:13:03  time: 1.6067  data_time: 0.0105  memory: 6599  grad_norm: 4.6082  loss: 0.4689  decode.loss_ce: 0.3186  decode.acc_seg: 90.3035  aux.loss_ce: 0.1503  aux.acc_seg: 88.7140
2024/10/28 13:43:35 - mmengine - INFO - Iter(train) [55250/80000]  base_lr: 8.1873e-05 lr: 8.1873e-05  eta: 11:11:41  time: 1.6094  data_time: 0.0109  memory: 6598  grad_norm: 7.2275  loss: 0.5769  decode.loss_ce: 0.3931  decode.acc_seg: 86.3058  aux.loss_ce: 0.1838  aux.acc_seg: 86.2926
2024/10/28 13:44:56 - mmengine - INFO - Iter(train) [55300/80000]  base_lr: 8.1653e-05 lr: 8.1653e-05  eta: 11:10:20  time: 1.6103  data_time: 0.0104  memory: 6598  grad_norm: 4.9781  loss: 0.5382  decode.loss_ce: 0.3649  decode.acc_seg: 86.0700  aux.loss_ce: 0.1733  aux.acc_seg: 83.8463
2024/10/28 13:46:17 - mmengine - INFO - Iter(train) [55350/80000]  base_lr: 8.1433e-05 lr: 8.1433e-05  eta: 11:08:58  time: 1.6243  data_time: 0.0105  memory: 6598  grad_norm: 6.1253  loss: 0.4996  decode.loss_ce: 0.3384  decode.acc_seg: 86.9796  aux.loss_ce: 0.1612  aux.acc_seg: 86.7402
2024/10/28 13:47:38 - mmengine - INFO - Iter(train) [55400/80000]  base_lr: 8.1213e-05 lr: 8.1213e-05  eta: 11:07:36  time: 1.6087  data_time: 0.0111  memory: 6599  grad_norm: 5.8261  loss: 0.5250  decode.loss_ce: 0.3612  decode.acc_seg: 88.7849  aux.loss_ce: 0.1638  aux.acc_seg: 87.2243
2024/10/28 13:48:59 - mmengine - INFO - Iter(train) [55450/80000]  base_lr: 8.0992e-05 lr: 8.0992e-05  eta: 11:06:14  time: 1.6100  data_time: 0.0141  memory: 6600  grad_norm: 7.5426  loss: 0.5070  decode.loss_ce: 0.3349  decode.acc_seg: 92.6081  aux.loss_ce: 0.1721  aux.acc_seg: 89.1218
2024/10/28 13:50:20 - mmengine - INFO - Iter(train) [55500/80000]  base_lr: 8.0771e-05 lr: 8.0771e-05  eta: 11:04:52  time: 1.6361  data_time: 0.0138  memory: 6599  grad_norm: 7.3377  loss: 0.6675  decode.loss_ce: 0.4451  decode.acc_seg: 92.1080  aux.loss_ce: 0.2224  aux.acc_seg: 90.1957
2024/10/28 13:51:40 - mmengine - INFO - Iter(train) [55550/80000]  base_lr: 8.0550e-05 lr: 8.0550e-05  eta: 11:03:30  time: 1.6125  data_time: 0.0139  memory: 6600  grad_norm: 5.4802  loss: 0.4466  decode.loss_ce: 0.3033  decode.acc_seg: 87.5783  aux.loss_ce: 0.1433  aux.acc_seg: 86.7053
2024/10/28 13:53:01 - mmengine - INFO - Iter(train) [55600/80000]  base_lr: 8.0329e-05 lr: 8.0329e-05  eta: 11:02:08  time: 1.6349  data_time: 0.0137  memory: 6599  grad_norm: 5.6731  loss: 0.4483  decode.loss_ce: 0.3064  decode.acc_seg: 88.1663  aux.loss_ce: 0.1419  aux.acc_seg: 87.5580
2024/10/28 13:54:26 - mmengine - INFO - Iter(train) [55650/80000]  base_lr: 8.0107e-05 lr: 8.0107e-05  eta: 11:00:50  time: 1.6091  data_time: 0.0134  memory: 6600  grad_norm: 4.7671  loss: 0.5111  decode.loss_ce: 0.3531  decode.acc_seg: 84.7277  aux.loss_ce: 0.1580  aux.acc_seg: 86.1492
2024/10/28 13:55:48 - mmengine - INFO - Iter(train) [55700/80000]  base_lr: 7.9885e-05 lr: 7.9885e-05  eta: 10:59:28  time: 1.6122  data_time: 0.0138  memory: 6599  grad_norm: 4.7924  loss: 0.4718  decode.loss_ce: 0.3185  decode.acc_seg: 85.2730  aux.loss_ce: 0.1533  aux.acc_seg: 85.4074
2024/10/28 13:57:08 - mmengine - INFO - Iter(train) [55750/80000]  base_lr: 7.9662e-05 lr: 7.9662e-05  eta: 10:58:06  time: 1.6119  data_time: 0.0134  memory: 6598  grad_norm: 5.1561  loss: 0.4788  decode.loss_ce: 0.3294  decode.acc_seg: 86.9493  aux.loss_ce: 0.1495  aux.acc_seg: 86.0551
2024/10/28 13:58:29 - mmengine - INFO - Iter(train) [55800/80000]  base_lr: 7.9440e-05 lr: 7.9440e-05  eta: 10:56:44  time: 1.6106  data_time: 0.0131  memory: 6598  grad_norm: 4.4090  loss: 0.5046  decode.loss_ce: 0.3508  decode.acc_seg: 84.0978  aux.loss_ce: 0.1537  aux.acc_seg: 81.6805
2024/10/28 13:59:50 - mmengine - INFO - Iter(train) [55850/80000]  base_lr: 7.9216e-05 lr: 7.9216e-05  eta: 10:55:22  time: 1.6089  data_time: 0.0134  memory: 6601  grad_norm: 9.0990  loss: 0.4950  decode.loss_ce: 0.3279  decode.acc_seg: 86.5133  aux.loss_ce: 0.1672  aux.acc_seg: 81.3900
2024/10/28 14:01:10 - mmengine - INFO - Iter(train) [55900/80000]  base_lr: 7.8993e-05 lr: 7.8993e-05  eta: 10:54:00  time: 1.6136  data_time: 0.0134  memory: 6598  grad_norm: 3.5922  loss: 0.4710  decode.loss_ce: 0.3202  decode.acc_seg: 83.9866  aux.loss_ce: 0.1508  aux.acc_seg: 84.3626
2024/10/28 14:02:31 - mmengine - INFO - Iter(train) [55950/80000]  base_lr: 7.8769e-05 lr: 7.8769e-05  eta: 10:52:38  time: 1.6163  data_time: 0.0133  memory: 6599  grad_norm: 4.2627  loss: 0.5232  decode.loss_ce: 0.3481  decode.acc_seg: 89.2791  aux.loss_ce: 0.1750  aux.acc_seg: 86.1630
2024/10/28 14:03:52 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 14:03:52 - mmengine - INFO - Iter(train) [56000/80000]  base_lr: 7.8546e-05 lr: 7.8546e-05  eta: 10:51:16  time: 1.6112  data_time: 0.0133  memory: 6598  grad_norm: 5.8345  loss: 0.5212  decode.loss_ce: 0.3445  decode.acc_seg: 86.4380  aux.loss_ce: 0.1767  aux.acc_seg: 85.8583
2024/10/28 14:03:52 - mmengine - INFO - Saving checkpoint at 56000 iterations
2024/10/28 14:03:57 - mmengine - INFO - Iter(val) [ 50/500]    eta: 0:00:13  time: 0.0286  data_time: 0.0013  memory: 1007  
2024/10/28 14:03:58 - mmengine - INFO - Iter(val) [100/500]    eta: 0:00:11  time: 0.0295  data_time: 0.0014  memory: 1077  
2024/10/28 14:04:00 - mmengine - INFO - Iter(val) [150/500]    eta: 0:00:10  time: 0.0299  data_time: 0.0015  memory: 792  
2024/10/28 14:04:01 - mmengine - INFO - Iter(val) [200/500]    eta: 0:00:08  time: 0.0269  data_time: 0.0012  memory: 825  
2024/10/28 14:04:03 - mmengine - INFO - Iter(val) [250/500]    eta: 0:00:07  time: 0.0305  data_time: 0.0018  memory: 865  
2024/10/28 14:04:04 - mmengine - INFO - Iter(val) [300/500]    eta: 0:00:05  time: 0.0303  data_time: 0.0018  memory: 1988  
2024/10/28 14:04:06 - mmengine - INFO - Iter(val) [350/500]    eta: 0:00:04  time: 0.0297  data_time: 0.0017  memory: 791  
2024/10/28 14:04:07 - mmengine - INFO - Iter(val) [400/500]    eta: 0:00:02  time: 0.0277  data_time: 0.0011  memory: 863  
2024/10/28 14:04:08 - mmengine - INFO - Iter(val) [450/500]    eta: 0:00:01  time: 0.0278  data_time: 0.0010  memory: 798  
2024/10/28 14:04:10 - mmengine - INFO - Iter(val) [500/500]    eta: 0:00:00  time: 0.0275  data_time: 0.0011  memory: 847  
2024/10/28 14:04:11 - mmengine - INFO - per class results:
2024/10/28 14:04:11 - mmengine - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 66.58 | 84.64 |
|       building      | 77.07 | 89.08 |
|         sky         | 88.55 | 94.08 |
|        floor        | 69.29 | 85.46 |
|         tree        | 65.07 | 84.14 |
|       ceiling       | 76.75 | 87.07 |
|         road        | 77.88 | 86.19 |
|         bed         | 77.88 | 88.04 |
|      windowpane     | 48.65 | 65.78 |
|        grass        | 53.54 | 69.89 |
|       cabinet       | 49.25 | 63.14 |
|       sidewalk      |  55.6 | 73.68 |
|        person       | 59.98 | 78.23 |
|        earth        | 29.22 | 43.96 |
|         door        | 32.92 | 47.06 |
|        table        | 43.03 | 59.79 |
|       mountain      | 50.31 | 61.17 |
|        plant        | 41.16 |  51.0 |
|       curtain       | 54.35 | 66.21 |
|        chair        | 37.93 | 48.11 |
|         car         | 69.83 |  81.1 |
|        water        | 44.02 | 59.99 |
|       painting      |  50.2 | 64.64 |
|         sofa        | 56.08 |  72.9 |
|        shelf        | 33.34 | 47.47 |
|        house        | 44.72 | 55.58 |
|         sea         | 51.23 | 71.09 |
|        mirror       | 54.12 | 60.91 |
|         rug         | 41.95 | 52.58 |
|        field        |  21.8 | 35.76 |
|       armchair      | 39.63 | 63.24 |
|         seat        | 53.04 | 71.95 |
|        fence        |  31.8 | 43.39 |
|         desk        | 37.29 | 55.54 |
|         rock        | 35.65 | 51.03 |
|       wardrobe      | 41.68 |  67.2 |
|         lamp        | 29.41 | 37.61 |
|       bathtub       | 64.77 | 71.53 |
|       railing       | 25.66 | 35.25 |
|       cushion       | 36.08 | 45.65 |
|         base        |  5.06 |  7.88 |
|         box         | 10.96 | 17.97 |
|        column       | 26.19 | 39.16 |
|      signboard      | 18.86 | 25.43 |
|   chest of drawers  | 30.82 | 48.57 |
|       counter       | 23.52 | 30.32 |
|         sand        |  34.9 | 47.39 |
|         sink        | 49.54 | 61.05 |
|      skyscraper     | 55.79 | 77.18 |
|      fireplace      | 62.44 | 74.84 |
|     refrigerator    | 63.92 | 72.28 |
|      grandstand     | 47.24 | 69.99 |
|         path        | 15.07 | 27.46 |
|        stairs       | 16.23 | 20.49 |
|        runway       | 65.73 | 89.56 |
|         case        | 51.41 | 60.53 |
|      pool table     | 73.37 | 84.42 |
|        pillow       | 40.16 | 50.82 |
|     screen door     | 64.02 | 71.38 |
|       stairway      | 22.57 | 33.27 |
|        river        | 12.34 | 32.72 |
|        bridge       | 25.29 | 31.81 |
|       bookcase      |  31.5 | 56.04 |
|        blind        |  19.7 |  21.9 |
|     coffee table    | 43.55 | 62.96 |
|        toilet       | 61.98 | 75.03 |
|        flower       | 21.82 |  31.0 |
|         book        | 27.64 | 37.91 |
|         hill        |  8.51 |  15.9 |
|        bench        | 33.76 | 46.49 |
|      countertop     | 46.39 | 61.89 |
|        stove        | 55.89 | 75.05 |
|         palm        | 28.37 | 51.49 |
|    kitchen island   | 25.14 | 52.85 |
|       computer      | 43.81 | 51.17 |
|     swivel chair    | 33.29 | 51.52 |
|         boat        | 50.67 | 74.06 |
|         bar         |  28.8 | 36.23 |
|    arcade machine   |  51.6 | 56.66 |
|        hovel        | 26.07 | 29.06 |
|         bus         | 55.14 | 66.01 |
|        towel        | 36.84 | 44.09 |
|        light        |  9.52 | 10.79 |
|        truck        |  5.96 |  8.98 |
|        tower        | 29.76 | 63.42 |
|      chandelier     | 44.11 | 56.13 |
|        awning       | 11.92 |  13.4 |
|     streetlight     |  3.68 |  4.12 |
|        booth        | 40.87 | 43.88 |
| television receiver | 46.95 | 64.58 |
|       airplane      | 34.11 | 45.61 |
|      dirt track     |  5.9  | 30.45 |
|       apparel       | 29.67 | 37.63 |
|         pole        |  6.34 | 11.48 |
|         land        |  1.3  |  1.87 |
|      bannister      |  0.37 |  0.43 |
|      escalator      | 11.24 | 13.58 |
|       ottoman       | 27.88 | 37.68 |
|        bottle       | 16.97 | 21.93 |
|        buffet       | 31.43 | 32.14 |
|        poster       | 28.02 |  34.3 |
|        stage        | 11.13 | 22.69 |
|         van         | 21.87 | 28.95 |
|         ship        |  2.42 |  3.3  |
|       fountain      | 19.95 | 20.67 |
|    conveyer belt    | 56.32 | 86.67 |
|        canopy       | 27.52 | 48.24 |
|        washer       |  55.7 |  58.2 |
|      plaything      |  7.5  | 12.98 |
|    swimming pool    | 46.63 | 56.17 |
|        stool        | 26.41 | 35.77 |
|        barrel       | 11.44 | 63.32 |
|        basket       | 12.51 | 15.62 |
|      waterfall      | 32.88 | 49.97 |
|         tent        | 72.85 | 89.01 |
|         bag         |  6.69 |  9.11 |
|       minibike      | 34.94 | 55.33 |
|        cradle       | 63.47 | 87.87 |
|         oven        |  20.6 | 41.69 |
|         ball        | 32.48 | 50.11 |
|         food        | 27.62 | 36.81 |
|         step        |  5.27 |  5.81 |
|         tank        | 40.85 | 45.33 |
|      trade name     | 10.67 |  11.6 |
|      microwave      | 31.85 | 37.37 |
|         pot         | 26.43 | 30.83 |
|        animal       | 31.02 | 41.24 |
|       bicycle       | 25.52 |  55.9 |
|         lake        | 64.13 | 65.75 |
|      dishwasher     | 37.88 |  41.0 |
|        screen       | 54.33 | 61.98 |
|       blanket       |  1.01 |  1.13 |
|      sculpture      | 31.41 | 47.85 |
|         hood        | 42.62 | 50.27 |
|        sconce       | 14.06 | 14.99 |
|         vase        | 11.96 | 16.79 |
|    traffic light    | 13.21 | 18.61 |
|         tray        |  1.23 |  2.44 |
|        ashcan       |  21.7 | 27.98 |
|         fan         | 30.46 | 41.64 |
|         pier        |  9.56 |  16.8 |
|      crt screen     |  12.6 | 32.18 |
|        plate        | 16.54 | 22.65 |
|       monitor       |  2.16 |  2.61 |
|    bulletin board   | 25.56 |  29.4 |
|        shower       |  0.0  |  0.0  |
|       radiator      | 35.64 |  40.9 |
|        glass        |  1.18 |  1.28 |
|        clock        |  6.69 |  8.37 |
|         flag        | 24.48 | 25.75 |
+---------------------+-------+-------+
2024/10/28 14:04:11 - mmengine - INFO - Iter(val) [500/500]    aAcc: 75.3500  mIoU: 34.4700  mAcc: 45.6400  data_time: 0.0014  time: 0.0287
2024/10/28 14:05:32 - mmengine - INFO - Iter(train) [56050/80000]  base_lr: 7.8321e-05 lr: 7.8321e-05  eta: 10:49:56  time: 1.6076  data_time: 0.0108  memory: 6600  grad_norm: 4.9502  loss: 0.5121  decode.loss_ce: 0.3558  decode.acc_seg: 88.2632  aux.loss_ce: 0.1563  aux.acc_seg: 90.4822
2024/10/28 14:06:52 - mmengine - INFO - Iter(train) [56100/80000]  base_lr: 7.8097e-05 lr: 7.8097e-05  eta: 10:48:33  time: 1.6052  data_time: 0.0107  memory: 6600  grad_norm: 5.4222  loss: 0.5681  decode.loss_ce: 0.3822  decode.acc_seg: 90.6929  aux.loss_ce: 0.1859  aux.acc_seg: 89.6565
2024/10/28 14:08:13 - mmengine - INFO - Iter(train) [56150/80000]  base_lr: 7.7872e-05 lr: 7.7872e-05  eta: 10:47:11  time: 1.6058  data_time: 0.0111  memory: 6599  grad_norm: 6.3381  loss: 0.5423  decode.loss_ce: 0.3721  decode.acc_seg: 88.3614  aux.loss_ce: 0.1701  aux.acc_seg: 88.7018
2024/10/28 14:09:33 - mmengine - INFO - Iter(train) [56200/80000]  base_lr: 7.7647e-05 lr: 7.7647e-05  eta: 10:45:49  time: 1.6022  data_time: 0.0110  memory: 6599  grad_norm: 5.4375  loss: 0.5354  decode.loss_ce: 0.3713  decode.acc_seg: 73.5416  aux.loss_ce: 0.1641  aux.acc_seg: 76.1145
2024/10/28 14:10:53 - mmengine - INFO - Iter(train) [56250/80000]  base_lr: 7.7422e-05 lr: 7.7422e-05  eta: 10:44:27  time: 1.6016  data_time: 0.0108  memory: 6599  grad_norm: 6.4343  loss: 0.5568  decode.loss_ce: 0.3794  decode.acc_seg: 86.8824  aux.loss_ce: 0.1774  aux.acc_seg: 84.8246
2024/10/28 14:12:14 - mmengine - INFO - Iter(train) [56300/80000]  base_lr: 7.7196e-05 lr: 7.7196e-05  eta: 10:43:05  time: 1.6147  data_time: 0.0107  memory: 6599  grad_norm: 4.8892  loss: 0.5235  decode.loss_ce: 0.3613  decode.acc_seg: 83.1659  aux.loss_ce: 0.1622  aux.acc_seg: 80.9580
2024/10/28 14:13:34 - mmengine - INFO - Iter(train) [56350/80000]  base_lr: 7.6970e-05 lr: 7.6970e-05  eta: 10:41:43  time: 1.6008  data_time: 0.0111  memory: 6598  grad_norm: 4.0791  loss: 0.5254  decode.loss_ce: 0.3537  decode.acc_seg: 86.6784  aux.loss_ce: 0.1717  aux.acc_seg: 83.9683
2024/10/28 14:14:55 - mmengine - INFO - Iter(train) [56400/80000]  base_lr: 7.6744e-05 lr: 7.6744e-05  eta: 10:40:20  time: 1.6013  data_time: 0.0112  memory: 6600  grad_norm: 8.6000  loss: 0.5651  decode.loss_ce: 0.3786  decode.acc_seg: 87.5216  aux.loss_ce: 0.1866  aux.acc_seg: 85.5765
2024/10/28 14:16:15 - mmengine - INFO - Iter(train) [56450/80000]  base_lr: 7.6518e-05 lr: 7.6518e-05  eta: 10:38:58  time: 1.6019  data_time: 0.0113  memory: 6599  grad_norm: 5.3332  loss: 0.4943  decode.loss_ce: 0.3262  decode.acc_seg: 80.1842  aux.loss_ce: 0.1681  aux.acc_seg: 76.4478
2024/10/28 14:17:35 - mmengine - INFO - Iter(train) [56500/80000]  base_lr: 7.6291e-05 lr: 7.6291e-05  eta: 10:37:36  time: 1.6029  data_time: 0.0111  memory: 6599  grad_norm: 6.0632  loss: 0.4332  decode.loss_ce: 0.2837  decode.acc_seg: 86.9529  aux.loss_ce: 0.1496  aux.acc_seg: 85.6038
2024/10/28 14:18:55 - mmengine - INFO - Iter(train) [56550/80000]  base_lr: 7.6064e-05 lr: 7.6064e-05  eta: 10:36:14  time: 1.6018  data_time: 0.0111  memory: 6600  grad_norm: 5.0827  loss: 0.5898  decode.loss_ce: 0.3976  decode.acc_seg: 85.5152  aux.loss_ce: 0.1922  aux.acc_seg: 83.1618
2024/10/28 14:20:15 - mmengine - INFO - Iter(train) [56600/80000]  base_lr: 7.5837e-05 lr: 7.5837e-05  eta: 10:34:51  time: 1.6004  data_time: 0.0112  memory: 6599  grad_norm: 5.5597  loss: 0.4598  decode.loss_ce: 0.3139  decode.acc_seg: 88.2853  aux.loss_ce: 0.1459  aux.acc_seg: 86.2449
2024/10/28 14:21:36 - mmengine - INFO - Iter(train) [56650/80000]  base_lr: 7.5610e-05 lr: 7.5610e-05  eta: 10:33:29  time: 1.6107  data_time: 0.0138  memory: 6599  grad_norm: 5.2605  loss: 0.5123  decode.loss_ce: 0.3475  decode.acc_seg: 91.2595  aux.loss_ce: 0.1648  aux.acc_seg: 84.5973
2024/10/28 14:22:56 - mmengine - INFO - Iter(train) [56700/80000]  base_lr: 7.5382e-05 lr: 7.5382e-05  eta: 10:32:07  time: 1.6115  data_time: 0.0138  memory: 6598  grad_norm: 5.1801  loss: 0.4153  decode.loss_ce: 0.2823  decode.acc_seg: 86.8189  aux.loss_ce: 0.1330  aux.acc_seg: 87.2088
2024/10/28 14:24:17 - mmengine - INFO - Iter(train) [56750/80000]  base_lr: 7.5154e-05 lr: 7.5154e-05  eta: 10:30:45  time: 1.6099  data_time: 0.0135  memory: 6599  grad_norm: 3.7601  loss: 0.5315  decode.loss_ce: 0.3542  decode.acc_seg: 82.8827  aux.loss_ce: 0.1773  aux.acc_seg: 82.7050
2024/10/28 14:25:38 - mmengine - INFO - Iter(train) [56800/80000]  base_lr: 7.4926e-05 lr: 7.4926e-05  eta: 10:29:24  time: 1.6095  data_time: 0.0137  memory: 6600  grad_norm: 6.0475  loss: 0.4828  decode.loss_ce: 0.3330  decode.acc_seg: 81.2041  aux.loss_ce: 0.1499  aux.acc_seg: 73.0160
2024/10/28 14:26:59 - mmengine - INFO - Iter(train) [56850/80000]  base_lr: 7.4698e-05 lr: 7.4698e-05  eta: 10:28:02  time: 1.6110  data_time: 0.0134  memory: 6600  grad_norm: 4.4603  loss: 0.4683  decode.loss_ce: 0.3195  decode.acc_seg: 84.1885  aux.loss_ce: 0.1488  aux.acc_seg: 79.9796
2024/10/28 14:28:19 - mmengine - INFO - Iter(train) [56900/80000]  base_lr: 7.4469e-05 lr: 7.4469e-05  eta: 10:26:40  time: 1.6078  data_time: 0.0130  memory: 6599  grad_norm: 4.6521  loss: 0.4796  decode.loss_ce: 0.3298  decode.acc_seg: 88.0554  aux.loss_ce: 0.1499  aux.acc_seg: 89.7576
2024/10/28 14:29:40 - mmengine - INFO - Iter(train) [56950/80000]  base_lr: 7.4240e-05 lr: 7.4240e-05  eta: 10:25:18  time: 1.6109  data_time: 0.0134  memory: 6598  grad_norm: 7.0609  loss: 0.5272  decode.loss_ce: 0.3582  decode.acc_seg: 87.8080  aux.loss_ce: 0.1690  aux.acc_seg: 89.4658
2024/10/28 14:31:01 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 14:31:01 - mmengine - INFO - Iter(train) [57000/80000]  base_lr: 7.4011e-05 lr: 7.4011e-05  eta: 10:23:56  time: 1.6216  data_time: 0.0135  memory: 6604  grad_norm: 6.0510  loss: 0.5639  decode.loss_ce: 0.3744  decode.acc_seg: 85.1177  aux.loss_ce: 0.1894  aux.acc_seg: 83.3229
2024/10/28 14:32:22 - mmengine - INFO - Iter(train) [57050/80000]  base_lr: 7.3782e-05 lr: 7.3782e-05  eta: 10:22:34  time: 1.6079  data_time: 0.0136  memory: 6600  grad_norm: 5.5724  loss: 0.4936  decode.loss_ce: 0.3293  decode.acc_seg: 84.4019  aux.loss_ce: 0.1643  aux.acc_seg: 83.2286
2024/10/28 14:33:42 - mmengine - INFO - Iter(train) [57100/80000]  base_lr: 7.3553e-05 lr: 7.3553e-05  eta: 10:21:12  time: 1.6114  data_time: 0.0133  memory: 6598  grad_norm: 6.1440  loss: 0.4568  decode.loss_ce: 0.2999  decode.acc_seg: 91.0377  aux.loss_ce: 0.1570  aux.acc_seg: 90.0326
2024/10/28 14:35:03 - mmengine - INFO - Iter(train) [57150/80000]  base_lr: 7.3323e-05 lr: 7.3323e-05  eta: 10:19:51  time: 1.6090  data_time: 0.0129  memory: 6599  grad_norm: 4.6518  loss: 0.4880  decode.loss_ce: 0.3283  decode.acc_seg: 86.7152  aux.loss_ce: 0.1598  aux.acc_seg: 85.8284
2024/10/28 14:36:26 - mmengine - INFO - Iter(train) [57200/80000]  base_lr: 7.3093e-05 lr: 7.3093e-05  eta: 10:18:30  time: 1.6151  data_time: 0.0134  memory: 6598  grad_norm: 4.2255  loss: 0.5355  decode.loss_ce: 0.3528  decode.acc_seg: 88.7732  aux.loss_ce: 0.1827  aux.acc_seg: 87.9104
2024/10/28 14:37:47 - mmengine - INFO - Iter(train) [57250/80000]  base_lr: 7.2863e-05 lr: 7.2863e-05  eta: 10:17:09  time: 1.6131  data_time: 0.0135  memory: 6599  grad_norm: 5.3353  loss: 0.5069  decode.loss_ce: 0.3386  decode.acc_seg: 90.2017  aux.loss_ce: 0.1683  aux.acc_seg: 87.1777
2024/10/28 14:39:08 - mmengine - INFO - Iter(train) [57300/80000]  base_lr: 7.2633e-05 lr: 7.2633e-05  eta: 10:15:47  time: 1.6098  data_time: 0.0137  memory: 6601  grad_norm: 6.1195  loss: 0.5380  decode.loss_ce: 0.3749  decode.acc_seg: 84.1824  aux.loss_ce: 0.1631  aux.acc_seg: 83.2776
2024/10/28 14:40:28 - mmengine - INFO - Iter(train) [57350/80000]  base_lr: 7.2402e-05 lr: 7.2402e-05  eta: 10:14:25  time: 1.6099  data_time: 0.0133  memory: 6599  grad_norm: 5.8085  loss: 0.4953  decode.loss_ce: 0.3244  decode.acc_seg: 89.2759  aux.loss_ce: 0.1709  aux.acc_seg: 87.2287
2024/10/28 14:41:49 - mmengine - INFO - Iter(train) [57400/80000]  base_lr: 7.2172e-05 lr: 7.2172e-05  eta: 10:13:03  time: 1.6115  data_time: 0.0137  memory: 6599  grad_norm: 4.8923  loss: 0.4752  decode.loss_ce: 0.3232  decode.acc_seg: 88.6669  aux.loss_ce: 0.1520  aux.acc_seg: 89.7888
2024/10/28 14:43:10 - mmengine - INFO - Iter(train) [57450/80000]  base_lr: 7.1941e-05 lr: 7.1941e-05  eta: 10:11:41  time: 1.6122  data_time: 0.0135  memory: 6598  grad_norm: 4.9012  loss: 0.5455  decode.loss_ce: 0.3723  decode.acc_seg: 85.5092  aux.loss_ce: 0.1732  aux.acc_seg: 79.5290
2024/10/28 14:44:31 - mmengine - INFO - Iter(train) [57500/80000]  base_lr: 7.1710e-05 lr: 7.1710e-05  eta: 10:10:20  time: 1.6097  data_time: 0.0129  memory: 6598  grad_norm: 4.6922  loss: 0.5663  decode.loss_ce: 0.3818  decode.acc_seg: 85.0062  aux.loss_ce: 0.1845  aux.acc_seg: 85.9511
2024/10/28 14:45:52 - mmengine - INFO - Iter(train) [57550/80000]  base_lr: 7.1479e-05 lr: 7.1479e-05  eta: 10:08:58  time: 1.6108  data_time: 0.0132  memory: 6598  grad_norm: 3.9006  loss: 0.5059  decode.loss_ce: 0.3463  decode.acc_seg: 81.8294  aux.loss_ce: 0.1596  aux.acc_seg: 81.3884
2024/10/28 14:47:12 - mmengine - INFO - Iter(train) [57600/80000]  base_lr: 7.1248e-05 lr: 7.1248e-05  eta: 10:07:36  time: 1.6099  data_time: 0.0133  memory: 6598  grad_norm: 5.4477  loss: 0.4448  decode.loss_ce: 0.3093  decode.acc_seg: 84.5241  aux.loss_ce: 0.1355  aux.acc_seg: 85.3258
2024/10/28 14:48:33 - mmengine - INFO - Iter(train) [57650/80000]  base_lr: 7.1016e-05 lr: 7.1016e-05  eta: 10:06:14  time: 1.6095  data_time: 0.0135  memory: 6600  grad_norm: 3.9628  loss: 0.5956  decode.loss_ce: 0.3951  decode.acc_seg: 74.0514  aux.loss_ce: 0.2005  aux.acc_seg: 74.3792
2024/10/28 14:49:54 - mmengine - INFO - Iter(train) [57700/80000]  base_lr: 7.0784e-05 lr: 7.0784e-05  eta: 10:04:52  time: 1.6089  data_time: 0.0121  memory: 6599  grad_norm: 3.7320  loss: 0.4828  decode.loss_ce: 0.3287  decode.acc_seg: 87.6730  aux.loss_ce: 0.1541  aux.acc_seg: 85.5144
2024/10/28 14:51:14 - mmengine - INFO - Iter(train) [57750/80000]  base_lr: 7.0552e-05 lr: 7.0552e-05  eta: 10:03:31  time: 1.6116  data_time: 0.0112  memory: 6598  grad_norm: 7.1706  loss: 0.5392  decode.loss_ce: 0.3672  decode.acc_seg: 85.1205  aux.loss_ce: 0.1719  aux.acc_seg: 81.2946
2024/10/28 14:52:35 - mmengine - INFO - Iter(train) [57800/80000]  base_lr: 7.0320e-05 lr: 7.0320e-05  eta: 10:02:09  time: 1.6091  data_time: 0.0111  memory: 6600  grad_norm: 7.5144  loss: 0.4172  decode.loss_ce: 0.2869  decode.acc_seg: 85.9130  aux.loss_ce: 0.1304  aux.acc_seg: 86.3777
2024/10/28 14:53:56 - mmengine - INFO - Iter(train) [57850/80000]  base_lr: 7.0088e-05 lr: 7.0088e-05  eta: 10:00:47  time: 1.6083  data_time: 0.0109  memory: 6599  grad_norm: 4.4364  loss: 0.4999  decode.loss_ce: 0.3405  decode.acc_seg: 85.4315  aux.loss_ce: 0.1594  aux.acc_seg: 85.8432
2024/10/28 14:55:16 - mmengine - INFO - Iter(train) [57900/80000]  base_lr: 6.9856e-05 lr: 6.9856e-05  eta: 9:59:25  time: 1.6107  data_time: 0.0110  memory: 6599  grad_norm: 7.3944  loss: 0.5270  decode.loss_ce: 0.3506  decode.acc_seg: 88.6255  aux.loss_ce: 0.1764  aux.acc_seg: 86.4498
2024/10/28 14:56:37 - mmengine - INFO - Iter(train) [57950/80000]  base_lr: 6.9623e-05 lr: 6.9623e-05  eta: 9:58:03  time: 1.6096  data_time: 0.0111  memory: 6599  grad_norm: 7.5288  loss: 0.4933  decode.loss_ce: 0.3387  decode.acc_seg: 85.6483  aux.loss_ce: 0.1547  aux.acc_seg: 87.4514
2024/10/28 14:57:58 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 14:57:58 - mmengine - INFO - Iter(train) [58000/80000]  base_lr: 6.9391e-05 lr: 6.9391e-05  eta: 9:56:42  time: 1.6118  data_time: 0.0109  memory: 6600  grad_norm: 7.0501  loss: 0.5368  decode.loss_ce: 0.3529  decode.acc_seg: 79.9660  aux.loss_ce: 0.1839  aux.acc_seg: 78.7772
2024/10/28 14:59:19 - mmengine - INFO - Iter(train) [58050/80000]  base_lr: 6.9158e-05 lr: 6.9158e-05  eta: 9:55:20  time: 1.6117  data_time: 0.0109  memory: 6598  grad_norm: 5.0442  loss: 0.4673  decode.loss_ce: 0.3205  decode.acc_seg: 83.0777  aux.loss_ce: 0.1468  aux.acc_seg: 82.7708
2024/10/28 15:00:39 - mmengine - INFO - Iter(train) [58100/80000]  base_lr: 6.8925e-05 lr: 6.8925e-05  eta: 9:53:58  time: 1.6100  data_time: 0.0108  memory: 6599  grad_norm: 4.9591  loss: 0.4957  decode.loss_ce: 0.3382  decode.acc_seg: 86.7587  aux.loss_ce: 0.1575  aux.acc_seg: 85.7041
2024/10/28 15:02:00 - mmengine - INFO - Iter(train) [58150/80000]  base_lr: 6.8692e-05 lr: 6.8692e-05  eta: 9:52:36  time: 1.6121  data_time: 0.0105  memory: 6598  grad_norm: 4.9055  loss: 0.4922  decode.loss_ce: 0.3382  decode.acc_seg: 77.7189  aux.loss_ce: 0.1540  aux.acc_seg: 75.0537
2024/10/28 15:03:21 - mmengine - INFO - Iter(train) [58200/80000]  base_lr: 6.8459e-05 lr: 6.8459e-05  eta: 9:51:15  time: 1.6093  data_time: 0.0107  memory: 6598  grad_norm: 5.1071  loss: 0.4942  decode.loss_ce: 0.3311  decode.acc_seg: 89.0570  aux.loss_ce: 0.1631  aux.acc_seg: 89.9070
2024/10/28 15:04:42 - mmengine - INFO - Iter(train) [58250/80000]  base_lr: 6.8225e-05 lr: 6.8225e-05  eta: 9:49:53  time: 1.6220  data_time: 0.0107  memory: 6599  grad_norm: 7.7445  loss: 0.4708  decode.loss_ce: 0.3208  decode.acc_seg: 92.9411  aux.loss_ce: 0.1500  aux.acc_seg: 88.3210
2024/10/28 15:06:02 - mmengine - INFO - Iter(train) [58300/80000]  base_lr: 6.7992e-05 lr: 6.7992e-05  eta: 9:48:31  time: 1.6117  data_time: 0.0108  memory: 6599  grad_norm: 6.1403  loss: 0.5107  decode.loss_ce: 0.3422  decode.acc_seg: 90.0144  aux.loss_ce: 0.1685  aux.acc_seg: 89.9682
2024/10/28 15:07:26 - mmengine - INFO - Iter(train) [58350/80000]  base_lr: 6.7758e-05 lr: 6.7758e-05  eta: 9:47:11  time: 1.6083  data_time: 0.0108  memory: 6600  grad_norm: 4.6108  loss: 0.4466  decode.loss_ce: 0.3061  decode.acc_seg: 85.5341  aux.loss_ce: 0.1404  aux.acc_seg: 83.3123
2024/10/28 15:08:47 - mmengine - INFO - Iter(train) [58400/80000]  base_lr: 6.7525e-05 lr: 6.7525e-05  eta: 9:45:49  time: 1.6088  data_time: 0.0104  memory: 6598  grad_norm: 4.5523  loss: 0.5540  decode.loss_ce: 0.3649  decode.acc_seg: 84.3531  aux.loss_ce: 0.1891  aux.acc_seg: 85.2616
2024/10/28 15:10:08 - mmengine - INFO - Iter(train) [58450/80000]  base_lr: 6.7291e-05 lr: 6.7291e-05  eta: 9:44:28  time: 1.6112  data_time: 0.0104  memory: 6597  grad_norm: 5.0949  loss: 0.4821  decode.loss_ce: 0.3260  decode.acc_seg: 87.1251  aux.loss_ce: 0.1561  aux.acc_seg: 81.7997
2024/10/28 15:11:28 - mmengine - INFO - Iter(train) [58500/80000]  base_lr: 6.7057e-05 lr: 6.7057e-05  eta: 9:43:06  time: 1.6106  data_time: 0.0104  memory: 6600  grad_norm: 3.1488  loss: 0.4564  decode.loss_ce: 0.3031  decode.acc_seg: 80.2760  aux.loss_ce: 0.1533  aux.acc_seg: 73.6581
2024/10/28 15:12:49 - mmengine - INFO - Iter(train) [58550/80000]  base_lr: 6.6823e-05 lr: 6.6823e-05  eta: 9:41:44  time: 1.6088  data_time: 0.0106  memory: 6600  grad_norm: 5.3704  loss: 0.5527  decode.loss_ce: 0.3760  decode.acc_seg: 89.4171  aux.loss_ce: 0.1767  aux.acc_seg: 89.2464
2024/10/28 15:14:10 - mmengine - INFO - Iter(train) [58600/80000]  base_lr: 6.6589e-05 lr: 6.6589e-05  eta: 9:40:22  time: 1.6341  data_time: 0.0108  memory: 6599  grad_norm: 4.9805  loss: 0.4971  decode.loss_ce: 0.3302  decode.acc_seg: 85.6778  aux.loss_ce: 0.1669  aux.acc_seg: 83.5691
2024/10/28 15:15:31 - mmengine - INFO - Iter(train) [58650/80000]  base_lr: 6.6354e-05 lr: 6.6354e-05  eta: 9:39:01  time: 1.6131  data_time: 0.0108  memory: 6600  grad_norm: 5.4085  loss: 0.4836  decode.loss_ce: 0.3193  decode.acc_seg: 87.2890  aux.loss_ce: 0.1643  aux.acc_seg: 79.9756
2024/10/28 15:16:51 - mmengine - INFO - Iter(train) [58700/80000]  base_lr: 6.6120e-05 lr: 6.6120e-05  eta: 9:37:39  time: 1.6106  data_time: 0.0108  memory: 6599  grad_norm: 5.4718  loss: 0.5276  decode.loss_ce: 0.3401  decode.acc_seg: 87.3251  aux.loss_ce: 0.1874  aux.acc_seg: 83.6721
2024/10/28 15:18:12 - mmengine - INFO - Iter(train) [58750/80000]  base_lr: 6.5886e-05 lr: 6.5886e-05  eta: 9:36:17  time: 1.6129  data_time: 0.0109  memory: 6599  grad_norm: 6.2377  loss: 0.4955  decode.loss_ce: 0.3358  decode.acc_seg: 86.1775  aux.loss_ce: 0.1597  aux.acc_seg: 84.9285
2024/10/28 15:19:33 - mmengine - INFO - Iter(train) [58800/80000]  base_lr: 6.5651e-05 lr: 6.5651e-05  eta: 9:34:55  time: 1.6138  data_time: 0.0109  memory: 6599  grad_norm: 5.9946  loss: 0.4486  decode.loss_ce: 0.3094  decode.acc_seg: 88.0609  aux.loss_ce: 0.1392  aux.acc_seg: 89.0110
2024/10/28 15:20:54 - mmengine - INFO - Iter(train) [58850/80000]  base_lr: 6.5417e-05 lr: 6.5417e-05  eta: 9:33:34  time: 1.6092  data_time: 0.0109  memory: 6598  grad_norm: 4.5186  loss: 0.5661  decode.loss_ce: 0.3855  decode.acc_seg: 85.6083  aux.loss_ce: 0.1806  aux.acc_seg: 85.4144
2024/10/28 15:22:14 - mmengine - INFO - Iter(train) [58900/80000]  base_lr: 6.5182e-05 lr: 6.5182e-05  eta: 9:32:12  time: 1.6086  data_time: 0.0111  memory: 6599  grad_norm: 6.6714  loss: 0.5091  decode.loss_ce: 0.3400  decode.acc_seg: 82.0078  aux.loss_ce: 0.1690  aux.acc_seg: 79.0928
2024/10/28 15:23:35 - mmengine - INFO - Iter(train) [58950/80000]  base_lr: 6.4947e-05 lr: 6.4947e-05  eta: 9:30:50  time: 1.6091  data_time: 0.0108  memory: 6600  grad_norm: 4.4010  loss: 0.5006  decode.loss_ce: 0.3414  decode.acc_seg: 86.9752  aux.loss_ce: 0.1592  aux.acc_seg: 88.0606
2024/10/28 15:24:55 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 15:24:55 - mmengine - INFO - Iter(train) [59000/80000]  base_lr: 6.4712e-05 lr: 6.4712e-05  eta: 9:29:28  time: 1.6108  data_time: 0.0110  memory: 6600  grad_norm: 5.4140  loss: 0.5241  decode.loss_ce: 0.3548  decode.acc_seg: 88.4463  aux.loss_ce: 0.1693  aux.acc_seg: 89.5572
2024/10/28 15:26:16 - mmengine - INFO - Iter(train) [59050/80000]  base_lr: 6.4477e-05 lr: 6.4477e-05  eta: 9:28:06  time: 1.6090  data_time: 0.0108  memory: 6598  grad_norm: 7.6217  loss: 0.4700  decode.loss_ce: 0.3259  decode.acc_seg: 89.7395  aux.loss_ce: 0.1441  aux.acc_seg: 89.3268
2024/10/28 15:27:37 - mmengine - INFO - Iter(train) [59100/80000]  base_lr: 6.4242e-05 lr: 6.4242e-05  eta: 9:26:45  time: 1.6115  data_time: 0.0108  memory: 6598  grad_norm: 5.7750  loss: 0.5072  decode.loss_ce: 0.3482  decode.acc_seg: 88.7189  aux.loss_ce: 0.1590  aux.acc_seg: 87.0817
2024/10/28 15:28:57 - mmengine - INFO - Iter(train) [59150/80000]  base_lr: 6.4007e-05 lr: 6.4007e-05  eta: 9:25:23  time: 1.6080  data_time: 0.0107  memory: 6599  grad_norm: 5.9418  loss: 0.4902  decode.loss_ce: 0.3284  decode.acc_seg: 85.2980  aux.loss_ce: 0.1618  aux.acc_seg: 82.6948
2024/10/28 15:30:18 - mmengine - INFO - Iter(train) [59200/80000]  base_lr: 6.3772e-05 lr: 6.3772e-05  eta: 9:24:01  time: 1.6115  data_time: 0.0109  memory: 6600  grad_norm: 4.1115  loss: 0.4604  decode.loss_ce: 0.3124  decode.acc_seg: 87.4611  aux.loss_ce: 0.1480  aux.acc_seg: 88.8968
2024/10/28 15:31:38 - mmengine - INFO - Iter(train) [59250/80000]  base_lr: 6.3537e-05 lr: 6.3537e-05  eta: 9:22:39  time: 1.6120  data_time: 0.0109  memory: 6599  grad_norm: 4.3935  loss: 0.4828  decode.loss_ce: 0.3319  decode.acc_seg: 87.5476  aux.loss_ce: 0.1509  aux.acc_seg: 86.8337
2024/10/28 15:32:59 - mmengine - INFO - Iter(train) [59300/80000]  base_lr: 6.3302e-05 lr: 6.3302e-05  eta: 9:21:17  time: 1.6077  data_time: 0.0111  memory: 6600  grad_norm: 5.3460  loss: 0.5610  decode.loss_ce: 0.3798  decode.acc_seg: 83.5068  aux.loss_ce: 0.1812  aux.acc_seg: 81.7874
2024/10/28 15:34:20 - mmengine - INFO - Iter(train) [59350/80000]  base_lr: 6.3066e-05 lr: 6.3066e-05  eta: 9:19:56  time: 1.6108  data_time: 0.0111  memory: 6598  grad_norm: 5.3472  loss: 0.4619  decode.loss_ce: 0.3201  decode.acc_seg: 85.8181  aux.loss_ce: 0.1418  aux.acc_seg: 84.0255
2024/10/28 15:35:40 - mmengine - INFO - Iter(train) [59400/80000]  base_lr: 6.2831e-05 lr: 6.2831e-05  eta: 9:18:34  time: 1.6120  data_time: 0.0109  memory: 6599  grad_norm: 5.2525  loss: 0.4433  decode.loss_ce: 0.3018  decode.acc_seg: 83.9402  aux.loss_ce: 0.1415  aux.acc_seg: 85.8005
2024/10/28 15:37:01 - mmengine - INFO - Iter(train) [59450/80000]  base_lr: 6.2596e-05 lr: 6.2596e-05  eta: 9:17:12  time: 1.6117  data_time: 0.0109  memory: 6600  grad_norm: 7.5236  loss: 0.4718  decode.loss_ce: 0.3193  decode.acc_seg: 85.5640  aux.loss_ce: 0.1525  aux.acc_seg: 78.3344
2024/10/28 15:38:26 - mmengine - INFO - Iter(train) [59500/80000]  base_lr: 6.2360e-05 lr: 6.2360e-05  eta: 9:15:53  time: 1.6090  data_time: 0.0108  memory: 6600  grad_norm: 5.5951  loss: 0.4811  decode.loss_ce: 0.3211  decode.acc_seg: 86.5508  aux.loss_ce: 0.1600  aux.acc_seg: 86.9320
2024/10/28 15:39:47 - mmengine - INFO - Iter(train) [59550/80000]  base_lr: 6.2125e-05 lr: 6.2125e-05  eta: 9:14:32  time: 1.6134  data_time: 0.0112  memory: 6599  grad_norm: 5.5119  loss: 0.4680  decode.loss_ce: 0.3119  decode.acc_seg: 92.5906  aux.loss_ce: 0.1562  aux.acc_seg: 92.3139
2024/10/28 15:41:08 - mmengine - INFO - Iter(train) [59600/80000]  base_lr: 6.1889e-05 lr: 6.1889e-05  eta: 9:13:10  time: 1.6080  data_time: 0.0106  memory: 6599  grad_norm: 8.3987  loss: 0.6228  decode.loss_ce: 0.4139  decode.acc_seg: 83.2939  aux.loss_ce: 0.2089  aux.acc_seg: 81.2094
2024/10/28 15:42:29 - mmengine - INFO - Iter(train) [59650/80000]  base_lr: 6.1654e-05 lr: 6.1654e-05  eta: 9:11:48  time: 1.6101  data_time: 0.0110  memory: 6600  grad_norm: 5.7030  loss: 0.5145  decode.loss_ce: 0.3287  decode.acc_seg: 85.5759  aux.loss_ce: 0.1858  aux.acc_seg: 80.5597
2024/10/28 15:43:50 - mmengine - INFO - Iter(train) [59700/80000]  base_lr: 6.1418e-05 lr: 6.1418e-05  eta: 9:10:27  time: 1.6088  data_time: 0.0108  memory: 6600  grad_norm: 3.9052  loss: 0.3546  decode.loss_ce: 0.2471  decode.acc_seg: 89.5995  aux.loss_ce: 0.1075  aux.acc_seg: 90.7075
2024/10/28 15:45:11 - mmengine - INFO - Iter(train) [59750/80000]  base_lr: 6.1183e-05 lr: 6.1183e-05  eta: 9:09:05  time: 1.6097  data_time: 0.0110  memory: 6598  grad_norm: 4.3503  loss: 0.4821  decode.loss_ce: 0.3196  decode.acc_seg: 83.2907  aux.loss_ce: 0.1625  aux.acc_seg: 80.6253
2024/10/28 15:46:31 - mmengine - INFO - Iter(train) [59800/80000]  base_lr: 6.0947e-05 lr: 6.0947e-05  eta: 9:07:43  time: 1.6085  data_time: 0.0112  memory: 6600  grad_norm: 3.5009  loss: 0.4335  decode.loss_ce: 0.3026  decode.acc_seg: 85.4927  aux.loss_ce: 0.1309  aux.acc_seg: 84.8563
2024/10/28 15:47:52 - mmengine - INFO - Iter(train) [59850/80000]  base_lr: 6.0712e-05 lr: 6.0712e-05  eta: 9:06:22  time: 1.6324  data_time: 0.0106  memory: 6600  grad_norm: 4.3762  loss: 0.4649  decode.loss_ce: 0.3137  decode.acc_seg: 80.9776  aux.loss_ce: 0.1513  aux.acc_seg: 78.8135
2024/10/28 15:49:13 - mmengine - INFO - Iter(train) [59900/80000]  base_lr: 6.0476e-05 lr: 6.0476e-05  eta: 9:05:00  time: 1.6107  data_time: 0.0108  memory: 6600  grad_norm: 6.4499  loss: 0.5009  decode.loss_ce: 0.3423  decode.acc_seg: 85.5283  aux.loss_ce: 0.1586  aux.acc_seg: 87.2311
2024/10/28 15:50:34 - mmengine - INFO - Iter(train) [59950/80000]  base_lr: 6.0240e-05 lr: 6.0240e-05  eta: 9:03:38  time: 1.6132  data_time: 0.0108  memory: 6599  grad_norm: 4.0358  loss: 0.4538  decode.loss_ce: 0.3121  decode.acc_seg: 90.5342  aux.loss_ce: 0.1418  aux.acc_seg: 90.0712
2024/10/28 15:51:55 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 15:51:55 - mmengine - INFO - Iter(train) [60000/80000]  base_lr: 6.0005e-05 lr: 6.0005e-05  eta: 9:02:17  time: 1.6120  data_time: 0.0138  memory: 6600  grad_norm: 5.0217  loss: 0.4431  decode.loss_ce: 0.3042  decode.acc_seg: 86.9097  aux.loss_ce: 0.1389  aux.acc_seg: 80.9392
2024/10/28 15:53:15 - mmengine - INFO - Iter(train) [60050/80000]  base_lr: 5.9769e-05 lr: 5.9769e-05  eta: 9:00:55  time: 1.6154  data_time: 0.0137  memory: 6600  grad_norm: 4.2601  loss: 0.4524  decode.loss_ce: 0.3024  decode.acc_seg: 89.1063  aux.loss_ce: 0.1500  aux.acc_seg: 85.8276
2024/10/28 15:54:36 - mmengine - INFO - Iter(train) [60100/80000]  base_lr: 5.9533e-05 lr: 5.9533e-05  eta: 8:59:33  time: 1.6098  data_time: 0.0137  memory: 6599  grad_norm: 5.5897  loss: 0.4309  decode.loss_ce: 0.3001  decode.acc_seg: 86.7553  aux.loss_ce: 0.1308  aux.acc_seg: 85.7518
2024/10/28 15:55:57 - mmengine - INFO - Iter(train) [60150/80000]  base_lr: 5.9298e-05 lr: 5.9298e-05  eta: 8:58:12  time: 1.6097  data_time: 0.0140  memory: 6600  grad_norm: 3.7493  loss: 0.4749  decode.loss_ce: 0.3239  decode.acc_seg: 88.8840  aux.loss_ce: 0.1510  aux.acc_seg: 88.3140
2024/10/28 15:57:18 - mmengine - INFO - Iter(train) [60200/80000]  base_lr: 5.9062e-05 lr: 5.9062e-05  eta: 8:56:50  time: 1.6119  data_time: 0.0137  memory: 6601  grad_norm: 4.9501  loss: 0.5100  decode.loss_ce: 0.3460  decode.acc_seg: 85.7164  aux.loss_ce: 0.1640  aux.acc_seg: 88.2367
2024/10/28 15:58:38 - mmengine - INFO - Iter(train) [60250/80000]  base_lr: 5.8827e-05 lr: 5.8827e-05  eta: 8:55:28  time: 1.6109  data_time: 0.0135  memory: 6599  grad_norm: 4.0801  loss: 0.5211  decode.loss_ce: 0.3576  decode.acc_seg: 89.6303  aux.loss_ce: 0.1635  aux.acc_seg: 89.7510
2024/10/28 15:59:59 - mmengine - INFO - Iter(train) [60300/80000]  base_lr: 5.8591e-05 lr: 5.8591e-05  eta: 8:54:07  time: 1.6095  data_time: 0.0131  memory: 6599  grad_norm: 6.8810  loss: 0.5070  decode.loss_ce: 0.3413  decode.acc_seg: 89.7656  aux.loss_ce: 0.1657  aux.acc_seg: 88.5200
2024/10/28 16:01:20 - mmengine - INFO - Iter(train) [60350/80000]  base_lr: 5.8356e-05 lr: 5.8356e-05  eta: 8:52:45  time: 1.6096  data_time: 0.0130  memory: 6599  grad_norm: 5.5174  loss: 0.5262  decode.loss_ce: 0.3546  decode.acc_seg: 91.5913  aux.loss_ce: 0.1716  aux.acc_seg: 90.0854
2024/10/28 16:02:40 - mmengine - INFO - Iter(train) [60400/80000]  base_lr: 5.8120e-05 lr: 5.8120e-05  eta: 8:51:23  time: 1.6117  data_time: 0.0133  memory: 6599  grad_norm: 5.1839  loss: 0.5044  decode.loss_ce: 0.3453  decode.acc_seg: 80.4040  aux.loss_ce: 0.1592  aux.acc_seg: 81.7984
2024/10/28 16:04:01 - mmengine - INFO - Iter(train) [60450/80000]  base_lr: 5.7885e-05 lr: 5.7885e-05  eta: 8:50:02  time: 1.6119  data_time: 0.0133  memory: 6600  grad_norm: 3.9492  loss: 0.4380  decode.loss_ce: 0.3048  decode.acc_seg: 87.4294  aux.loss_ce: 0.1332  aux.acc_seg: 86.7820
2024/10/28 16:05:22 - mmengine - INFO - Iter(train) [60500/80000]  base_lr: 5.7649e-05 lr: 5.7649e-05  eta: 8:48:40  time: 1.6093  data_time: 0.0135  memory: 6600  grad_norm: 5.9635  loss: 0.4075  decode.loss_ce: 0.2726  decode.acc_seg: 83.3571  aux.loss_ce: 0.1349  aux.acc_seg: 82.8617
2024/10/28 16:06:43 - mmengine - INFO - Iter(train) [60550/80000]  base_lr: 5.7414e-05 lr: 5.7414e-05  eta: 8:47:18  time: 1.6107  data_time: 0.0135  memory: 6600  grad_norm: 4.4528  loss: 0.4402  decode.loss_ce: 0.2954  decode.acc_seg: 89.9847  aux.loss_ce: 0.1448  aux.acc_seg: 84.4841
2024/10/28 16:08:03 - mmengine - INFO - Iter(train) [60600/80000]  base_lr: 5.7178e-05 lr: 5.7178e-05  eta: 8:45:57  time: 1.6082  data_time: 0.0135  memory: 6599  grad_norm: 5.3270  loss: 0.4864  decode.loss_ce: 0.3204  decode.acc_seg: 89.8842  aux.loss_ce: 0.1660  aux.acc_seg: 87.5148
2024/10/28 16:09:25 - mmengine - INFO - Iter(train) [60650/80000]  base_lr: 5.6943e-05 lr: 5.6943e-05  eta: 8:44:36  time: 1.6104  data_time: 0.0132  memory: 6599  grad_norm: 4.2941  loss: 0.3798  decode.loss_ce: 0.2649  decode.acc_seg: 87.1346  aux.loss_ce: 0.1149  aux.acc_seg: 86.6733
2024/10/28 16:10:46 - mmengine - INFO - Iter(train) [60700/80000]  base_lr: 5.6708e-05 lr: 5.6708e-05  eta: 8:43:14  time: 1.6091  data_time: 0.0136  memory: 6599  grad_norm: 6.0909  loss: 0.4656  decode.loss_ce: 0.3126  decode.acc_seg: 78.2540  aux.loss_ce: 0.1530  aux.acc_seg: 67.9980
2024/10/28 16:12:07 - mmengine - INFO - Iter(train) [60750/80000]  base_lr: 5.6472e-05 lr: 5.6472e-05  eta: 8:41:52  time: 1.6127  data_time: 0.0136  memory: 6599  grad_norm: 6.6631  loss: 0.4445  decode.loss_ce: 0.3074  decode.acc_seg: 85.5244  aux.loss_ce: 0.1371  aux.acc_seg: 81.8650
2024/10/28 16:13:28 - mmengine - INFO - Iter(train) [60800/80000]  base_lr: 5.6237e-05 lr: 5.6237e-05  eta: 8:40:31  time: 1.6115  data_time: 0.0137  memory: 6598  grad_norm: 7.2603  loss: 0.4596  decode.loss_ce: 0.3092  decode.acc_seg: 87.8690  aux.loss_ce: 0.1504  aux.acc_seg: 87.2648
2024/10/28 16:14:48 - mmengine - INFO - Iter(train) [60850/80000]  base_lr: 5.6002e-05 lr: 5.6002e-05  eta: 8:39:09  time: 1.6118  data_time: 0.0135  memory: 6600  grad_norm: 4.5487  loss: 0.5094  decode.loss_ce: 0.3469  decode.acc_seg: 80.0684  aux.loss_ce: 0.1625  aux.acc_seg: 72.6242
2024/10/28 16:16:09 - mmengine - INFO - Iter(train) [60900/80000]  base_lr: 5.5767e-05 lr: 5.5767e-05  eta: 8:37:48  time: 1.6104  data_time: 0.0133  memory: 6599  grad_norm: 4.4705  loss: 0.4902  decode.loss_ce: 0.3317  decode.acc_seg: 83.4617  aux.loss_ce: 0.1585  aux.acc_seg: 80.0364
2024/10/28 16:17:30 - mmengine - INFO - Iter(train) [60950/80000]  base_lr: 5.5532e-05 lr: 5.5532e-05  eta: 8:36:26  time: 1.6344  data_time: 0.0132  memory: 6598  grad_norm: 5.8986  loss: 0.5275  decode.loss_ce: 0.3595  decode.acc_seg: 87.2979  aux.loss_ce: 0.1680  aux.acc_seg: 88.2810
2024/10/28 16:18:51 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 16:18:51 - mmengine - INFO - Iter(train) [61000/80000]  base_lr: 5.5297e-05 lr: 5.5297e-05  eta: 8:35:04  time: 1.6102  data_time: 0.0136  memory: 6599  grad_norm: 6.5917  loss: 0.5223  decode.loss_ce: 0.3489  decode.acc_seg: 89.5834  aux.loss_ce: 0.1735  aux.acc_seg: 89.4042
2024/10/28 16:20:12 - mmengine - INFO - Iter(train) [61050/80000]  base_lr: 5.5062e-05 lr: 5.5062e-05  eta: 8:33:43  time: 1.6102  data_time: 0.0133  memory: 6598  grad_norm: 4.2350  loss: 0.4251  decode.loss_ce: 0.2819  decode.acc_seg: 90.6390  aux.loss_ce: 0.1432  aux.acc_seg: 89.5711
2024/10/28 16:21:33 - mmengine - INFO - Iter(train) [61100/80000]  base_lr: 5.4828e-05 lr: 5.4828e-05  eta: 8:32:21  time: 1.6348  data_time: 0.0134  memory: 6598  grad_norm: 4.4949  loss: 0.4948  decode.loss_ce: 0.3439  decode.acc_seg: 86.1238  aux.loss_ce: 0.1508  aux.acc_seg: 86.0242
2024/10/28 16:22:54 - mmengine - INFO - Iter(train) [61150/80000]  base_lr: 5.4593e-05 lr: 5.4593e-05  eta: 8:31:00  time: 1.6098  data_time: 0.0134  memory: 6600  grad_norm: 3.9984  loss: 0.4318  decode.loss_ce: 0.2951  decode.acc_seg: 83.8354  aux.loss_ce: 0.1367  aux.acc_seg: 85.2267
2024/10/28 16:24:14 - mmengine - INFO - Iter(train) [61200/80000]  base_lr: 5.4358e-05 lr: 5.4358e-05  eta: 8:29:38  time: 1.6126  data_time: 0.0132  memory: 6600  grad_norm: 4.9599  loss: 0.4598  decode.loss_ce: 0.3122  decode.acc_seg: 86.3696  aux.loss_ce: 0.1476  aux.acc_seg: 87.3688
2024/10/28 16:25:35 - mmengine - INFO - Iter(train) [61250/80000]  base_lr: 5.4124e-05 lr: 5.4124e-05  eta: 8:28:16  time: 1.6121  data_time: 0.0132  memory: 6599  grad_norm: 3.9661  loss: 0.4542  decode.loss_ce: 0.3033  decode.acc_seg: 85.7215  aux.loss_ce: 0.1509  aux.acc_seg: 87.4821
2024/10/28 16:26:56 - mmengine - INFO - Iter(train) [61300/80000]  base_lr: 5.3889e-05 lr: 5.3889e-05  eta: 8:26:55  time: 1.6112  data_time: 0.0136  memory: 6599  grad_norm: 4.2550  loss: 0.5237  decode.loss_ce: 0.3638  decode.acc_seg: 89.0866  aux.loss_ce: 0.1599  aux.acc_seg: 87.8057
2024/10/28 16:28:17 - mmengine - INFO - Iter(train) [61350/80000]  base_lr: 5.3655e-05 lr: 5.3655e-05  eta: 8:25:33  time: 1.6096  data_time: 0.0133  memory: 6598  grad_norm: 4.4364  loss: 0.4263  decode.loss_ce: 0.2798  decode.acc_seg: 93.0828  aux.loss_ce: 0.1465  aux.acc_seg: 93.1157
2024/10/28 16:29:37 - mmengine - INFO - Iter(train) [61400/80000]  base_lr: 5.3421e-05 lr: 5.3421e-05  eta: 8:24:12  time: 1.6089  data_time: 0.0133  memory: 6598  grad_norm: 4.0473  loss: 0.4569  decode.loss_ce: 0.3093  decode.acc_seg: 86.2810  aux.loss_ce: 0.1475  aux.acc_seg: 87.0357
2024/10/28 16:30:58 - mmengine - INFO - Iter(train) [61450/80000]  base_lr: 5.3186e-05 lr: 5.3186e-05  eta: 8:22:50  time: 1.6113  data_time: 0.0134  memory: 6598  grad_norm: 4.3596  loss: 0.4263  decode.loss_ce: 0.2888  decode.acc_seg: 87.4141  aux.loss_ce: 0.1375  aux.acc_seg: 87.2094
2024/10/28 16:32:19 - mmengine - INFO - Iter(train) [61500/80000]  base_lr: 5.2952e-05 lr: 5.2952e-05  eta: 8:21:28  time: 1.6088  data_time: 0.0135  memory: 6600  grad_norm: 3.6336  loss: 0.4226  decode.loss_ce: 0.2829  decode.acc_seg: 89.3411  aux.loss_ce: 0.1396  aux.acc_seg: 88.0446
2024/10/28 16:33:39 - mmengine - INFO - Iter(train) [61550/80000]  base_lr: 5.2719e-05 lr: 5.2719e-05  eta: 8:20:07  time: 1.6122  data_time: 0.0135  memory: 6599  grad_norm: 3.5682  loss: 0.4796  decode.loss_ce: 0.3199  decode.acc_seg: 81.9590  aux.loss_ce: 0.1597  aux.acc_seg: 66.6400
2024/10/28 16:35:00 - mmengine - INFO - Iter(train) [61600/80000]  base_lr: 5.2485e-05 lr: 5.2485e-05  eta: 8:18:45  time: 1.6111  data_time: 0.0133  memory: 6599  grad_norm: 4.4429  loss: 0.4539  decode.loss_ce: 0.3077  decode.acc_seg: 84.4233  aux.loss_ce: 0.1462  aux.acc_seg: 85.8274
2024/10/28 16:36:20 - mmengine - INFO - Iter(train) [61650/80000]  base_lr: 5.2251e-05 lr: 5.2251e-05  eta: 8:17:23  time: 1.6109  data_time: 0.0134  memory: 6600  grad_norm: 4.9107  loss: 0.4125  decode.loss_ce: 0.2730  decode.acc_seg: 86.5945  aux.loss_ce: 0.1395  aux.acc_seg: 83.3067
2024/10/28 16:37:41 - mmengine - INFO - Iter(train) [61700/80000]  base_lr: 5.2017e-05 lr: 5.2017e-05  eta: 8:16:02  time: 1.6129  data_time: 0.0139  memory: 6599  grad_norm: 4.8295  loss: 0.4918  decode.loss_ce: 0.3344  decode.acc_seg: 90.7860  aux.loss_ce: 0.1574  aux.acc_seg: 91.6838
2024/10/28 16:39:02 - mmengine - INFO - Iter(train) [61750/80000]  base_lr: 5.1784e-05 lr: 5.1784e-05  eta: 8:14:40  time: 1.6117  data_time: 0.0131  memory: 6600  grad_norm: 5.4878  loss: 0.5036  decode.loss_ce: 0.3397  decode.acc_seg: 79.3593  aux.loss_ce: 0.1639  aux.acc_seg: 80.0457
2024/10/28 16:40:26 - mmengine - INFO - Iter(train) [61800/80000]  base_lr: 5.1551e-05 lr: 5.1551e-05  eta: 8:13:20  time: 1.6109  data_time: 0.0137  memory: 6598  grad_norm: 4.8780  loss: 0.5558  decode.loss_ce: 0.3775  decode.acc_seg: 89.0152  aux.loss_ce: 0.1783  aux.acc_seg: 85.9797
2024/10/28 16:41:47 - mmengine - INFO - Iter(train) [61850/80000]  base_lr: 5.1317e-05 lr: 5.1317e-05  eta: 8:11:59  time: 1.6106  data_time: 0.0134  memory: 6599  grad_norm: 3.7884  loss: 0.4654  decode.loss_ce: 0.3165  decode.acc_seg: 85.8529  aux.loss_ce: 0.1489  aux.acc_seg: 84.6959
2024/10/28 16:43:08 - mmengine - INFO - Iter(train) [61900/80000]  base_lr: 5.1084e-05 lr: 5.1084e-05  eta: 8:10:37  time: 1.6074  data_time: 0.0137  memory: 6598  grad_norm: 3.5957  loss: 0.4595  decode.loss_ce: 0.3031  decode.acc_seg: 88.4592  aux.loss_ce: 0.1564  aux.acc_seg: 86.1381
2024/10/28 16:44:28 - mmengine - INFO - Iter(train) [61950/80000]  base_lr: 5.0851e-05 lr: 5.0851e-05  eta: 8:09:15  time: 1.6097  data_time: 0.0132  memory: 6601  grad_norm: 3.2025  loss: 0.4120  decode.loss_ce: 0.2805  decode.acc_seg: 85.3751  aux.loss_ce: 0.1315  aux.acc_seg: 85.7209
2024/10/28 16:45:49 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 16:45:49 - mmengine - INFO - Iter(train) [62000/80000]  base_lr: 5.0619e-05 lr: 5.0619e-05  eta: 8:07:54  time: 1.6112  data_time: 0.0137  memory: 6600  grad_norm: 5.0883  loss: 0.4075  decode.loss_ce: 0.2785  decode.acc_seg: 87.3494  aux.loss_ce: 0.1289  aux.acc_seg: 82.5490
2024/10/28 16:47:10 - mmengine - INFO - Iter(train) [62050/80000]  base_lr: 5.0386e-05 lr: 5.0386e-05  eta: 8:06:32  time: 1.6233  data_time: 0.0133  memory: 6599  grad_norm: 4.4061  loss: 0.4461  decode.loss_ce: 0.2925  decode.acc_seg: 86.6201  aux.loss_ce: 0.1536  aux.acc_seg: 81.1988
2024/10/28 16:48:31 - mmengine - INFO - Iter(train) [62100/80000]  base_lr: 5.0153e-05 lr: 5.0153e-05  eta: 8:05:11  time: 1.6073  data_time: 0.0133  memory: 6599  grad_norm: 4.5025  loss: 0.4936  decode.loss_ce: 0.3197  decode.acc_seg: 86.6149  aux.loss_ce: 0.1739  aux.acc_seg: 86.7106
2024/10/28 16:49:51 - mmengine - INFO - Iter(train) [62150/80000]  base_lr: 4.9921e-05 lr: 4.9921e-05  eta: 8:03:49  time: 1.6099  data_time: 0.0132  memory: 6599  grad_norm: 6.6474  loss: 0.4806  decode.loss_ce: 0.3246  decode.acc_seg: 89.0029  aux.loss_ce: 0.1560  aux.acc_seg: 88.5207
2024/10/28 16:51:13 - mmengine - INFO - Iter(train) [62200/80000]  base_lr: 4.9689e-05 lr: 4.9689e-05  eta: 8:02:28  time: 1.6357  data_time: 0.0134  memory: 6603  grad_norm: 4.3385  loss: 0.4417  decode.loss_ce: 0.3046  decode.acc_seg: 84.6258  aux.loss_ce: 0.1370  aux.acc_seg: 83.0591
2024/10/28 16:52:33 - mmengine - INFO - Iter(train) [62250/80000]  base_lr: 4.9457e-05 lr: 4.9457e-05  eta: 8:01:06  time: 1.6086  data_time: 0.0135  memory: 6598  grad_norm: 3.7662  loss: 0.4495  decode.loss_ce: 0.3029  decode.acc_seg: 88.9120  aux.loss_ce: 0.1466  aux.acc_seg: 90.4213
2024/10/28 16:53:54 - mmengine - INFO - Iter(train) [62300/80000]  base_lr: 4.9225e-05 lr: 4.9225e-05  eta: 7:59:44  time: 1.6127  data_time: 0.0135  memory: 6598  grad_norm: 5.2004  loss: 0.4977  decode.loss_ce: 0.3310  decode.acc_seg: 88.2579  aux.loss_ce: 0.1667  aux.acc_seg: 87.1028
2024/10/28 16:55:15 - mmengine - INFO - Iter(train) [62350/80000]  base_lr: 4.8993e-05 lr: 4.8993e-05  eta: 7:58:23  time: 1.6371  data_time: 0.0132  memory: 6598  grad_norm: 4.6833  loss: 0.4473  decode.loss_ce: 0.2965  decode.acc_seg: 88.7697  aux.loss_ce: 0.1508  aux.acc_seg: 86.4890
2024/10/28 16:56:35 - mmengine - INFO - Iter(train) [62400/80000]  base_lr: 4.8762e-05 lr: 4.8762e-05  eta: 7:57:01  time: 1.6134  data_time: 0.0131  memory: 6600  grad_norm: 5.1115  loss: 0.4931  decode.loss_ce: 0.3396  decode.acc_seg: 89.9809  aux.loss_ce: 0.1535  aux.acc_seg: 89.6953
2024/10/28 16:57:56 - mmengine - INFO - Iter(train) [62450/80000]  base_lr: 4.8530e-05 lr: 4.8530e-05  eta: 7:55:40  time: 1.6100  data_time: 0.0134  memory: 6599  grad_norm: 4.6492  loss: 0.5273  decode.loss_ce: 0.3436  decode.acc_seg: 81.7468  aux.loss_ce: 0.1837  aux.acc_seg: 79.2955
2024/10/28 16:59:17 - mmengine - INFO - Iter(train) [62500/80000]  base_lr: 4.8299e-05 lr: 4.8299e-05  eta: 7:54:18  time: 1.6097  data_time: 0.0132  memory: 6599  grad_norm: 4.0097  loss: 0.4805  decode.loss_ce: 0.3163  decode.acc_seg: 87.1435  aux.loss_ce: 0.1642  aux.acc_seg: 84.3623
2024/10/28 17:00:38 - mmengine - INFO - Iter(train) [62550/80000]  base_lr: 4.8068e-05 lr: 4.8068e-05  eta: 7:52:57  time: 1.6101  data_time: 0.0133  memory: 6599  grad_norm: 4.1630  loss: 0.4006  decode.loss_ce: 0.2683  decode.acc_seg: 86.8357  aux.loss_ce: 0.1322  aux.acc_seg: 86.7539
2024/10/28 17:01:59 - mmengine - INFO - Iter(train) [62600/80000]  base_lr: 4.7837e-05 lr: 4.7837e-05  eta: 7:51:35  time: 1.6112  data_time: 0.0135  memory: 6599  grad_norm: 3.9441  loss: 0.4595  decode.loss_ce: 0.3123  decode.acc_seg: 92.4302  aux.loss_ce: 0.1471  aux.acc_seg: 92.5450
2024/10/28 17:03:20 - mmengine - INFO - Iter(train) [62650/80000]  base_lr: 4.7607e-05 lr: 4.7607e-05  eta: 7:50:14  time: 1.6122  data_time: 0.0135  memory: 6599  grad_norm: 5.6488  loss: 0.5849  decode.loss_ce: 0.4060  decode.acc_seg: 88.1826  aux.loss_ce: 0.1788  aux.acc_seg: 88.1215
2024/10/28 17:04:41 - mmengine - INFO - Iter(train) [62700/80000]  base_lr: 4.7376e-05 lr: 4.7376e-05  eta: 7:48:52  time: 1.6144  data_time: 0.0130  memory: 6600  grad_norm: 4.9546  loss: 0.5310  decode.loss_ce: 0.3670  decode.acc_seg: 81.4679  aux.loss_ce: 0.1640  aux.acc_seg: 82.7186
2024/10/28 17:06:01 - mmengine - INFO - Iter(train) [62750/80000]  base_lr: 4.7146e-05 lr: 4.7146e-05  eta: 7:47:31  time: 1.6090  data_time: 0.0132  memory: 6598  grad_norm: 4.5861  loss: 0.5928  decode.loss_ce: 0.4108  decode.acc_seg: 78.6203  aux.loss_ce: 0.1820  aux.acc_seg: 78.3998
2024/10/28 17:07:22 - mmengine - INFO - Iter(train) [62800/80000]  base_lr: 4.6916e-05 lr: 4.6916e-05  eta: 7:46:09  time: 1.6115  data_time: 0.0136  memory: 6598  grad_norm: 3.8106  loss: 0.3949  decode.loss_ce: 0.2651  decode.acc_seg: 86.6341  aux.loss_ce: 0.1297  aux.acc_seg: 89.0762
2024/10/28 17:08:43 - mmengine - INFO - Iter(train) [62850/80000]  base_lr: 4.6686e-05 lr: 4.6686e-05  eta: 7:44:47  time: 1.6089  data_time: 0.0137  memory: 6599  grad_norm: 5.1870  loss: 0.4054  decode.loss_ce: 0.2717  decode.acc_seg: 88.2269  aux.loss_ce: 0.1337  aux.acc_seg: 87.8775
2024/10/28 17:10:03 - mmengine - INFO - Iter(train) [62900/80000]  base_lr: 4.6457e-05 lr: 4.6457e-05  eta: 7:43:26  time: 1.6117  data_time: 0.0132  memory: 6600  grad_norm: 3.8339  loss: 0.4291  decode.loss_ce: 0.2813  decode.acc_seg: 91.1664  aux.loss_ce: 0.1478  aux.acc_seg: 92.2104
2024/10/28 17:11:26 - mmengine - INFO - Iter(train) [62950/80000]  base_lr: 4.6227e-05 lr: 4.6227e-05  eta: 7:42:05  time: 1.6111  data_time: 0.0132  memory: 6599  grad_norm: 4.2846  loss: 0.5181  decode.loss_ce: 0.3551  decode.acc_seg: 86.2251  aux.loss_ce: 0.1630  aux.acc_seg: 84.0566
2024/10/28 17:12:47 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 17:12:47 - mmengine - INFO - Iter(train) [63000/80000]  base_lr: 4.5998e-05 lr: 4.5998e-05  eta: 7:40:44  time: 1.6143  data_time: 0.0133  memory: 6599  grad_norm: 3.6748  loss: 0.4672  decode.loss_ce: 0.3179  decode.acc_seg: 81.1136  aux.loss_ce: 0.1494  aux.acc_seg: 81.4263
2024/10/28 17:14:08 - mmengine - INFO - Iter(train) [63050/80000]  base_lr: 4.5769e-05 lr: 4.5769e-05  eta: 7:39:22  time: 1.6087  data_time: 0.0132  memory: 6601  grad_norm: 3.5888  loss: 0.5123  decode.loss_ce: 0.3498  decode.acc_seg: 86.9691  aux.loss_ce: 0.1625  aux.acc_seg: 86.3401
2024/10/28 17:15:29 - mmengine - INFO - Iter(train) [63100/80000]  base_lr: 4.5540e-05 lr: 4.5540e-05  eta: 7:38:01  time: 1.6081  data_time: 0.0135  memory: 6601  grad_norm: 6.2956  loss: 0.4183  decode.loss_ce: 0.2878  decode.acc_seg: 79.0087  aux.loss_ce: 0.1305  aux.acc_seg: 81.1064
2024/10/28 17:16:50 - mmengine - INFO - Iter(train) [63150/80000]  base_lr: 4.5312e-05 lr: 4.5312e-05  eta: 7:36:39  time: 1.6067  data_time: 0.0131  memory: 6599  grad_norm: 4.5358  loss: 0.4940  decode.loss_ce: 0.3334  decode.acc_seg: 84.7930  aux.loss_ce: 0.1606  aux.acc_seg: 80.1340
2024/10/28 17:18:10 - mmengine - INFO - Iter(train) [63200/80000]  base_lr: 4.5083e-05 lr: 4.5083e-05  eta: 7:35:18  time: 1.6110  data_time: 0.0133  memory: 6600  grad_norm: 4.6644  loss: 0.4242  decode.loss_ce: 0.2903  decode.acc_seg: 87.9188  aux.loss_ce: 0.1338  aux.acc_seg: 87.4409
2024/10/28 17:19:31 - mmengine - INFO - Iter(train) [63250/80000]  base_lr: 4.4855e-05 lr: 4.4855e-05  eta: 7:33:56  time: 1.6090  data_time: 0.0129  memory: 6599  grad_norm: 5.2730  loss: 0.5368  decode.loss_ce: 0.3543  decode.acc_seg: 85.8453  aux.loss_ce: 0.1825  aux.acc_seg: 86.7841
2024/10/28 17:20:52 - mmengine - INFO - Iter(train) [63300/80000]  base_lr: 4.4627e-05 lr: 4.4627e-05  eta: 7:32:35  time: 1.6247  data_time: 0.0135  memory: 6598  grad_norm: 4.7402  loss: 0.4238  decode.loss_ce: 0.2833  decode.acc_seg: 86.9046  aux.loss_ce: 0.1405  aux.acc_seg: 84.5642
2024/10/28 17:22:12 - mmengine - INFO - Iter(train) [63350/80000]  base_lr: 4.4400e-05 lr: 4.4400e-05  eta: 7:31:13  time: 1.6132  data_time: 0.0133  memory: 6600  grad_norm: 5.4153  loss: 0.4983  decode.loss_ce: 0.3408  decode.acc_seg: 87.9663  aux.loss_ce: 0.1576  aux.acc_seg: 87.8329
2024/10/28 17:23:33 - mmengine - INFO - Iter(train) [63400/80000]  base_lr: 4.4172e-05 lr: 4.4172e-05  eta: 7:29:51  time: 1.6094  data_time: 0.0129  memory: 6599  grad_norm: 4.5118  loss: 0.4514  decode.loss_ce: 0.3013  decode.acc_seg: 89.5366  aux.loss_ce: 0.1502  aux.acc_seg: 84.9952
2024/10/28 17:24:54 - mmengine - INFO - Iter(train) [63450/80000]  base_lr: 4.3945e-05 lr: 4.3945e-05  eta: 7:28:30  time: 1.6338  data_time: 0.0129  memory: 6600  grad_norm: 4.0769  loss: 0.3757  decode.loss_ce: 0.2553  decode.acc_seg: 93.2297  aux.loss_ce: 0.1204  aux.acc_seg: 90.1099
2024/10/28 17:26:14 - mmengine - INFO - Iter(train) [63500/80000]  base_lr: 4.3718e-05 lr: 4.3718e-05  eta: 7:27:08  time: 1.6101  data_time: 0.0136  memory: 6599  grad_norm: 7.0892  loss: 0.3905  decode.loss_ce: 0.2693  decode.acc_seg: 90.4160  aux.loss_ce: 0.1212  aux.acc_seg: 88.6912
2024/10/28 17:27:35 - mmengine - INFO - Iter(train) [63550/80000]  base_lr: 4.3491e-05 lr: 4.3491e-05  eta: 7:25:47  time: 1.6077  data_time: 0.0130  memory: 6599  grad_norm: 8.2237  loss: 0.4804  decode.loss_ce: 0.3278  decode.acc_seg: 90.4542  aux.loss_ce: 0.1526  aux.acc_seg: 88.5721
2024/10/28 17:28:56 - mmengine - INFO - Iter(train) [63600/80000]  base_lr: 4.3265e-05 lr: 4.3265e-05  eta: 7:24:25  time: 1.6116  data_time: 0.0135  memory: 6599  grad_norm: 3.7003  loss: 0.4467  decode.loss_ce: 0.3028  decode.acc_seg: 84.1464  aux.loss_ce: 0.1439  aux.acc_seg: 85.8826
2024/10/28 17:30:17 - mmengine - INFO - Iter(train) [63650/80000]  base_lr: 4.3039e-05 lr: 4.3039e-05  eta: 7:23:04  time: 1.6099  data_time: 0.0133  memory: 6600  grad_norm: 4.9986  loss: 0.4625  decode.loss_ce: 0.3009  decode.acc_seg: 90.0293  aux.loss_ce: 0.1616  aux.acc_seg: 87.3174
2024/10/28 17:31:38 - mmengine - INFO - Iter(train) [63700/80000]  base_lr: 4.2813e-05 lr: 4.2813e-05  eta: 7:21:42  time: 1.6251  data_time: 0.0133  memory: 6598  grad_norm: 5.3560  loss: 0.5114  decode.loss_ce: 0.3411  decode.acc_seg: 88.1631  aux.loss_ce: 0.1703  aux.acc_seg: 87.9812
2024/10/28 17:32:59 - mmengine - INFO - Iter(train) [63750/80000]  base_lr: 4.2587e-05 lr: 4.2587e-05  eta: 7:20:21  time: 1.6123  data_time: 0.0131  memory: 6598  grad_norm: 3.3068  loss: 0.4222  decode.loss_ce: 0.2859  decode.acc_seg: 86.7769  aux.loss_ce: 0.1363  aux.acc_seg: 85.7931
2024/10/28 17:34:19 - mmengine - INFO - Iter(train) [63800/80000]  base_lr: 4.2362e-05 lr: 4.2362e-05  eta: 7:18:59  time: 1.6092  data_time: 0.0135  memory: 6599  grad_norm: 4.2140  loss: 0.4691  decode.loss_ce: 0.3202  decode.acc_seg: 78.8617  aux.loss_ce: 0.1490  aux.acc_seg: 77.5644
2024/10/28 17:35:40 - mmengine - INFO - Iter(train) [63850/80000]  base_lr: 4.2137e-05 lr: 4.2137e-05  eta: 7:17:38  time: 1.6075  data_time: 0.0136  memory: 6599  grad_norm: 9.2632  loss: 0.4789  decode.loss_ce: 0.3196  decode.acc_seg: 87.1307  aux.loss_ce: 0.1593  aux.acc_seg: 88.0793
2024/10/28 17:37:01 - mmengine - INFO - Iter(train) [63900/80000]  base_lr: 4.1912e-05 lr: 4.1912e-05  eta: 7:16:16  time: 1.6093  data_time: 0.0131  memory: 6602  grad_norm: 4.5691  loss: 0.5011  decode.loss_ce: 0.3416  decode.acc_seg: 86.1883  aux.loss_ce: 0.1595  aux.acc_seg: 84.6124
2024/10/28 17:38:21 - mmengine - INFO - Iter(train) [63950/80000]  base_lr: 4.1688e-05 lr: 4.1688e-05  eta: 7:14:55  time: 1.6097  data_time: 0.0132  memory: 6599  grad_norm: 3.9695  loss: 0.4014  decode.loss_ce: 0.2713  decode.acc_seg: 82.1338  aux.loss_ce: 0.1301  aux.acc_seg: 82.5934
2024/10/28 17:39:42 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 17:39:42 - mmengine - INFO - Iter(train) [64000/80000]  base_lr: 4.1463e-05 lr: 4.1463e-05  eta: 7:13:33  time: 1.6101  data_time: 0.0128  memory: 6600  grad_norm: 6.6341  loss: 0.4863  decode.loss_ce: 0.3257  decode.acc_seg: 85.3595  aux.loss_ce: 0.1606  aux.acc_seg: 83.9060
2024/10/28 17:39:42 - mmengine - INFO - Saving checkpoint at 64000 iterations
2024/10/28 17:39:47 - mmengine - INFO - Iter(val) [ 50/500]    eta: 0:00:13  time: 0.0286  data_time: 0.0013  memory: 1007  
2024/10/28 17:39:49 - mmengine - INFO - Iter(val) [100/500]    eta: 0:00:11  time: 0.0288  data_time: 0.0013  memory: 1077  
2024/10/28 17:39:50 - mmengine - INFO - Iter(val) [150/500]    eta: 0:00:10  time: 0.0297  data_time: 0.0014  memory: 792  
2024/10/28 17:39:52 - mmengine - INFO - Iter(val) [200/500]    eta: 0:00:08  time: 0.0297  data_time: 0.0015  memory: 825  
2024/10/28 17:39:53 - mmengine - INFO - Iter(val) [250/500]    eta: 0:00:07  time: 0.0291  data_time: 0.0016  memory: 865  
2024/10/28 17:39:55 - mmengine - INFO - Iter(val) [300/500]    eta: 0:00:05  time: 0.0293  data_time: 0.0017  memory: 1988  
2024/10/28 17:39:56 - mmengine - INFO - Iter(val) [350/500]    eta: 0:00:04  time: 0.0281  data_time: 0.0012  memory: 791  
2024/10/28 17:39:58 - mmengine - INFO - Iter(val) [400/500]    eta: 0:00:02  time: 0.0295  data_time: 0.0014  memory: 863  
2024/10/28 17:39:59 - mmengine - INFO - Iter(val) [450/500]    eta: 0:00:01  time: 0.0286  data_time: 0.0012  memory: 798  
2024/10/28 17:40:01 - mmengine - INFO - Iter(val) [500/500]    eta: 0:00:00  time: 0.0286  data_time: 0.0012  memory: 847  
2024/10/28 17:40:05 - mmengine - INFO - per class results:
2024/10/28 17:40:05 - mmengine - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 66.52 | 83.62 |
|       building      | 75.92 | 88.46 |
|         sky         | 89.05 | 94.93 |
|        floor        | 70.44 | 85.07 |
|         tree        | 66.35 | 83.47 |
|       ceiling       | 77.07 | 87.75 |
|         road        | 78.11 | 85.85 |
|         bed         |  78.9 | 88.52 |
|      windowpane     | 51.63 | 64.77 |
|        grass        | 56.09 |  73.5 |
|       cabinet       | 51.16 | 65.17 |
|       sidewalk      | 56.48 | 72.83 |
|        person       |  60.2 | 77.89 |
|        earth        | 28.49 | 44.28 |
|         door        | 36.28 | 53.97 |
|        table        | 44.65 | 62.41 |
|       mountain      | 51.24 | 62.15 |
|        plant        | 43.06 | 52.87 |
|       curtain       | 56.07 | 69.52 |
|        chair        | 39.79 | 51.96 |
|         car         | 69.73 | 82.11 |
|        water        |  42.0 | 52.81 |
|       painting      | 52.08 | 67.09 |
|         sofa        |  54.0 | 75.43 |
|        shelf        | 30.31 | 43.03 |
|        house        | 35.74 | 48.74 |
|         sea         | 46.83 | 72.17 |
|        mirror       | 55.82 | 64.19 |
|         rug         | 50.87 | 68.94 |
|        field        | 23.57 | 41.64 |
|       armchair      | 30.28 | 40.88 |
|         seat        | 60.09 | 76.02 |
|        fence        |  37.0 | 54.51 |
|         desk        | 40.28 | 55.56 |
|         rock        | 37.03 | 57.21 |
|       wardrobe      | 46.42 | 66.99 |
|         lamp        | 30.42 | 37.93 |
|       bathtub       | 63.41 | 73.13 |
|       railing       | 23.41 | 34.66 |
|       cushion       | 34.55 | 43.76 |
|         base        | 13.81 | 18.53 |
|         box         | 13.91 |  20.8 |
|        column       |  24.5 | 35.48 |
|      signboard      | 18.27 | 26.27 |
|   chest of drawers  | 31.95 | 53.67 |
|       counter       | 25.13 | 32.19 |
|         sand        | 36.45 | 53.67 |
|         sink        | 50.52 | 61.46 |
|      skyscraper     | 63.94 | 76.87 |
|      fireplace      | 62.53 | 78.54 |
|     refrigerator    | 62.43 | 73.66 |
|      grandstand     | 35.42 | 79.73 |
|         path        | 16.55 | 32.52 |
|        stairs       | 27.42 | 35.43 |
|        runway       | 63.36 | 84.79 |
|         case        | 48.36 | 60.72 |
|      pool table     | 68.81 | 79.89 |
|        pillow       | 39.26 | 47.74 |
|     screen door     | 59.59 | 62.81 |
|       stairway      | 24.01 | 29.13 |
|        river        | 11.18 | 33.19 |
|        bridge       | 31.78 | 37.09 |
|       bookcase      | 31.79 | 50.55 |
|        blind        | 35.99 | 45.84 |
|     coffee table    | 46.38 | 60.49 |
|        toilet       | 64.26 | 73.01 |
|        flower       | 23.46 | 33.98 |
|         book        |  31.1 | 47.91 |
|         hill        |  9.11 | 20.65 |
|        bench        | 34.23 |  41.4 |
|      countertop     | 45.26 | 62.68 |
|        stove        | 55.49 | 67.69 |
|         palm        | 40.46 | 60.72 |
|    kitchen island   | 27.51 | 50.57 |
|       computer      | 44.06 | 51.52 |
|     swivel chair    | 31.81 | 43.91 |
|         boat        | 43.18 | 73.85 |
|         bar         | 48.72 | 64.61 |
|    arcade machine   | 49.01 | 53.61 |
|        hovel        | 26.88 | 32.75 |
|         bus         | 62.22 | 65.31 |
|        towel        | 37.68 | 50.13 |
|        light        |  7.98 |  8.58 |
|        truck        | 20.39 |  35.9 |
|        tower        |  31.3 | 53.29 |
|      chandelier     | 44.89 | 54.74 |
|        awning       | 17.78 | 20.06 |
|     streetlight     |  4.26 |  5.18 |
|        booth        | 37.89 | 47.84 |
| television receiver |  53.0 | 62.24 |
|       airplane      |  30.8 | 52.81 |
|      dirt track     |  9.39 | 20.57 |
|       apparel       | 28.39 | 39.48 |
|         pole        |  4.79 |  8.28 |
|         land        |  0.34 |  0.47 |
|      bannister      |  2.85 |  3.74 |
|      escalator      | 17.42 |  20.5 |
|       ottoman       | 24.95 | 31.87 |
|        bottle       | 19.19 | 33.42 |
|        buffet       | 50.51 | 57.03 |
|        poster       | 23.73 | 31.83 |
|        stage        |  13.7 | 21.96 |
|         van         | 20.99 | 28.52 |
|         ship        | 17.64 | 25.78 |
|       fountain      | 20.15 | 20.73 |
|    conveyer belt    | 57.78 | 85.59 |
|        canopy       | 17.76 | 26.36 |
|        washer       | 65.09 | 68.59 |
|      plaything      |  8.97 | 12.89 |
|    swimming pool    | 30.22 | 39.86 |
|        stool        | 21.41 | 38.71 |
|        barrel       |  24.6 | 63.86 |
|        basket       | 13.83 | 17.04 |
|      waterfall      | 34.98 | 47.85 |
|         tent        |  79.8 | 94.29 |
|         bag         |  8.73 | 12.22 |
|       minibike      | 48.49 | 72.19 |
|        cradle       | 66.71 |  87.8 |
|         oven        | 20.67 | 44.76 |
|         ball        | 37.42 | 47.55 |
|         food        | 41.44 | 54.36 |
|         step        |  5.31 |  6.0  |
|         tank        | 37.26 | 41.33 |
|      trade name     | 12.42 | 14.47 |
|      microwave      | 31.61 | 35.33 |
|         pot         | 20.69 | 23.55 |
|        animal       | 35.32 | 41.14 |
|       bicycle       |  35.3 | 52.04 |
|         lake        | 66.65 | 67.69 |
|      dishwasher     | 52.26 |  64.0 |
|        screen       | 38.55 | 57.94 |
|       blanket       |  9.07 | 10.67 |
|      sculpture      | 39.86 | 56.11 |
|         hood        | 39.32 | 46.98 |
|        sconce       | 14.71 |  15.8 |
|         vase        | 13.53 |  18.8 |
|    traffic light    | 15.38 | 20.11 |
|         tray        |  2.06 |  3.41 |
|        ashcan       | 22.58 |  33.9 |
|         fan         | 25.17 | 30.67 |
|         pier        | 25.61 | 28.48 |
|      crt screen     |  4.23 | 11.73 |
|        plate        | 29.82 | 42.56 |
|       monitor       |  1.31 |  1.94 |
|    bulletin board   | 29.49 | 37.19 |
|        shower       |  0.0  |  0.0  |
|       radiator      |  35.9 | 42.73 |
|        glass        |  2.6  |  3.06 |
|        clock        |  4.37 |  6.77 |
|         flag        | 24.03 | 27.09 |
+---------------------+-------+-------+
2024/10/28 17:40:05 - mmengine - INFO - Iter(val) [500/500]    aAcc: 75.7600  mIoU: 36.0900  mAcc: 47.4100  data_time: 0.0014  time: 0.0290
2024/10/28 17:41:26 - mmengine - INFO - Iter(train) [64050/80000]  base_lr: 4.1240e-05 lr: 4.1240e-05  eta: 7:12:13  time: 1.6091  data_time: 0.0130  memory: 6600  grad_norm: 4.6875  loss: 0.4350  decode.loss_ce: 0.2984  decode.acc_seg: 89.5625  aux.loss_ce: 0.1365  aux.acc_seg: 88.7682
2024/10/28 17:42:47 - mmengine - INFO - Iter(train) [64100/80000]  base_lr: 4.1016e-05 lr: 4.1016e-05  eta: 7:10:52  time: 1.6080  data_time: 0.0130  memory: 6600  grad_norm: 5.2909  loss: 0.4399  decode.loss_ce: 0.2995  decode.acc_seg: 87.4447  aux.loss_ce: 0.1404  aux.acc_seg: 85.3195
2024/10/28 17:44:08 - mmengine - INFO - Iter(train) [64150/80000]  base_lr: 4.0792e-05 lr: 4.0792e-05  eta: 7:09:30  time: 1.6096  data_time: 0.0131  memory: 6599  grad_norm: 4.0746  loss: 0.4651  decode.loss_ce: 0.3178  decode.acc_seg: 82.5628  aux.loss_ce: 0.1472  aux.acc_seg: 84.9041
2024/10/28 17:45:28 - mmengine - INFO - Iter(train) [64200/80000]  base_lr: 4.0569e-05 lr: 4.0569e-05  eta: 7:08:09  time: 1.6074  data_time: 0.0133  memory: 6599  grad_norm: 6.8456  loss: 0.5594  decode.loss_ce: 0.3742  decode.acc_seg: 84.3556  aux.loss_ce: 0.1852  aux.acc_seg: 77.8248
2024/10/28 17:46:49 - mmengine - INFO - Iter(train) [64250/80000]  base_lr: 4.0347e-05 lr: 4.0347e-05  eta: 7:06:47  time: 1.6087  data_time: 0.0135  memory: 6598  grad_norm: 5.1000  loss: 0.4212  decode.loss_ce: 0.2831  decode.acc_seg: 89.7632  aux.loss_ce: 0.1380  aux.acc_seg: 88.9123
2024/10/28 17:48:10 - mmengine - INFO - Iter(train) [64300/80000]  base_lr: 4.0124e-05 lr: 4.0124e-05  eta: 7:05:26  time: 1.6069  data_time: 0.0130  memory: 6599  grad_norm: 4.3864  loss: 0.4943  decode.loss_ce: 0.3419  decode.acc_seg: 88.5989  aux.loss_ce: 0.1523  aux.acc_seg: 86.6860
2024/10/28 17:49:30 - mmengine - INFO - Iter(train) [64350/80000]  base_lr: 3.9902e-05 lr: 3.9902e-05  eta: 7:04:04  time: 1.6084  data_time: 0.0134  memory: 6601  grad_norm: 3.9962  loss: 0.4033  decode.loss_ce: 0.2719  decode.acc_seg: 88.0646  aux.loss_ce: 0.1314  aux.acc_seg: 79.7905
2024/10/28 17:50:51 - mmengine - INFO - Iter(train) [64400/80000]  base_lr: 3.9680e-05 lr: 3.9680e-05  eta: 7:02:43  time: 1.6103  data_time: 0.0131  memory: 6598  grad_norm: 3.3998  loss: 0.4324  decode.loss_ce: 0.2982  decode.acc_seg: 89.7543  aux.loss_ce: 0.1342  aux.acc_seg: 90.8292
2024/10/28 17:52:11 - mmengine - INFO - Iter(train) [64450/80000]  base_lr: 3.9459e-05 lr: 3.9459e-05  eta: 7:01:21  time: 1.6090  data_time: 0.0132  memory: 6599  grad_norm: 4.7292  loss: 0.3982  decode.loss_ce: 0.2693  decode.acc_seg: 89.0536  aux.loss_ce: 0.1290  aux.acc_seg: 88.8335
2024/10/28 17:53:32 - mmengine - INFO - Iter(train) [64500/80000]  base_lr: 3.9237e-05 lr: 3.9237e-05  eta: 7:00:00  time: 1.6326  data_time: 0.0128  memory: 6599  grad_norm: 2.9671  loss: 0.4108  decode.loss_ce: 0.2801  decode.acc_seg: 85.2601  aux.loss_ce: 0.1306  aux.acc_seg: 86.4910
2024/10/28 17:54:53 - mmengine - INFO - Iter(train) [64550/80000]  base_lr: 3.9016e-05 lr: 3.9016e-05  eta: 6:58:38  time: 1.6088  data_time: 0.0133  memory: 6599  grad_norm: 4.7752  loss: 0.4747  decode.loss_ce: 0.3085  decode.acc_seg: 86.3259  aux.loss_ce: 0.1662  aux.acc_seg: 82.8825
2024/10/28 17:56:13 - mmengine - INFO - Iter(train) [64600/80000]  base_lr: 3.8796e-05 lr: 3.8796e-05  eta: 6:57:16  time: 1.6104  data_time: 0.0132  memory: 6600  grad_norm: 4.2696  loss: 0.4301  decode.loss_ce: 0.2916  decode.acc_seg: 90.9430  aux.loss_ce: 0.1386  aux.acc_seg: 91.2060
2024/10/28 17:57:34 - mmengine - INFO - Iter(train) [64650/80000]  base_lr: 3.8576e-05 lr: 3.8576e-05  eta: 6:55:55  time: 1.6065  data_time: 0.0129  memory: 6600  grad_norm: 5.2398  loss: 0.4060  decode.loss_ce: 0.2775  decode.acc_seg: 89.4883  aux.loss_ce: 0.1285  aux.acc_seg: 90.4950
2024/10/28 17:58:54 - mmengine - INFO - Iter(train) [64700/80000]  base_lr: 3.8356e-05 lr: 3.8356e-05  eta: 6:54:33  time: 1.6086  data_time: 0.0133  memory: 6598  grad_norm: 4.2170  loss: 0.4152  decode.loss_ce: 0.2860  decode.acc_seg: 81.5832  aux.loss_ce: 0.1291  aux.acc_seg: 82.8785
2024/10/28 18:00:15 - mmengine - INFO - Iter(train) [64750/80000]  base_lr: 3.8136e-05 lr: 3.8136e-05  eta: 6:53:12  time: 1.6092  data_time: 0.0129  memory: 6599  grad_norm: 5.5971  loss: 0.4470  decode.loss_ce: 0.3016  decode.acc_seg: 92.7124  aux.loss_ce: 0.1454  aux.acc_seg: 93.0390
2024/10/28 18:01:35 - mmengine - INFO - Iter(train) [64800/80000]  base_lr: 3.7917e-05 lr: 3.7917e-05  eta: 6:51:50  time: 1.6089  data_time: 0.0130  memory: 6600  grad_norm: 5.4929  loss: 0.4628  decode.loss_ce: 0.3181  decode.acc_seg: 89.6214  aux.loss_ce: 0.1447  aux.acc_seg: 90.4208
2024/10/28 18:02:56 - mmengine - INFO - Iter(train) [64850/80000]  base_lr: 3.7698e-05 lr: 3.7698e-05  eta: 6:50:29  time: 1.6085  data_time: 0.0132  memory: 6598  grad_norm: 6.6750  loss: 0.4456  decode.loss_ce: 0.3036  decode.acc_seg: 89.0723  aux.loss_ce: 0.1420  aux.acc_seg: 88.6288
2024/10/28 18:04:17 - mmengine - INFO - Iter(train) [64900/80000]  base_lr: 3.7479e-05 lr: 3.7479e-05  eta: 6:49:07  time: 1.6076  data_time: 0.0134  memory: 6598  grad_norm: 3.6827  loss: 0.3985  decode.loss_ce: 0.2745  decode.acc_seg: 88.9995  aux.loss_ce: 0.1240  aux.acc_seg: 90.4018
2024/10/28 18:05:38 - mmengine - INFO - Iter(train) [64950/80000]  base_lr: 3.7261e-05 lr: 3.7261e-05  eta: 6:47:46  time: 1.6259  data_time: 0.0129  memory: 6599  grad_norm: 3.5637  loss: 0.4383  decode.loss_ce: 0.2948  decode.acc_seg: 87.1778  aux.loss_ce: 0.1435  aux.acc_seg: 87.0593
2024/10/28 18:06:59 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 18:06:59 - mmengine - INFO - Iter(train) [65000/80000]  base_lr: 3.7043e-05 lr: 3.7043e-05  eta: 6:46:24  time: 1.6104  data_time: 0.0136  memory: 6599  grad_norm: 4.8475  loss: 0.4974  decode.loss_ce: 0.3372  decode.acc_seg: 88.5423  aux.loss_ce: 0.1602  aux.acc_seg: 89.6569
2024/10/28 18:08:20 - mmengine - INFO - Iter(train) [65050/80000]  base_lr: 3.6826e-05 lr: 3.6826e-05  eta: 6:45:03  time: 1.6128  data_time: 0.0109  memory: 6599  grad_norm: 4.9962  loss: 0.3616  decode.loss_ce: 0.2501  decode.acc_seg: 90.1352  aux.loss_ce: 0.1115  aux.acc_seg: 89.3381
2024/10/28 18:09:41 - mmengine - INFO - Iter(train) [65100/80000]  base_lr: 3.6609e-05 lr: 3.6609e-05  eta: 6:43:41  time: 1.6126  data_time: 0.0109  memory: 6600  grad_norm: 4.0812  loss: 0.4725  decode.loss_ce: 0.3187  decode.acc_seg: 89.5569  aux.loss_ce: 0.1538  aux.acc_seg: 89.1404
2024/10/28 18:11:01 - mmengine - INFO - Iter(train) [65150/80000]  base_lr: 3.6392e-05 lr: 3.6392e-05  eta: 6:42:20  time: 1.6119  data_time: 0.0109  memory: 6599  grad_norm: 4.9756  loss: 0.4393  decode.loss_ce: 0.3000  decode.acc_seg: 90.3079  aux.loss_ce: 0.1394  aux.acc_seg: 90.1979
2024/10/28 18:12:22 - mmengine - INFO - Iter(train) [65200/80000]  base_lr: 3.6175e-05 lr: 3.6175e-05  eta: 6:40:58  time: 1.6132  data_time: 0.0111  memory: 6599  grad_norm: 4.8194  loss: 0.4360  decode.loss_ce: 0.2930  decode.acc_seg: 86.9704  aux.loss_ce: 0.1431  aux.acc_seg: 88.1403
2024/10/28 18:13:43 - mmengine - INFO - Iter(train) [65250/80000]  base_lr: 3.5959e-05 lr: 3.5959e-05  eta: 6:39:37  time: 1.6090  data_time: 0.0109  memory: 6600  grad_norm: 3.7524  loss: 0.5076  decode.loss_ce: 0.3472  decode.acc_seg: 81.8896  aux.loss_ce: 0.1604  aux.acc_seg: 78.8819
2024/10/28 18:15:03 - mmengine - INFO - Iter(train) [65300/80000]  base_lr: 3.5744e-05 lr: 3.5744e-05  eta: 6:38:15  time: 1.6128  data_time: 0.0104  memory: 6600  grad_norm: 4.6968  loss: 0.4580  decode.loss_ce: 0.3130  decode.acc_seg: 86.0151  aux.loss_ce: 0.1451  aux.acc_seg: 86.1478
2024/10/28 18:16:26 - mmengine - INFO - Iter(train) [65350/80000]  base_lr: 3.5528e-05 lr: 3.5528e-05  eta: 6:36:55  time: 1.6102  data_time: 0.0110  memory: 6600  grad_norm: 4.3626  loss: 0.3973  decode.loss_ce: 0.2674  decode.acc_seg: 94.2134  aux.loss_ce: 0.1299  aux.acc_seg: 94.0426
2024/10/28 18:17:47 - mmengine - INFO - Iter(train) [65400/80000]  base_lr: 3.5313e-05 lr: 3.5313e-05  eta: 6:35:33  time: 1.6093  data_time: 0.0109  memory: 6598  grad_norm: 4.3710  loss: 0.4404  decode.loss_ce: 0.2975  decode.acc_seg: 83.4400  aux.loss_ce: 0.1429  aux.acc_seg: 84.1470
2024/10/28 18:19:07 - mmengine - INFO - Iter(train) [65450/80000]  base_lr: 3.5099e-05 lr: 3.5099e-05  eta: 6:34:12  time: 1.6084  data_time: 0.0110  memory: 6599  grad_norm: 4.4074  loss: 0.3955  decode.loss_ce: 0.2616  decode.acc_seg: 85.6301  aux.loss_ce: 0.1339  aux.acc_seg: 84.7782
2024/10/28 18:20:28 - mmengine - INFO - Iter(train) [65500/80000]  base_lr: 3.4885e-05 lr: 3.4885e-05  eta: 6:32:50  time: 1.6091  data_time: 0.0110  memory: 6599  grad_norm: 4.2646  loss: 0.4415  decode.loss_ce: 0.2929  decode.acc_seg: 88.8523  aux.loss_ce: 0.1486  aux.acc_seg: 89.6189
2024/10/28 18:21:48 - mmengine - INFO - Iter(train) [65550/80000]  base_lr: 3.4671e-05 lr: 3.4671e-05  eta: 6:31:29  time: 1.6079  data_time: 0.0110  memory: 6599  grad_norm: 4.0372  loss: 0.3606  decode.loss_ce: 0.2438  decode.acc_seg: 90.3160  aux.loss_ce: 0.1168  aux.acc_seg: 88.8220
2024/10/28 18:23:09 - mmengine - INFO - Iter(train) [65600/80000]  base_lr: 3.4458e-05 lr: 3.4458e-05  eta: 6:30:07  time: 1.6136  data_time: 0.0117  memory: 6598  grad_norm: 5.0322  loss: 0.5175  decode.loss_ce: 0.3511  decode.acc_seg: 84.4043  aux.loss_ce: 0.1664  aux.acc_seg: 84.6138
2024/10/28 18:24:30 - mmengine - INFO - Iter(train) [65650/80000]  base_lr: 3.4245e-05 lr: 3.4245e-05  eta: 6:28:46  time: 1.6095  data_time: 0.0109  memory: 6599  grad_norm: 5.3749  loss: 0.4463  decode.loss_ce: 0.2995  decode.acc_seg: 87.2035  aux.loss_ce: 0.1468  aux.acc_seg: 84.1602
2024/10/28 18:25:51 - mmengine - INFO - Iter(train) [65700/80000]  base_lr: 3.4032e-05 lr: 3.4032e-05  eta: 6:27:24  time: 1.6114  data_time: 0.0108  memory: 6600  grad_norm: 5.8496  loss: 0.4237  decode.loss_ce: 0.2858  decode.acc_seg: 92.1402  aux.loss_ce: 0.1379  aux.acc_seg: 91.3614
2024/10/28 18:27:12 - mmengine - INFO - Iter(train) [65750/80000]  base_lr: 3.3820e-05 lr: 3.3820e-05  eta: 6:26:03  time: 1.6139  data_time: 0.0112  memory: 6600  grad_norm: 3.9310  loss: 0.4342  decode.loss_ce: 0.2939  decode.acc_seg: 89.4282  aux.loss_ce: 0.1403  aux.acc_seg: 88.4596
2024/10/28 18:28:32 - mmengine - INFO - Iter(train) [65800/80000]  base_lr: 3.3608e-05 lr: 3.3608e-05  eta: 6:24:41  time: 1.6070  data_time: 0.0113  memory: 6600  grad_norm: 3.0371  loss: 0.4445  decode.loss_ce: 0.3024  decode.acc_seg: 91.8081  aux.loss_ce: 0.1420  aux.acc_seg: 92.2140
2024/10/28 18:29:53 - mmengine - INFO - Iter(train) [65850/80000]  base_lr: 3.3396e-05 lr: 3.3396e-05  eta: 6:23:20  time: 1.6058  data_time: 0.0112  memory: 6599  grad_norm: 4.3854  loss: 0.4000  decode.loss_ce: 0.2681  decode.acc_seg: 90.9893  aux.loss_ce: 0.1319  aux.acc_seg: 84.2617
2024/10/28 18:31:13 - mmengine - INFO - Iter(train) [65900/80000]  base_lr: 3.3185e-05 lr: 3.3185e-05  eta: 6:21:58  time: 1.6066  data_time: 0.0110  memory: 6598  grad_norm: 4.8763  loss: 0.4203  decode.loss_ce: 0.2847  decode.acc_seg: 91.5023  aux.loss_ce: 0.1356  aux.acc_seg: 84.3230
2024/10/28 18:32:33 - mmengine - INFO - Iter(train) [65950/80000]  base_lr: 3.2975e-05 lr: 3.2975e-05  eta: 6:20:37  time: 1.6070  data_time: 0.0110  memory: 6600  grad_norm: 3.8096  loss: 0.4297  decode.loss_ce: 0.2751  decode.acc_seg: 92.5542  aux.loss_ce: 0.1545  aux.acc_seg: 92.0177
2024/10/28 18:33:54 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 18:33:54 - mmengine - INFO - Iter(train) [66000/80000]  base_lr: 3.2765e-05 lr: 3.2765e-05  eta: 6:19:15  time: 1.6049  data_time: 0.0111  memory: 6601  grad_norm: 3.6830  loss: 0.4465  decode.loss_ce: 0.3075  decode.acc_seg: 82.8961  aux.loss_ce: 0.1389  aux.acc_seg: 84.3364
2024/10/28 18:35:14 - mmengine - INFO - Iter(train) [66050/80000]  base_lr: 3.2555e-05 lr: 3.2555e-05  eta: 6:17:54  time: 1.6075  data_time: 0.0110  memory: 6600  grad_norm: 4.7630  loss: 0.4853  decode.loss_ce: 0.3269  decode.acc_seg: 88.4088  aux.loss_ce: 0.1584  aux.acc_seg: 85.0567
2024/10/28 18:36:35 - mmengine - INFO - Iter(train) [66100/80000]  base_lr: 3.2346e-05 lr: 3.2346e-05  eta: 6:16:32  time: 1.6037  data_time: 0.0110  memory: 6598  grad_norm: 4.5769  loss: 0.4540  decode.loss_ce: 0.3024  decode.acc_seg: 85.9161  aux.loss_ce: 0.1516  aux.acc_seg: 83.9110
2024/10/28 18:37:55 - mmengine - INFO - Iter(train) [66150/80000]  base_lr: 3.2137e-05 lr: 3.2137e-05  eta: 6:15:10  time: 1.6008  data_time: 0.0108  memory: 6599  grad_norm: 4.3695  loss: 0.4082  decode.loss_ce: 0.2780  decode.acc_seg: 85.4057  aux.loss_ce: 0.1302  aux.acc_seg: 83.8553
2024/10/28 18:39:16 - mmengine - INFO - Iter(train) [66200/80000]  base_lr: 3.1928e-05 lr: 3.1928e-05  eta: 6:13:49  time: 1.6031  data_time: 0.0115  memory: 6599  grad_norm: 5.3051  loss: 0.4107  decode.loss_ce: 0.2727  decode.acc_seg: 93.3011  aux.loss_ce: 0.1381  aux.acc_seg: 93.6040
2024/10/28 18:40:36 - mmengine - INFO - Iter(train) [66250/80000]  base_lr: 3.1720e-05 lr: 3.1720e-05  eta: 6:12:28  time: 1.6066  data_time: 0.0109  memory: 6598  grad_norm: 4.0319  loss: 0.4790  decode.loss_ce: 0.3258  decode.acc_seg: 87.2341  aux.loss_ce: 0.1532  aux.acc_seg: 87.6902
2024/10/28 18:41:57 - mmengine - INFO - Iter(train) [66300/80000]  base_lr: 3.1513e-05 lr: 3.1513e-05  eta: 6:11:06  time: 1.6043  data_time: 0.0109  memory: 6599  grad_norm: 6.3220  loss: 0.4903  decode.loss_ce: 0.3287  decode.acc_seg: 86.1900  aux.loss_ce: 0.1616  aux.acc_seg: 85.7180
2024/10/28 18:43:17 - mmengine - INFO - Iter(train) [66350/80000]  base_lr: 3.1306e-05 lr: 3.1306e-05  eta: 6:09:44  time: 1.6105  data_time: 0.0110  memory: 6600  grad_norm: 5.1425  loss: 0.4198  decode.loss_ce: 0.2776  decode.acc_seg: 85.5917  aux.loss_ce: 0.1422  aux.acc_seg: 83.5320
2024/10/28 18:44:38 - mmengine - INFO - Iter(train) [66400/80000]  base_lr: 3.1099e-05 lr: 3.1099e-05  eta: 6:08:23  time: 1.6061  data_time: 0.0112  memory: 6600  grad_norm: 3.5108  loss: 0.4012  decode.loss_ce: 0.2736  decode.acc_seg: 90.1702  aux.loss_ce: 0.1277  aux.acc_seg: 88.3961
2024/10/28 18:45:59 - mmengine - INFO - Iter(train) [66450/80000]  base_lr: 3.0893e-05 lr: 3.0893e-05  eta: 6:07:01  time: 1.6081  data_time: 0.0109  memory: 6598  grad_norm: 4.1730  loss: 0.4581  decode.loss_ce: 0.3144  decode.acc_seg: 89.6480  aux.loss_ce: 0.1437  aux.acc_seg: 88.9584
2024/10/28 18:47:19 - mmengine - INFO - Iter(train) [66500/80000]  base_lr: 3.0687e-05 lr: 3.0687e-05  eta: 6:05:40  time: 1.6062  data_time: 0.0107  memory: 6600  grad_norm: 5.8545  loss: 0.4655  decode.loss_ce: 0.3191  decode.acc_seg: 84.6582  aux.loss_ce: 0.1465  aux.acc_seg: 85.4385
2024/10/28 18:48:40 - mmengine - INFO - Iter(train) [66550/80000]  base_lr: 3.0481e-05 lr: 3.0481e-05  eta: 6:04:19  time: 1.6072  data_time: 0.0134  memory: 6600  grad_norm: 3.7152  loss: 0.3753  decode.loss_ce: 0.2548  decode.acc_seg: 86.5260  aux.loss_ce: 0.1205  aux.acc_seg: 84.4500
2024/10/28 18:50:00 - mmengine - INFO - Iter(train) [66600/80000]  base_lr: 3.0277e-05 lr: 3.0277e-05  eta: 6:02:57  time: 1.6091  data_time: 0.0133  memory: 6598  grad_norm: 4.3183  loss: 0.4903  decode.loss_ce: 0.3430  decode.acc_seg: 86.5681  aux.loss_ce: 0.1473  aux.acc_seg: 85.7049
2024/10/28 18:51:21 - mmengine - INFO - Iter(train) [66650/80000]  base_lr: 3.0072e-05 lr: 3.0072e-05  eta: 6:01:36  time: 1.6108  data_time: 0.0131  memory: 6599  grad_norm: 3.2495  loss: 0.3883  decode.loss_ce: 0.2625  decode.acc_seg: 83.2866  aux.loss_ce: 0.1258  aux.acc_seg: 81.4000
2024/10/28 18:52:42 - mmengine - INFO - Iter(train) [66700/80000]  base_lr: 2.9868e-05 lr: 2.9868e-05  eta: 6:00:14  time: 1.6088  data_time: 0.0131  memory: 6598  grad_norm: 7.6427  loss: 0.5070  decode.loss_ce: 0.3372  decode.acc_seg: 87.9261  aux.loss_ce: 0.1698  aux.acc_seg: 87.7719
2024/10/28 18:54:03 - mmengine - INFO - Iter(train) [66750/80000]  base_lr: 2.9665e-05 lr: 2.9665e-05  eta: 5:58:53  time: 1.6083  data_time: 0.0134  memory: 6600  grad_norm: 3.3543  loss: 0.3417  decode.loss_ce: 0.2314  decode.acc_seg: 90.6912  aux.loss_ce: 0.1103  aux.acc_seg: 89.6455
2024/10/28 18:55:25 - mmengine - INFO - Iter(train) [66800/80000]  base_lr: 2.9462e-05 lr: 2.9462e-05  eta: 5:57:32  time: 1.6079  data_time: 0.0129  memory: 6598  grad_norm: 4.5486  loss: 0.4449  decode.loss_ce: 0.3074  decode.acc_seg: 84.5294  aux.loss_ce: 0.1376  aux.acc_seg: 84.6537
2024/10/28 18:56:46 - mmengine - INFO - Iter(train) [66850/80000]  base_lr: 2.9259e-05 lr: 2.9259e-05  eta: 5:56:11  time: 1.6066  data_time: 0.0132  memory: 6600  grad_norm: 4.4846  loss: 0.4801  decode.loss_ce: 0.3247  decode.acc_seg: 86.1230  aux.loss_ce: 0.1554  aux.acc_seg: 84.8066
2024/10/28 18:58:06 - mmengine - INFO - Iter(train) [66900/80000]  base_lr: 2.9057e-05 lr: 2.9057e-05  eta: 5:54:49  time: 1.6082  data_time: 0.0131  memory: 6600  grad_norm: 4.4937  loss: 0.4738  decode.loss_ce: 0.3259  decode.acc_seg: 86.1726  aux.loss_ce: 0.1479  aux.acc_seg: 87.3657
2024/10/28 18:59:27 - mmengine - INFO - Iter(train) [66950/80000]  base_lr: 2.8855e-05 lr: 2.8855e-05  eta: 5:53:28  time: 1.6092  data_time: 0.0133  memory: 6599  grad_norm: 4.0614  loss: 0.3919  decode.loss_ce: 0.2743  decode.acc_seg: 88.4504  aux.loss_ce: 0.1177  aux.acc_seg: 88.8166
2024/10/28 19:00:48 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 19:00:48 - mmengine - INFO - Iter(train) [67000/80000]  base_lr: 2.8654e-05 lr: 2.8654e-05  eta: 5:52:06  time: 1.6070  data_time: 0.0133  memory: 6598  grad_norm: 4.9550  loss: 0.4137  decode.loss_ce: 0.2766  decode.acc_seg: 88.5458  aux.loss_ce: 0.1371  aux.acc_seg: 87.7405
2024/10/28 19:02:08 - mmengine - INFO - Iter(train) [67050/80000]  base_lr: 2.8453e-05 lr: 2.8453e-05  eta: 5:50:45  time: 1.6014  data_time: 0.0114  memory: 6599  grad_norm: 3.5526  loss: 0.4685  decode.loss_ce: 0.3206  decode.acc_seg: 89.4481  aux.loss_ce: 0.1479  aux.acc_seg: 88.0465
2024/10/28 19:03:29 - mmengine - INFO - Iter(train) [67100/80000]  base_lr: 2.8253e-05 lr: 2.8253e-05  eta: 5:49:23  time: 1.6016  data_time: 0.0108  memory: 6599  grad_norm: 6.5179  loss: 0.4159  decode.loss_ce: 0.2800  decode.acc_seg: 91.8907  aux.loss_ce: 0.1360  aux.acc_seg: 91.5185
2024/10/28 19:04:49 - mmengine - INFO - Iter(train) [67150/80000]  base_lr: 2.8054e-05 lr: 2.8054e-05  eta: 5:48:02  time: 1.6014  data_time: 0.0114  memory: 6599  grad_norm: 3.8212  loss: 0.4245  decode.loss_ce: 0.2884  decode.acc_seg: 88.7728  aux.loss_ce: 0.1361  aux.acc_seg: 86.6231
2024/10/28 19:06:09 - mmengine - INFO - Iter(train) [67200/80000]  base_lr: 2.7854e-05 lr: 2.7854e-05  eta: 5:46:40  time: 1.6021  data_time: 0.0112  memory: 6599  grad_norm: 5.6888  loss: 0.4697  decode.loss_ce: 0.3118  decode.acc_seg: 88.7871  aux.loss_ce: 0.1579  aux.acc_seg: 86.7936
2024/10/28 19:07:29 - mmengine - INFO - Iter(train) [67250/80000]  base_lr: 2.7656e-05 lr: 2.7656e-05  eta: 5:45:19  time: 1.6023  data_time: 0.0111  memory: 6599  grad_norm: 4.3785  loss: 0.4243  decode.loss_ce: 0.2857  decode.acc_seg: 84.9942  aux.loss_ce: 0.1386  aux.acc_seg: 86.9626
2024/10/28 19:08:50 - mmengine - INFO - Iter(train) [67300/80000]  base_lr: 2.7457e-05 lr: 2.7457e-05  eta: 5:43:57  time: 1.6014  data_time: 0.0111  memory: 6599  grad_norm: 3.7896  loss: 0.4941  decode.loss_ce: 0.3342  decode.acc_seg: 81.7997  aux.loss_ce: 0.1598  aux.acc_seg: 80.2630
2024/10/28 19:10:10 - mmengine - INFO - Iter(train) [67350/80000]  base_lr: 2.7260e-05 lr: 2.7260e-05  eta: 5:42:35  time: 1.6000  data_time: 0.0109  memory: 6600  grad_norm: 4.3859  loss: 0.4972  decode.loss_ce: 0.3386  decode.acc_seg: 86.9521  aux.loss_ce: 0.1587  aux.acc_seg: 87.1377
2024/10/28 19:11:30 - mmengine - INFO - Iter(train) [67400/80000]  base_lr: 2.7063e-05 lr: 2.7063e-05  eta: 5:41:14  time: 1.6012  data_time: 0.0109  memory: 6599  grad_norm: 3.2721  loss: 0.4732  decode.loss_ce: 0.3231  decode.acc_seg: 87.7268  aux.loss_ce: 0.1502  aux.acc_seg: 89.0160
2024/10/28 19:12:50 - mmengine - INFO - Iter(train) [67450/80000]  base_lr: 2.6866e-05 lr: 2.6866e-05  eta: 5:39:52  time: 1.6010  data_time: 0.0111  memory: 6599  grad_norm: 3.3564  loss: 0.3967  decode.loss_ce: 0.2626  decode.acc_seg: 84.6673  aux.loss_ce: 0.1341  aux.acc_seg: 80.8304
2024/10/28 19:14:11 - mmengine - INFO - Iter(train) [67500/80000]  base_lr: 2.6670e-05 lr: 2.6670e-05  eta: 5:38:31  time: 1.6014  data_time: 0.0110  memory: 6602  grad_norm: 4.1852  loss: 0.4656  decode.loss_ce: 0.3139  decode.acc_seg: 86.1807  aux.loss_ce: 0.1517  aux.acc_seg: 85.2927
2024/10/28 19:15:31 - mmengine - INFO - Iter(train) [67550/80000]  base_lr: 2.6474e-05 lr: 2.6474e-05  eta: 5:37:09  time: 1.6006  data_time: 0.0107  memory: 6600  grad_norm: 5.9505  loss: 0.4689  decode.loss_ce: 0.3204  decode.acc_seg: 86.4370  aux.loss_ce: 0.1485  aux.acc_seg: 85.9189
2024/10/28 19:16:51 - mmengine - INFO - Iter(train) [67600/80000]  base_lr: 2.6279e-05 lr: 2.6279e-05  eta: 5:35:48  time: 1.6027  data_time: 0.0110  memory: 6599  grad_norm: 3.5880  loss: 0.4733  decode.loss_ce: 0.3234  decode.acc_seg: 92.2465  aux.loss_ce: 0.1499  aux.acc_seg: 92.3781
2024/10/28 19:18:12 - mmengine - INFO - Iter(train) [67650/80000]  base_lr: 2.6084e-05 lr: 2.6084e-05  eta: 5:34:26  time: 1.6080  data_time: 0.0112  memory: 6600  grad_norm: 3.8348  loss: 0.3727  decode.loss_ce: 0.2522  decode.acc_seg: 88.1643  aux.loss_ce: 0.1205  aux.acc_seg: 84.7530
2024/10/28 19:19:32 - mmengine - INFO - Iter(train) [67700/80000]  base_lr: 2.5890e-05 lr: 2.5890e-05  eta: 5:33:05  time: 1.6053  data_time: 0.0116  memory: 6601  grad_norm: 4.6424  loss: 0.4059  decode.loss_ce: 0.2797  decode.acc_seg: 89.5066  aux.loss_ce: 0.1262  aux.acc_seg: 90.3957
2024/10/28 19:20:53 - mmengine - INFO - Iter(train) [67750/80000]  base_lr: 2.5697e-05 lr: 2.5697e-05  eta: 5:31:43  time: 1.6079  data_time: 0.0128  memory: 6600  grad_norm: 4.4565  loss: 0.4893  decode.loss_ce: 0.3288  decode.acc_seg: 77.2368  aux.loss_ce: 0.1605  aux.acc_seg: 72.1039
2024/10/28 19:22:13 - mmengine - INFO - Iter(train) [67800/80000]  base_lr: 2.5504e-05 lr: 2.5504e-05  eta: 5:30:22  time: 1.6091  data_time: 0.0134  memory: 6600  grad_norm: 4.1395  loss: 0.4280  decode.loss_ce: 0.2890  decode.acc_seg: 87.5614  aux.loss_ce: 0.1390  aux.acc_seg: 85.5756
2024/10/28 19:23:34 - mmengine - INFO - Iter(train) [67850/80000]  base_lr: 2.5311e-05 lr: 2.5311e-05  eta: 5:29:01  time: 1.6083  data_time: 0.0137  memory: 6599  grad_norm: 4.4897  loss: 0.4048  decode.loss_ce: 0.2757  decode.acc_seg: 90.7553  aux.loss_ce: 0.1291  aux.acc_seg: 88.4149
2024/10/28 19:24:54 - mmengine - INFO - Iter(train) [67900/80000]  base_lr: 2.5119e-05 lr: 2.5119e-05  eta: 5:27:39  time: 1.6220  data_time: 0.0131  memory: 6598  grad_norm: 5.0370  loss: 0.4403  decode.loss_ce: 0.3037  decode.acc_seg: 86.3604  aux.loss_ce: 0.1366  aux.acc_seg: 86.9850
2024/10/28 19:26:15 - mmengine - INFO - Iter(train) [67950/80000]  base_lr: 2.4928e-05 lr: 2.4928e-05  eta: 5:26:18  time: 1.6081  data_time: 0.0129  memory: 6599  grad_norm: 2.9571  loss: 0.4287  decode.loss_ce: 0.2906  decode.acc_seg: 91.3806  aux.loss_ce: 0.1381  aux.acc_seg: 91.1140
2024/10/28 19:27:36 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 19:27:36 - mmengine - INFO - Iter(train) [68000/80000]  base_lr: 2.4737e-05 lr: 2.4737e-05  eta: 5:24:56  time: 1.6101  data_time: 0.0134  memory: 6600  grad_norm: 3.0018  loss: 0.3544  decode.loss_ce: 0.2448  decode.acc_seg: 90.6710  aux.loss_ce: 0.1096  aux.acc_seg: 91.0821
2024/10/28 19:28:57 - mmengine - INFO - Iter(train) [68050/80000]  base_lr: 2.4546e-05 lr: 2.4546e-05  eta: 5:23:35  time: 1.6102  data_time: 0.0134  memory: 6600  grad_norm: 3.7778  loss: 0.4449  decode.loss_ce: 0.3021  decode.acc_seg: 89.5726  aux.loss_ce: 0.1429  aux.acc_seg: 88.2810
2024/10/28 19:30:18 - mmengine - INFO - Iter(train) [68100/80000]  base_lr: 2.4357e-05 lr: 2.4357e-05  eta: 5:22:14  time: 1.6103  data_time: 0.0135  memory: 6598  grad_norm: 5.0918  loss: 0.4119  decode.loss_ce: 0.2811  decode.acc_seg: 90.5970  aux.loss_ce: 0.1308  aux.acc_seg: 89.4336
2024/10/28 19:31:38 - mmengine - INFO - Iter(train) [68150/80000]  base_lr: 2.4167e-05 lr: 2.4167e-05  eta: 5:20:52  time: 1.6106  data_time: 0.0133  memory: 6598  grad_norm: 3.9682  loss: 0.4826  decode.loss_ce: 0.3361  decode.acc_seg: 83.1948  aux.loss_ce: 0.1465  aux.acc_seg: 82.6492
2024/10/28 19:32:59 - mmengine - INFO - Iter(train) [68200/80000]  base_lr: 2.3979e-05 lr: 2.3979e-05  eta: 5:19:31  time: 1.6108  data_time: 0.0134  memory: 6600  grad_norm: 3.5536  loss: 0.3783  decode.loss_ce: 0.2587  decode.acc_seg: 92.8336  aux.loss_ce: 0.1196  aux.acc_seg: 90.6951
2024/10/28 19:34:20 - mmengine - INFO - Iter(train) [68250/80000]  base_lr: 2.3790e-05 lr: 2.3790e-05  eta: 5:18:10  time: 1.6100  data_time: 0.0132  memory: 6598  grad_norm: 3.6719  loss: 0.4247  decode.loss_ce: 0.2912  decode.acc_seg: 89.0881  aux.loss_ce: 0.1334  aux.acc_seg: 90.2554
2024/10/28 19:35:41 - mmengine - INFO - Iter(train) [68300/80000]  base_lr: 2.3603e-05 lr: 2.3603e-05  eta: 5:16:48  time: 1.6105  data_time: 0.0131  memory: 6599  grad_norm: 4.1093  loss: 0.4347  decode.loss_ce: 0.2994  decode.acc_seg: 87.7251  aux.loss_ce: 0.1353  aux.acc_seg: 86.9675
2024/10/28 19:37:02 - mmengine - INFO - Iter(train) [68350/80000]  base_lr: 2.3416e-05 lr: 2.3416e-05  eta: 5:15:27  time: 1.6120  data_time: 0.0134  memory: 6600  grad_norm: 3.6510  loss: 0.4780  decode.loss_ce: 0.3260  decode.acc_seg: 88.8601  aux.loss_ce: 0.1520  aux.acc_seg: 88.5949
2024/10/28 19:38:25 - mmengine - INFO - Iter(train) [68400/80000]  base_lr: 2.3229e-05 lr: 2.3229e-05  eta: 5:14:06  time: 1.6104  data_time: 0.0137  memory: 6598  grad_norm: 4.0092  loss: 0.4090  decode.loss_ce: 0.2810  decode.acc_seg: 90.2064  aux.loss_ce: 0.1281  aux.acc_seg: 87.3681
2024/10/28 19:39:46 - mmengine - INFO - Iter(train) [68450/80000]  base_lr: 2.3043e-05 lr: 2.3043e-05  eta: 5:12:45  time: 1.6110  data_time: 0.0133  memory: 6599  grad_norm: 3.9145  loss: 0.4400  decode.loss_ce: 0.3006  decode.acc_seg: 82.9746  aux.loss_ce: 0.1394  aux.acc_seg: 78.3354
2024/10/28 19:41:06 - mmengine - INFO - Iter(train) [68500/80000]  base_lr: 2.2858e-05 lr: 2.2858e-05  eta: 5:11:23  time: 1.6096  data_time: 0.0129  memory: 6599  grad_norm: 4.0067  loss: 0.3613  decode.loss_ce: 0.2482  decode.acc_seg: 91.3224  aux.loss_ce: 0.1131  aux.acc_seg: 89.7508
2024/10/28 19:42:27 - mmengine - INFO - Iter(train) [68550/80000]  base_lr: 2.2673e-05 lr: 2.2673e-05  eta: 5:10:02  time: 1.6113  data_time: 0.0132  memory: 6600  grad_norm: 5.8607  loss: 0.4492  decode.loss_ce: 0.3028  decode.acc_seg: 86.7887  aux.loss_ce: 0.1464  aux.acc_seg: 85.4206
2024/10/28 19:43:47 - mmengine - INFO - Iter(train) [68600/80000]  base_lr: 2.2489e-05 lr: 2.2489e-05  eta: 5:08:41  time: 1.6093  data_time: 0.0133  memory: 6600  grad_norm: 3.8413  loss: 0.4051  decode.loss_ce: 0.2679  decode.acc_seg: 86.3392  aux.loss_ce: 0.1371  aux.acc_seg: 84.9410
2024/10/28 19:45:08 - mmengine - INFO - Iter(train) [68650/80000]  base_lr: 2.2306e-05 lr: 2.2306e-05  eta: 5:07:19  time: 1.6105  data_time: 0.0134  memory: 6598  grad_norm: 5.6270  loss: 0.4603  decode.loss_ce: 0.3231  decode.acc_seg: 90.1133  aux.loss_ce: 0.1372  aux.acc_seg: 90.0994
2024/10/28 19:46:29 - mmengine - INFO - Iter(train) [68700/80000]  base_lr: 2.2122e-05 lr: 2.2122e-05  eta: 5:05:58  time: 1.6084  data_time: 0.0132  memory: 6598  grad_norm: 4.5888  loss: 0.4909  decode.loss_ce: 0.3300  decode.acc_seg: 86.1349  aux.loss_ce: 0.1609  aux.acc_seg: 83.6928
2024/10/28 19:47:50 - mmengine - INFO - Iter(train) [68750/80000]  base_lr: 2.1940e-05 lr: 2.1940e-05  eta: 5:04:37  time: 1.6231  data_time: 0.0131  memory: 6600  grad_norm: 4.2144  loss: 0.4156  decode.loss_ce: 0.2705  decode.acc_seg: 89.0701  aux.loss_ce: 0.1452  aux.acc_seg: 87.6603
2024/10/28 19:49:10 - mmengine - INFO - Iter(train) [68800/80000]  base_lr: 2.1758e-05 lr: 2.1758e-05  eta: 5:03:15  time: 1.6087  data_time: 0.0132  memory: 6599  grad_norm: 3.8686  loss: 0.3557  decode.loss_ce: 0.2414  decode.acc_seg: 88.3426  aux.loss_ce: 0.1143  aux.acc_seg: 88.1622
2024/10/28 19:50:31 - mmengine - INFO - Iter(train) [68850/80000]  base_lr: 2.1577e-05 lr: 2.1577e-05  eta: 5:01:54  time: 1.6075  data_time: 0.0128  memory: 6600  grad_norm: 4.7875  loss: 0.3606  decode.loss_ce: 0.2450  decode.acc_seg: 89.2469  aux.loss_ce: 0.1156  aux.acc_seg: 88.5891
2024/10/28 19:51:51 - mmengine - INFO - Iter(train) [68900/80000]  base_lr: 2.1396e-05 lr: 2.1396e-05  eta: 5:00:32  time: 1.6189  data_time: 0.0130  memory: 6600  grad_norm: 3.7155  loss: 0.4388  decode.loss_ce: 0.3011  decode.acc_seg: 88.2322  aux.loss_ce: 0.1377  aux.acc_seg: 88.2035
2024/10/28 19:53:12 - mmengine - INFO - Iter(train) [68950/80000]  base_lr: 2.1216e-05 lr: 2.1216e-05  eta: 4:59:11  time: 1.6091  data_time: 0.0131  memory: 6599  grad_norm: 3.6514  loss: 0.4251  decode.loss_ce: 0.2895  decode.acc_seg: 88.5744  aux.loss_ce: 0.1356  aux.acc_seg: 88.3708
2024/10/28 19:54:33 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 19:54:33 - mmengine - INFO - Iter(train) [69000/80000]  base_lr: 2.1037e-05 lr: 2.1037e-05  eta: 4:57:50  time: 1.6109  data_time: 0.0134  memory: 6600  grad_norm: 5.2819  loss: 0.3983  decode.loss_ce: 0.2552  decode.acc_seg: 87.8805  aux.loss_ce: 0.1431  aux.acc_seg: 85.6000
2024/10/28 19:55:53 - mmengine - INFO - Iter(train) [69050/80000]  base_lr: 2.0858e-05 lr: 2.0858e-05  eta: 4:56:28  time: 1.6115  data_time: 0.0139  memory: 6599  grad_norm: 4.1384  loss: 0.4542  decode.loss_ce: 0.3130  decode.acc_seg: 82.0579  aux.loss_ce: 0.1412  aux.acc_seg: 83.1669
2024/10/28 19:57:14 - mmengine - INFO - Iter(train) [69100/80000]  base_lr: 2.0680e-05 lr: 2.0680e-05  eta: 4:55:07  time: 1.6088  data_time: 0.0134  memory: 6599  grad_norm: 5.0407  loss: 0.4350  decode.loss_ce: 0.3008  decode.acc_seg: 88.7831  aux.loss_ce: 0.1342  aux.acc_seg: 87.5127
2024/10/28 19:58:35 - mmengine - INFO - Iter(train) [69150/80000]  base_lr: 2.0502e-05 lr: 2.0502e-05  eta: 4:53:46  time: 1.6207  data_time: 0.0137  memory: 6600  grad_norm: 4.8269  loss: 0.4054  decode.loss_ce: 0.2778  decode.acc_seg: 90.5433  aux.loss_ce: 0.1276  aux.acc_seg: 90.5383
2024/10/28 19:59:56 - mmengine - INFO - Iter(train) [69200/80000]  base_lr: 2.0325e-05 lr: 2.0325e-05  eta: 4:52:24  time: 1.6105  data_time: 0.0143  memory: 6599  grad_norm: 3.2633  loss: 0.4146  decode.loss_ce: 0.2860  decode.acc_seg: 88.2718  aux.loss_ce: 0.1286  aux.acc_seg: 87.2335
2024/10/28 20:01:17 - mmengine - INFO - Iter(train) [69250/80000]  base_lr: 2.0148e-05 lr: 2.0148e-05  eta: 4:51:03  time: 1.6083  data_time: 0.0140  memory: 6599  grad_norm: 4.0318  loss: 0.4091  decode.loss_ce: 0.2741  decode.acc_seg: 86.4699  aux.loss_ce: 0.1350  aux.acc_seg: 84.6559
2024/10/28 20:02:38 - mmengine - INFO - Iter(train) [69300/80000]  base_lr: 1.9973e-05 lr: 1.9973e-05  eta: 4:49:42  time: 1.6125  data_time: 0.0136  memory: 6600  grad_norm: 3.9269  loss: 0.4567  decode.loss_ce: 0.3192  decode.acc_seg: 93.5673  aux.loss_ce: 0.1376  aux.acc_seg: 92.7045
2024/10/28 20:03:58 - mmengine - INFO - Iter(train) [69350/80000]  base_lr: 1.9797e-05 lr: 1.9797e-05  eta: 4:48:20  time: 1.6130  data_time: 0.0136  memory: 6599  grad_norm: 3.6354  loss: 0.4142  decode.loss_ce: 0.2802  decode.acc_seg: 83.6216  aux.loss_ce: 0.1339  aux.acc_seg: 83.6623
2024/10/28 20:05:20 - mmengine - INFO - Iter(train) [69400/80000]  base_lr: 1.9623e-05 lr: 1.9623e-05  eta: 4:46:59  time: 1.6130  data_time: 0.0135  memory: 6600  grad_norm: 4.6254  loss: 0.4388  decode.loss_ce: 0.3004  decode.acc_seg: 82.1741  aux.loss_ce: 0.1384  aux.acc_seg: 81.4751
2024/10/28 20:06:41 - mmengine - INFO - Iter(train) [69450/80000]  base_lr: 1.9449e-05 lr: 1.9449e-05  eta: 4:45:38  time: 1.6345  data_time: 0.0134  memory: 6600  grad_norm: 5.2222  loss: 0.3794  decode.loss_ce: 0.2637  decode.acc_seg: 87.8590  aux.loss_ce: 0.1157  aux.acc_seg: 87.4296
2024/10/28 20:08:02 - mmengine - INFO - Iter(train) [69500/80000]  base_lr: 1.9275e-05 lr: 1.9275e-05  eta: 4:44:17  time: 1.6092  data_time: 0.0133  memory: 6600  grad_norm: 4.8778  loss: 0.4220  decode.loss_ce: 0.2959  decode.acc_seg: 86.7934  aux.loss_ce: 0.1261  aux.acc_seg: 84.6105
2024/10/28 20:09:26 - mmengine - INFO - Iter(train) [69550/80000]  base_lr: 1.9103e-05 lr: 1.9103e-05  eta: 4:42:56  time: 1.6108  data_time: 0.0132  memory: 6599  grad_norm: 3.9805  loss: 0.4163  decode.loss_ce: 0.2787  decode.acc_seg: 89.3314  aux.loss_ce: 0.1376  aux.acc_seg: 89.9621
2024/10/28 20:10:47 - mmengine - INFO - Iter(train) [69600/80000]  base_lr: 1.8931e-05 lr: 1.8931e-05  eta: 4:41:35  time: 1.6096  data_time: 0.0133  memory: 6599  grad_norm: 4.4873  loss: 0.3730  decode.loss_ce: 0.2582  decode.acc_seg: 88.6415  aux.loss_ce: 0.1148  aux.acc_seg: 89.7598
2024/10/28 20:12:07 - mmengine - INFO - Iter(train) [69650/80000]  base_lr: 1.8759e-05 lr: 1.8759e-05  eta: 4:40:13  time: 1.6092  data_time: 0.0133  memory: 6599  grad_norm: 4.4088  loss: 0.3995  decode.loss_ce: 0.2749  decode.acc_seg: 87.4923  aux.loss_ce: 0.1246  aux.acc_seg: 87.5880
2024/10/28 20:13:28 - mmengine - INFO - Iter(train) [69700/80000]  base_lr: 1.8588e-05 lr: 1.8588e-05  eta: 4:38:52  time: 1.6101  data_time: 0.0133  memory: 6599  grad_norm: 3.2137  loss: 0.4303  decode.loss_ce: 0.2893  decode.acc_seg: 90.7065  aux.loss_ce: 0.1410  aux.acc_seg: 86.1956
2024/10/28 20:14:48 - mmengine - INFO - Iter(train) [69750/80000]  base_lr: 1.8418e-05 lr: 1.8418e-05  eta: 4:37:31  time: 1.6097  data_time: 0.0135  memory: 6600  grad_norm: 3.8300  loss: 0.4171  decode.loss_ce: 0.2854  decode.acc_seg: 81.0031  aux.loss_ce: 0.1317  aux.acc_seg: 80.2348
2024/10/28 20:16:09 - mmengine - INFO - Iter(train) [69800/80000]  base_lr: 1.8249e-05 lr: 1.8249e-05  eta: 4:36:09  time: 1.6100  data_time: 0.0133  memory: 6599  grad_norm: 4.2636  loss: 0.4737  decode.loss_ce: 0.3217  decode.acc_seg: 91.2562  aux.loss_ce: 0.1520  aux.acc_seg: 91.1867
2024/10/28 20:17:29 - mmengine - INFO - Iter(train) [69850/80000]  base_lr: 1.8080e-05 lr: 1.8080e-05  eta: 4:34:48  time: 1.6111  data_time: 0.0136  memory: 6599  grad_norm: 3.4001  loss: 0.4297  decode.loss_ce: 0.2940  decode.acc_seg: 87.7800  aux.loss_ce: 0.1357  aux.acc_seg: 84.6665
2024/10/28 20:18:50 - mmengine - INFO - Iter(train) [69900/80000]  base_lr: 1.7911e-05 lr: 1.7911e-05  eta: 4:33:27  time: 1.6128  data_time: 0.0137  memory: 6599  grad_norm: 4.1218  loss: 0.4771  decode.loss_ce: 0.3278  decode.acc_seg: 84.9575  aux.loss_ce: 0.1493  aux.acc_seg: 86.8639
2024/10/28 20:20:11 - mmengine - INFO - Iter(train) [69950/80000]  base_lr: 1.7744e-05 lr: 1.7744e-05  eta: 4:32:05  time: 1.6372  data_time: 0.0130  memory: 6599  grad_norm: 4.6545  loss: 0.4251  decode.loss_ce: 0.2887  decode.acc_seg: 89.0228  aux.loss_ce: 0.1364  aux.acc_seg: 84.8760
2024/10/28 20:21:32 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 20:21:32 - mmengine - INFO - Iter(train) [70000/80000]  base_lr: 1.7577e-05 lr: 1.7577e-05  eta: 4:30:44  time: 1.6230  data_time: 0.0132  memory: 6599  grad_norm: 4.0239  loss: 0.3849  decode.loss_ce: 0.2620  decode.acc_seg: 93.2997  aux.loss_ce: 0.1229  aux.acc_seg: 93.3745
2024/10/28 20:22:53 - mmengine - INFO - Iter(train) [70050/80000]  base_lr: 1.7411e-05 lr: 1.7411e-05  eta: 4:29:23  time: 1.6111  data_time: 0.0134  memory: 6599  grad_norm: 6.7503  loss: 0.3657  decode.loss_ce: 0.2540  decode.acc_seg: 85.2737  aux.loss_ce: 0.1116  aux.acc_seg: 87.0093
2024/10/28 20:24:13 - mmengine - INFO - Iter(train) [70100/80000]  base_lr: 1.7245e-05 lr: 1.7245e-05  eta: 4:28:01  time: 1.6084  data_time: 0.0133  memory: 6600  grad_norm: 3.6699  loss: 0.3859  decode.loss_ce: 0.2578  decode.acc_seg: 87.6365  aux.loss_ce: 0.1281  aux.acc_seg: 81.3567
2024/10/28 20:25:34 - mmengine - INFO - Iter(train) [70150/80000]  base_lr: 1.7080e-05 lr: 1.7080e-05  eta: 4:26:40  time: 1.6117  data_time: 0.0134  memory: 6600  grad_norm: 4.1489  loss: 0.3980  decode.loss_ce: 0.2757  decode.acc_seg: 87.5007  aux.loss_ce: 0.1223  aux.acc_seg: 87.8994
2024/10/28 20:26:55 - mmengine - INFO - Iter(train) [70200/80000]  base_lr: 1.6916e-05 lr: 1.6916e-05  eta: 4:25:19  time: 1.6079  data_time: 0.0129  memory: 6598  grad_norm: 2.9804  loss: 0.4052  decode.loss_ce: 0.2789  decode.acc_seg: 88.0917  aux.loss_ce: 0.1263  aux.acc_seg: 85.4013
2024/10/28 20:28:16 - mmengine - INFO - Iter(train) [70250/80000]  base_lr: 1.6752e-05 lr: 1.6752e-05  eta: 4:23:57  time: 1.6119  data_time: 0.0133  memory: 6598  grad_norm: 3.8235  loss: 0.4200  decode.loss_ce: 0.2842  decode.acc_seg: 92.4628  aux.loss_ce: 0.1357  aux.acc_seg: 92.9239
2024/10/28 20:29:37 - mmengine - INFO - Iter(train) [70300/80000]  base_lr: 1.6589e-05 lr: 1.6589e-05  eta: 4:22:36  time: 1.6102  data_time: 0.0139  memory: 6599  grad_norm: 4.0838  loss: 0.4382  decode.loss_ce: 0.2942  decode.acc_seg: 88.1290  aux.loss_ce: 0.1440  aux.acc_seg: 84.2780
2024/10/28 20:30:57 - mmengine - INFO - Iter(train) [70350/80000]  base_lr: 1.6427e-05 lr: 1.6427e-05  eta: 4:21:15  time: 1.6097  data_time: 0.0136  memory: 6599  grad_norm: 4.2984  loss: 0.3673  decode.loss_ce: 0.2535  decode.acc_seg: 87.7951  aux.loss_ce: 0.1139  aux.acc_seg: 86.4694
2024/10/28 20:32:18 - mmengine - INFO - Iter(train) [70400/80000]  base_lr: 1.6265e-05 lr: 1.6265e-05  eta: 4:19:53  time: 1.6098  data_time: 0.0136  memory: 6599  grad_norm: 4.4270  loss: 0.3852  decode.loss_ce: 0.2679  decode.acc_seg: 93.5831  aux.loss_ce: 0.1173  aux.acc_seg: 91.2881
2024/10/28 20:33:39 - mmengine - INFO - Iter(train) [70450/80000]  base_lr: 1.6104e-05 lr: 1.6104e-05  eta: 4:18:32  time: 1.6140  data_time: 0.0139  memory: 6598  grad_norm: 3.6239  loss: 0.4504  decode.loss_ce: 0.3066  decode.acc_seg: 88.6295  aux.loss_ce: 0.1439  aux.acc_seg: 86.8427
2024/10/28 20:35:00 - mmengine - INFO - Iter(train) [70500/80000]  base_lr: 1.5944e-05 lr: 1.5944e-05  eta: 4:17:11  time: 1.6099  data_time: 0.0135  memory: 6598  grad_norm: 4.1446  loss: 0.4069  decode.loss_ce: 0.2778  decode.acc_seg: 91.0174  aux.loss_ce: 0.1291  aux.acc_seg: 90.6165
2024/10/28 20:36:21 - mmengine - INFO - Iter(train) [70550/80000]  base_lr: 1.5784e-05 lr: 1.5784e-05  eta: 4:15:50  time: 1.6080  data_time: 0.0132  memory: 6598  grad_norm: 3.3644  loss: 0.3605  decode.loss_ce: 0.2469  decode.acc_seg: 87.5701  aux.loss_ce: 0.1137  aux.acc_seg: 88.0184
2024/10/28 20:37:41 - mmengine - INFO - Iter(train) [70600/80000]  base_lr: 1.5625e-05 lr: 1.5625e-05  eta: 4:14:28  time: 1.6082  data_time: 0.0133  memory: 6600  grad_norm: 4.0844  loss: 0.4083  decode.loss_ce: 0.2755  decode.acc_seg: 90.9930  aux.loss_ce: 0.1328  aux.acc_seg: 87.1501
2024/10/28 20:39:02 - mmengine - INFO - Iter(train) [70650/80000]  base_lr: 1.5467e-05 lr: 1.5467e-05  eta: 4:13:07  time: 1.6098  data_time: 0.0134  memory: 6598  grad_norm: 3.7958  loss: 0.4530  decode.loss_ce: 0.3075  decode.acc_seg: 85.8839  aux.loss_ce: 0.1455  aux.acc_seg: 86.5005
2024/10/28 20:40:25 - mmengine - INFO - Iter(train) [70700/80000]  base_lr: 1.5310e-05 lr: 1.5310e-05  eta: 4:11:46  time: 1.6370  data_time: 0.0133  memory: 6600  grad_norm: 4.4971  loss: 0.4219  decode.loss_ce: 0.2759  decode.acc_seg: 87.5704  aux.loss_ce: 0.1460  aux.acc_seg: 88.5484
2024/10/28 20:41:46 - mmengine - INFO - Iter(train) [70750/80000]  base_lr: 1.5153e-05 lr: 1.5153e-05  eta: 4:10:25  time: 1.6123  data_time: 0.0134  memory: 6600  grad_norm: 3.3898  loss: 0.3863  decode.loss_ce: 0.2723  decode.acc_seg: 86.4901  aux.loss_ce: 0.1141  aux.acc_seg: 86.9077
2024/10/28 20:43:07 - mmengine - INFO - Iter(train) [70800/80000]  base_lr: 1.4996e-05 lr: 1.4996e-05  eta: 4:09:03  time: 1.6094  data_time: 0.0130  memory: 6598  grad_norm: 2.9885  loss: 0.4261  decode.loss_ce: 0.2894  decode.acc_seg: 84.1751  aux.loss_ce: 0.1366  aux.acc_seg: 85.8930
2024/10/28 20:44:28 - mmengine - INFO - Iter(train) [70850/80000]  base_lr: 1.4841e-05 lr: 1.4841e-05  eta: 4:07:42  time: 1.6091  data_time: 0.0129  memory: 6599  grad_norm: 3.6740  loss: 0.4176  decode.loss_ce: 0.2822  decode.acc_seg: 89.9751  aux.loss_ce: 0.1353  aux.acc_seg: 89.9923
2024/10/28 20:45:48 - mmengine - INFO - Iter(train) [70900/80000]  base_lr: 1.4686e-05 lr: 1.4686e-05  eta: 4:06:21  time: 1.6100  data_time: 0.0128  memory: 6599  grad_norm: 5.2195  loss: 0.3657  decode.loss_ce: 0.2515  decode.acc_seg: 86.8147  aux.loss_ce: 0.1142  aux.acc_seg: 86.5276
2024/10/28 20:47:09 - mmengine - INFO - Iter(train) [70950/80000]  base_lr: 1.4532e-05 lr: 1.4532e-05  eta: 4:04:59  time: 1.6107  data_time: 0.0128  memory: 6600  grad_norm: 4.3974  loss: 0.3917  decode.loss_ce: 0.2602  decode.acc_seg: 89.0055  aux.loss_ce: 0.1315  aux.acc_seg: 86.8541
2024/10/28 20:48:30 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 20:48:30 - mmengine - INFO - Iter(train) [71000/80000]  base_lr: 1.4379e-05 lr: 1.4379e-05  eta: 4:03:38  time: 1.6106  data_time: 0.0131  memory: 6600  grad_norm: 4.5933  loss: 0.3758  decode.loss_ce: 0.2536  decode.acc_seg: 88.5099  aux.loss_ce: 0.1223  aux.acc_seg: 84.4849
2024/10/28 20:49:50 - mmengine - INFO - Iter(train) [71050/80000]  base_lr: 1.4226e-05 lr: 1.4226e-05  eta: 4:02:17  time: 1.6083  data_time: 0.0129  memory: 6599  grad_norm: 4.4330  loss: 0.4473  decode.loss_ce: 0.3014  decode.acc_seg: 90.0493  aux.loss_ce: 0.1460  aux.acc_seg: 88.7806
2024/10/28 20:51:11 - mmengine - INFO - Iter(train) [71100/80000]  base_lr: 1.4074e-05 lr: 1.4074e-05  eta: 4:00:56  time: 1.6118  data_time: 0.0130  memory: 6598  grad_norm: 2.9818  loss: 0.4304  decode.loss_ce: 0.2847  decode.acc_seg: 90.5020  aux.loss_ce: 0.1457  aux.acc_seg: 86.7438
2024/10/28 20:52:32 - mmengine - INFO - Iter(train) [71150/80000]  base_lr: 1.3923e-05 lr: 1.3923e-05  eta: 3:59:34  time: 1.6122  data_time: 0.0132  memory: 6599  grad_norm: 4.3991  loss: 0.4572  decode.loss_ce: 0.3118  decode.acc_seg: 84.9609  aux.loss_ce: 0.1454  aux.acc_seg: 85.5886
2024/10/28 20:53:54 - mmengine - INFO - Iter(train) [71200/80000]  base_lr: 1.3772e-05 lr: 1.3772e-05  eta: 3:58:13  time: 1.6359  data_time: 0.0126  memory: 6600  grad_norm: 3.5351  loss: 0.3623  decode.loss_ce: 0.2534  decode.acc_seg: 85.7377  aux.loss_ce: 0.1089  aux.acc_seg: 82.0726
2024/10/28 20:55:15 - mmengine - INFO - Iter(train) [71250/80000]  base_lr: 1.3622e-05 lr: 1.3622e-05  eta: 3:56:52  time: 1.6094  data_time: 0.0127  memory: 6600  grad_norm: 4.1930  loss: 0.4167  decode.loss_ce: 0.2868  decode.acc_seg: 88.8118  aux.loss_ce: 0.1298  aux.acc_seg: 89.6248
2024/10/28 20:56:35 - mmengine - INFO - Iter(train) [71300/80000]  base_lr: 1.3473e-05 lr: 1.3473e-05  eta: 3:55:31  time: 1.6139  data_time: 0.0130  memory: 6600  grad_norm: 3.5020  loss: 0.4191  decode.loss_ce: 0.2845  decode.acc_seg: 90.7785  aux.loss_ce: 0.1346  aux.acc_seg: 89.7273
2024/10/28 20:57:56 - mmengine - INFO - Iter(train) [71350/80000]  base_lr: 1.3325e-05 lr: 1.3325e-05  eta: 3:54:09  time: 1.6091  data_time: 0.0129  memory: 6600  grad_norm: 3.5767  loss: 0.5036  decode.loss_ce: 0.3442  decode.acc_seg: 83.4739  aux.loss_ce: 0.1594  aux.acc_seg: 82.4874
2024/10/28 20:59:17 - mmengine - INFO - Iter(train) [71400/80000]  base_lr: 1.3177e-05 lr: 1.3177e-05  eta: 3:52:48  time: 1.6077  data_time: 0.0129  memory: 6599  grad_norm: 5.5303  loss: 0.4168  decode.loss_ce: 0.2776  decode.acc_seg: 90.5526  aux.loss_ce: 0.1392  aux.acc_seg: 88.0206
2024/10/28 21:00:37 - mmengine - INFO - Iter(train) [71450/80000]  base_lr: 1.3030e-05 lr: 1.3030e-05  eta: 3:51:27  time: 1.6148  data_time: 0.0128  memory: 6600  grad_norm: 4.2017  loss: 0.4166  decode.loss_ce: 0.2847  decode.acc_seg: 83.3297  aux.loss_ce: 0.1319  aux.acc_seg: 84.1871
2024/10/28 21:01:58 - mmengine - INFO - Iter(train) [71500/80000]  base_lr: 1.2884e-05 lr: 1.2884e-05  eta: 3:50:05  time: 1.6090  data_time: 0.0126  memory: 6598  grad_norm: 4.3881  loss: 0.4108  decode.loss_ce: 0.2799  decode.acc_seg: 87.5768  aux.loss_ce: 0.1309  aux.acc_seg: 86.8564
2024/10/28 21:03:19 - mmengine - INFO - Iter(train) [71550/80000]  base_lr: 1.2738e-05 lr: 1.2738e-05  eta: 3:48:44  time: 1.6097  data_time: 0.0133  memory: 6599  grad_norm: 4.6589  loss: 0.3900  decode.loss_ce: 0.2644  decode.acc_seg: 86.7881  aux.loss_ce: 0.1256  aux.acc_seg: 83.3183
2024/10/28 21:04:40 - mmengine - INFO - Iter(train) [71600/80000]  base_lr: 1.2594e-05 lr: 1.2594e-05  eta: 3:47:23  time: 1.6134  data_time: 0.0137  memory: 6600  grad_norm: 4.9433  loss: 0.4123  decode.loss_ce: 0.2844  decode.acc_seg: 89.7755  aux.loss_ce: 0.1279  aux.acc_seg: 88.6486
2024/10/28 21:06:02 - mmengine - INFO - Iter(train) [71650/80000]  base_lr: 1.2450e-05 lr: 1.2450e-05  eta: 3:46:02  time: 1.6155  data_time: 0.0134  memory: 6598  grad_norm: 4.2094  loss: 0.4151  decode.loss_ce: 0.2806  decode.acc_seg: 90.8739  aux.loss_ce: 0.1345  aux.acc_seg: 90.9752
2024/10/28 21:07:25 - mmengine - INFO - Iter(train) [71700/80000]  base_lr: 1.2306e-05 lr: 1.2306e-05  eta: 3:44:41  time: 1.6111  data_time: 0.0131  memory: 6598  grad_norm: 3.5216  loss: 0.4714  decode.loss_ce: 0.3040  decode.acc_seg: 86.4577  aux.loss_ce: 0.1674  aux.acc_seg: 79.7568
2024/10/28 21:08:46 - mmengine - INFO - Iter(train) [71750/80000]  base_lr: 1.2164e-05 lr: 1.2164e-05  eta: 3:43:20  time: 1.6111  data_time: 0.0134  memory: 6599  grad_norm: 2.7329  loss: 0.4309  decode.loss_ce: 0.2939  decode.acc_seg: 86.4578  aux.loss_ce: 0.1370  aux.acc_seg: 85.1614
2024/10/28 21:10:07 - mmengine - INFO - Iter(train) [71800/80000]  base_lr: 1.2022e-05 lr: 1.2022e-05  eta: 3:41:58  time: 1.6245  data_time: 0.0131  memory: 6600  grad_norm: 4.4308  loss: 0.4542  decode.loss_ce: 0.3076  decode.acc_seg: 88.9739  aux.loss_ce: 0.1466  aux.acc_seg: 90.0476
2024/10/28 21:11:28 - mmengine - INFO - Iter(train) [71850/80000]  base_lr: 1.1881e-05 lr: 1.1881e-05  eta: 3:40:37  time: 1.6117  data_time: 0.0131  memory: 6598  grad_norm: 3.3623  loss: 0.4093  decode.loss_ce: 0.2808  decode.acc_seg: 90.9505  aux.loss_ce: 0.1285  aux.acc_seg: 90.2665
2024/10/28 21:12:49 - mmengine - INFO - Iter(train) [71900/80000]  base_lr: 1.1740e-05 lr: 1.1740e-05  eta: 3:39:16  time: 1.6099  data_time: 0.0131  memory: 6598  grad_norm: 3.3200  loss: 0.4497  decode.loss_ce: 0.3023  decode.acc_seg: 87.9902  aux.loss_ce: 0.1474  aux.acc_seg: 88.5137
2024/10/28 21:14:09 - mmengine - INFO - Iter(train) [71950/80000]  base_lr: 1.1601e-05 lr: 1.1601e-05  eta: 3:37:55  time: 1.6256  data_time: 0.0131  memory: 6600  grad_norm: 5.3088  loss: 0.4072  decode.loss_ce: 0.2720  decode.acc_seg: 86.6964  aux.loss_ce: 0.1352  aux.acc_seg: 85.7576
2024/10/28 21:15:31 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 21:15:31 - mmengine - INFO - Iter(train) [72000/80000]  base_lr: 1.1462e-05 lr: 1.1462e-05  eta: 3:36:33  time: 1.6111  data_time: 0.0129  memory: 6600  grad_norm: 3.1395  loss: 0.3615  decode.loss_ce: 0.2392  decode.acc_seg: 83.3329  aux.loss_ce: 0.1223  aux.acc_seg: 86.4811
2024/10/28 21:15:31 - mmengine - INFO - Saving checkpoint at 72000 iterations
2024/10/28 21:15:35 - mmengine - INFO - Iter(val) [ 50/500]    eta: 0:00:14  time: 0.0323  data_time: 0.0022  memory: 1007  
2024/10/28 21:15:37 - mmengine - INFO - Iter(val) [100/500]    eta: 0:00:12  time: 0.0308  data_time: 0.0020  memory: 1077  
2024/10/28 21:15:39 - mmengine - INFO - Iter(val) [150/500]    eta: 0:00:11  time: 0.0332  data_time: 0.0022  memory: 792  
2024/10/28 21:15:40 - mmengine - INFO - Iter(val) [200/500]    eta: 0:00:09  time: 0.0311  data_time: 0.0018  memory: 825  
2024/10/28 21:15:41 - mmengine - INFO - Iter(val) [250/500]    eta: 0:00:07  time: 0.0288  data_time: 0.0015  memory: 865  
2024/10/28 21:15:43 - mmengine - INFO - Iter(val) [300/500]    eta: 0:00:06  time: 0.0288  data_time: 0.0015  memory: 1988  
2024/10/28 21:15:44 - mmengine - INFO - Iter(val) [350/500]    eta: 0:00:04  time: 0.0278  data_time: 0.0012  memory: 791  
2024/10/28 21:15:46 - mmengine - INFO - Iter(val) [400/500]    eta: 0:00:02  time: 0.0289  data_time: 0.0013  memory: 863  
2024/10/28 21:15:47 - mmengine - INFO - Iter(val) [450/500]    eta: 0:00:01  time: 0.0287  data_time: 0.0012  memory: 798  
2024/10/28 21:15:49 - mmengine - INFO - Iter(val) [500/500]    eta: 0:00:00  time: 0.0292  data_time: 0.0013  memory: 847  
2024/10/28 21:15:50 - mmengine - INFO - per class results:
2024/10/28 21:15:50 - mmengine - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 66.38 | 83.71 |
|       building      | 76.42 | 89.16 |
|         sky         | 89.26 | 95.05 |
|        floor        | 70.53 |  85.7 |
|         tree        | 65.71 | 82.53 |
|       ceiling       | 76.92 | 86.41 |
|         road        | 79.69 |  87.9 |
|         bed         | 78.92 | 88.03 |
|      windowpane     | 51.87 | 66.72 |
|        grass        | 57.44 | 75.51 |
|       cabinet       | 51.44 | 64.91 |
|       sidewalk      | 59.45 | 75.36 |
|        person       | 60.38 | 78.82 |
|        earth        | 29.01 | 42.09 |
|         door        | 33.69 | 49.23 |
|        table        | 45.35 | 63.76 |
|       mountain      | 52.32 | 66.44 |
|        plant        | 41.55 |  51.4 |
|       curtain       |  56.2 | 72.56 |
|        chair        | 40.54 | 53.38 |
|         car         | 71.18 | 84.33 |
|        water        | 44.76 | 55.98 |
|       painting      | 52.19 | 67.84 |
|         sofa        | 56.71 |  75.8 |
|        shelf        | 29.82 | 43.04 |
|        house        |  42.8 | 55.98 |
|         sea         |  47.7 | 72.07 |
|        mirror       | 54.55 | 64.54 |
|         rug         | 49.05 |  62.0 |
|        field        | 22.31 | 38.46 |
|       armchair      | 37.94 | 52.83 |
|         seat        | 57.52 | 75.09 |
|        fence        | 33.36 | 50.43 |
|         desk        | 41.25 | 57.68 |
|         rock        | 31.01 |  46.3 |
|       wardrobe      | 43.35 | 65.68 |
|         lamp        | 31.84 | 40.38 |
|       bathtub       | 67.63 | 74.57 |
|       railing       | 24.14 |  33.0 |
|       cushion       | 34.98 | 44.15 |
|         base        | 11.15 | 15.61 |
|         box         | 14.23 | 19.26 |
|        column       | 23.93 | 34.49 |
|      signboard      | 18.09 | 24.29 |
|   chest of drawers  | 34.48 | 51.47 |
|       counter       | 26.61 | 35.31 |
|         sand        | 34.15 | 49.66 |
|         sink        | 51.72 | 64.54 |
|      skyscraper     | 55.39 |  63.8 |
|      fireplace      |  64.2 | 76.82 |
|     refrigerator    |  62.9 | 74.47 |
|      grandstand     | 33.81 | 79.07 |
|         path        | 16.84 | 27.74 |
|        stairs       | 27.74 | 33.12 |
|        runway       | 66.34 | 89.62 |
|         case        | 43.62 | 67.49 |
|      pool table     | 73.97 | 83.51 |
|        pillow       | 42.21 | 53.54 |
|     screen door     | 61.39 | 67.75 |
|       stairway      |  25.5 | 34.76 |
|        river        |  10.7 | 28.54 |
|        bridge       | 29.04 | 32.36 |
|       bookcase      | 32.98 | 50.67 |
|        blind        | 37.18 | 45.91 |
|     coffee table    | 45.14 |  64.6 |
|        toilet       | 65.28 | 77.54 |
|        flower       | 23.51 | 41.23 |
|         book        |  29.5 | 46.66 |
|         hill        | 10.63 | 17.89 |
|        bench        | 36.11 | 44.51 |
|      countertop     | 44.55 | 59.32 |
|        stove        | 61.54 | 68.87 |
|         palm        | 38.55 | 57.61 |
|    kitchen island   | 29.06 |  55.1 |
|       computer      | 47.97 |  58.7 |
|     swivel chair    | 32.35 | 47.09 |
|         boat        | 53.12 | 76.23 |
|         bar         | 38.94 | 48.95 |
|    arcade machine   | 52.18 | 57.55 |
|        hovel        | 19.83 |  21.3 |
|         bus         | 70.67 | 76.93 |
|        towel        | 36.49 | 45.25 |
|        light        | 11.63 | 13.06 |
|        truck        | 20.42 |  25.4 |
|        tower        |  31.4 |  59.9 |
|      chandelier     | 44.95 | 55.79 |
|        awning       | 13.64 | 17.32 |
|     streetlight     |  4.44 |  5.31 |
|        booth        | 50.13 | 53.76 |
| television receiver | 54.31 | 64.94 |
|       airplane      | 32.61 |  53.2 |
|      dirt track     |  4.78 | 21.65 |
|       apparel       | 24.54 | 32.82 |
|         pole        |  4.92 |  9.32 |
|         land        |  0.34 |  0.51 |
|      bannister      |  2.91 |  3.63 |
|      escalator      | 17.47 |  21.0 |
|       ottoman       | 27.69 |  38.4 |
|        bottle       | 24.31 | 40.38 |
|        buffet       | 40.01 | 45.13 |
|        poster       | 25.76 | 32.61 |
|        stage        | 11.97 | 18.56 |
|         van         | 23.38 |  31.7 |
|         ship        | 13.22 | 18.38 |
|       fountain      | 20.26 | 20.53 |
|    conveyer belt    | 60.02 | 76.76 |
|        canopy       | 17.75 | 24.89 |
|        washer       | 61.14 | 62.81 |
|      plaything      | 10.63 | 17.78 |
|    swimming pool    | 51.32 | 63.66 |
|        stool        | 21.14 | 30.77 |
|        barrel       | 22.24 |  64.5 |
|        basket       | 12.45 | 16.42 |
|      waterfall      | 38.54 | 52.84 |
|         tent        |  75.6 | 94.49 |
|         bag         |  9.97 | 13.83 |
|       minibike      | 48.55 | 67.03 |
|        cradle       | 66.75 | 88.31 |
|         oven        | 22.12 |  45.4 |
|         ball        | 39.79 | 52.15 |
|         food        |  27.1 | 33.19 |
|         step        |  6.15 |  6.78 |
|         tank        | 42.35 | 48.97 |
|      trade name     | 12.79 | 14.26 |
|      microwave      |  31.1 | 34.22 |
|         pot         | 17.84 | 20.65 |
|        animal       | 37.35 | 43.72 |
|       bicycle       | 36.44 | 50.44 |
|         lake        | 63.48 | 67.52 |
|      dishwasher     | 52.85 | 62.95 |
|        screen       | 52.81 | 76.89 |
|       blanket       |  4.16 |  4.4  |
|      sculpture      | 43.89 | 54.48 |
|         hood        | 43.65 | 51.98 |
|        sconce       | 17.62 |  19.5 |
|         vase        | 13.93 | 18.83 |
|    traffic light    | 16.13 | 21.31 |
|         tray        |  2.35 |  4.03 |
|        ashcan       | 23.65 | 32.84 |
|         fan         | 28.14 | 35.45 |
|         pier        | 31.19 | 40.12 |
|      crt screen     |  5.4  | 13.56 |
|        plate        | 29.68 | 40.94 |
|       monitor       |  2.15 |  3.11 |
|    bulletin board   | 29.32 | 35.14 |
|        shower       |  0.0  |  0.0  |
|       radiator      | 31.85 | 37.43 |
|        glass        |  2.56 |  2.87 |
|        clock        |  4.23 |  6.32 |
|         flag        | 25.33 | 26.69 |
+---------------------+-------+-------+
2024/10/28 21:15:50 - mmengine - INFO - Iter(val) [500/500]    aAcc: 76.0600  mIoU: 36.6000  mAcc: 47.6800  data_time: 0.0016  time: 0.0297
2024/10/28 21:17:11 - mmengine - INFO - Iter(train) [72050/80000]  base_lr: 1.1324e-05 lr: 1.1324e-05  eta: 3:35:12  time: 1.6128  data_time: 0.0131  memory: 6598  grad_norm: 4.7651  loss: 0.5070  decode.loss_ce: 0.3487  decode.acc_seg: 84.8843  aux.loss_ce: 0.1584  aux.acc_seg: 86.2085
2024/10/28 21:18:32 - mmengine - INFO - Iter(train) [72100/80000]  base_lr: 1.1186e-05 lr: 1.1186e-05  eta: 3:33:51  time: 1.6118  data_time: 0.0134  memory: 6600  grad_norm: 3.3638  loss: 0.3958  decode.loss_ce: 0.2655  decode.acc_seg: 87.6899  aux.loss_ce: 0.1303  aux.acc_seg: 90.5028
2024/10/28 21:19:53 - mmengine - INFO - Iter(train) [72150/80000]  base_lr: 1.1050e-05 lr: 1.1050e-05  eta: 3:32:30  time: 1.6104  data_time: 0.0136  memory: 6599  grad_norm: 5.6767  loss: 0.4144  decode.loss_ce: 0.2800  decode.acc_seg: 90.7073  aux.loss_ce: 0.1344  aux.acc_seg: 91.2875
2024/10/28 21:21:14 - mmengine - INFO - Iter(train) [72200/80000]  base_lr: 1.0914e-05 lr: 1.0914e-05  eta: 3:31:08  time: 1.6095  data_time: 0.0131  memory: 6600  grad_norm: 5.1433  loss: 0.3782  decode.loss_ce: 0.2570  decode.acc_seg: 89.2114  aux.loss_ce: 0.1212  aux.acc_seg: 86.5053
2024/10/28 21:22:35 - mmengine - INFO - Iter(train) [72250/80000]  base_lr: 1.0779e-05 lr: 1.0779e-05  eta: 3:29:47  time: 1.6124  data_time: 0.0132  memory: 6601  grad_norm: 4.0413  loss: 0.3853  decode.loss_ce: 0.2591  decode.acc_seg: 89.9775  aux.loss_ce: 0.1262  aux.acc_seg: 90.3832
2024/10/28 21:23:56 - mmengine - INFO - Iter(train) [72300/80000]  base_lr: 1.0644e-05 lr: 1.0644e-05  eta: 3:28:26  time: 1.6123  data_time: 0.0127  memory: 6598  grad_norm: 3.9663  loss: 0.3859  decode.loss_ce: 0.2638  decode.acc_seg: 88.7785  aux.loss_ce: 0.1221  aux.acc_seg: 87.4698
2024/10/28 21:25:16 - mmengine - INFO - Iter(train) [72350/80000]  base_lr: 1.0511e-05 lr: 1.0511e-05  eta: 3:27:05  time: 1.6088  data_time: 0.0127  memory: 6600  grad_norm: 5.2508  loss: 0.4202  decode.loss_ce: 0.2918  decode.acc_seg: 87.0735  aux.loss_ce: 0.1284  aux.acc_seg: 85.5107
2024/10/28 21:26:37 - mmengine - INFO - Iter(train) [72400/80000]  base_lr: 1.0378e-05 lr: 1.0378e-05  eta: 3:25:43  time: 1.6147  data_time: 0.0142  memory: 6600  grad_norm: 3.8557  loss: 0.4122  decode.loss_ce: 0.2686  decode.acc_seg: 87.6557  aux.loss_ce: 0.1435  aux.acc_seg: 85.4213
2024/10/28 21:27:58 - mmengine - INFO - Iter(train) [72450/80000]  base_lr: 1.0246e-05 lr: 1.0246e-05  eta: 3:24:22  time: 1.6097  data_time: 0.0127  memory: 6598  grad_norm: 3.7256  loss: 0.3924  decode.loss_ce: 0.2635  decode.acc_seg: 90.2943  aux.loss_ce: 0.1289  aux.acc_seg: 90.5959
2024/10/28 21:29:19 - mmengine - INFO - Iter(train) [72500/80000]  base_lr: 1.0114e-05 lr: 1.0114e-05  eta: 3:23:01  time: 1.6097  data_time: 0.0133  memory: 6600  grad_norm: 2.5271  loss: 0.4121  decode.loss_ce: 0.2766  decode.acc_seg: 90.2229  aux.loss_ce: 0.1355  aux.acc_seg: 90.1649
2024/10/28 21:30:40 - mmengine - INFO - Iter(train) [72550/80000]  base_lr: 9.9839e-06 lr: 9.9839e-06  eta: 3:21:40  time: 1.6113  data_time: 0.0129  memory: 6598  grad_norm: 3.4057  loss: 0.4402  decode.loss_ce: 0.2997  decode.acc_seg: 92.7321  aux.loss_ce: 0.1405  aux.acc_seg: 92.1937
2024/10/28 21:32:00 - mmengine - INFO - Iter(train) [72600/80000]  base_lr: 9.8541e-06 lr: 9.8541e-06  eta: 3:20:18  time: 1.6090  data_time: 0.0124  memory: 6600  grad_norm: 4.4607  loss: 0.4398  decode.loss_ce: 0.3024  decode.acc_seg: 88.6589  aux.loss_ce: 0.1374  aux.acc_seg: 91.1438
2024/10/28 21:33:21 - mmengine - INFO - Iter(train) [72650/80000]  base_lr: 9.7252e-06 lr: 9.7252e-06  eta: 3:18:57  time: 1.6111  data_time: 0.0134  memory: 6600  grad_norm: 4.6162  loss: 0.4519  decode.loss_ce: 0.3045  decode.acc_seg: 90.7148  aux.loss_ce: 0.1474  aux.acc_seg: 82.9808
2024/10/28 21:34:42 - mmengine - INFO - Iter(train) [72700/80000]  base_lr: 9.5969e-06 lr: 9.5969e-06  eta: 3:17:36  time: 1.6120  data_time: 0.0137  memory: 6598  grad_norm: 4.6213  loss: 0.4124  decode.loss_ce: 0.2826  decode.acc_seg: 85.7111  aux.loss_ce: 0.1298  aux.acc_seg: 83.6709
2024/10/28 21:36:03 - mmengine - INFO - Iter(train) [72750/80000]  base_lr: 9.4695e-06 lr: 9.4695e-06  eta: 3:16:15  time: 1.6157  data_time: 0.0144  memory: 6599  grad_norm: 3.3149  loss: 0.4482  decode.loss_ce: 0.3000  decode.acc_seg: 88.1796  aux.loss_ce: 0.1482  aux.acc_seg: 88.5640
2024/10/28 21:37:26 - mmengine - INFO - Iter(train) [72800/80000]  base_lr: 9.3428e-06 lr: 9.3428e-06  eta: 3:14:54  time: 1.6138  data_time: 0.0141  memory: 6598  grad_norm: 4.0081  loss: 0.4619  decode.loss_ce: 0.3133  decode.acc_seg: 87.9416  aux.loss_ce: 0.1486  aux.acc_seg: 87.0857
2024/10/28 21:38:47 - mmengine - INFO - Iter(train) [72850/80000]  base_lr: 9.2170e-06 lr: 9.2170e-06  eta: 3:13:32  time: 1.6135  data_time: 0.0134  memory: 6599  grad_norm: 4.2480  loss: 0.3949  decode.loss_ce: 0.2660  decode.acc_seg: 89.4771  aux.loss_ce: 0.1289  aux.acc_seg: 85.6213
2024/10/28 21:40:07 - mmengine - INFO - Iter(train) [72900/80000]  base_lr: 9.0919e-06 lr: 9.0919e-06  eta: 3:12:11  time: 1.6132  data_time: 0.0138  memory: 6599  grad_norm: 3.4175  loss: 0.4212  decode.loss_ce: 0.2881  decode.acc_seg: 91.5327  aux.loss_ce: 0.1331  aux.acc_seg: 91.1952
2024/10/28 21:41:28 - mmengine - INFO - Iter(train) [72950/80000]  base_lr: 8.9676e-06 lr: 8.9676e-06  eta: 3:10:50  time: 1.6138  data_time: 0.0136  memory: 6600  grad_norm: 4.1619  loss: 0.4257  decode.loss_ce: 0.2870  decode.acc_seg: 84.9767  aux.loss_ce: 0.1387  aux.acc_seg: 83.3352
2024/10/28 21:42:49 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 21:42:49 - mmengine - INFO - Iter(train) [73000/80000]  base_lr: 8.8441e-06 lr: 8.8441e-06  eta: 3:09:29  time: 1.6136  data_time: 0.0139  memory: 6599  grad_norm: 3.6974  loss: 0.4424  decode.loss_ce: 0.2997  decode.acc_seg: 86.3859  aux.loss_ce: 0.1426  aux.acc_seg: 84.9986
2024/10/28 21:44:10 - mmengine - INFO - Iter(train) [73050/80000]  base_lr: 8.7213e-06 lr: 8.7213e-06  eta: 3:08:07  time: 1.6111  data_time: 0.0134  memory: 6599  grad_norm: 4.6244  loss: 0.4376  decode.loss_ce: 0.3029  decode.acc_seg: 90.6787  aux.loss_ce: 0.1348  aux.acc_seg: 88.3835
2024/10/28 21:45:31 - mmengine - INFO - Iter(train) [73100/80000]  base_lr: 8.5994e-06 lr: 8.5994e-06  eta: 3:06:46  time: 1.6130  data_time: 0.0133  memory: 6602  grad_norm: 4.9855  loss: 0.3688  decode.loss_ce: 0.2531  decode.acc_seg: 82.2925  aux.loss_ce: 0.1157  aux.acc_seg: 81.3820
2024/10/28 21:46:52 - mmengine - INFO - Iter(train) [73150/80000]  base_lr: 8.4782e-06 lr: 8.4782e-06  eta: 3:05:25  time: 1.6132  data_time: 0.0139  memory: 6599  grad_norm: 3.5641  loss: 0.3907  decode.loss_ce: 0.2691  decode.acc_seg: 91.6977  aux.loss_ce: 0.1215  aux.acc_seg: 89.9937
2024/10/28 21:48:13 - mmengine - INFO - Iter(train) [73200/80000]  base_lr: 8.3579e-06 lr: 8.3579e-06  eta: 3:04:04  time: 1.6101  data_time: 0.0132  memory: 6599  grad_norm: 3.3083  loss: 0.4134  decode.loss_ce: 0.2712  decode.acc_seg: 87.7322  aux.loss_ce: 0.1422  aux.acc_seg: 86.7085
2024/10/28 21:49:34 - mmengine - INFO - Iter(train) [73250/80000]  base_lr: 8.2383e-06 lr: 8.2383e-06  eta: 3:02:42  time: 1.6101  data_time: 0.0128  memory: 6600  grad_norm: 2.6699  loss: 0.3674  decode.loss_ce: 0.2444  decode.acc_seg: 90.2575  aux.loss_ce: 0.1231  aux.acc_seg: 88.1509
2024/10/28 21:50:54 - mmengine - INFO - Iter(train) [73300/80000]  base_lr: 8.1196e-06 lr: 8.1196e-06  eta: 3:01:21  time: 1.6091  data_time: 0.0129  memory: 6600  grad_norm: 5.7067  loss: 0.3453  decode.loss_ce: 0.2360  decode.acc_seg: 94.3211  aux.loss_ce: 0.1093  aux.acc_seg: 93.8427
2024/10/28 21:52:15 - mmengine - INFO - Iter(train) [73350/80000]  base_lr: 8.0016e-06 lr: 8.0016e-06  eta: 3:00:00  time: 1.6110  data_time: 0.0126  memory: 6599  grad_norm: 3.5860  loss: 0.4125  decode.loss_ce: 0.2788  decode.acc_seg: 90.3195  aux.loss_ce: 0.1337  aux.acc_seg: 90.7874
2024/10/28 21:53:36 - mmengine - INFO - Iter(train) [73400/80000]  base_lr: 7.8844e-06 lr: 7.8844e-06  eta: 2:58:38  time: 1.6132  data_time: 0.0131  memory: 6600  grad_norm: 6.0231  loss: 0.4261  decode.loss_ce: 0.2926  decode.acc_seg: 87.9576  aux.loss_ce: 0.1336  aux.acc_seg: 85.6021
2024/10/28 21:54:57 - mmengine - INFO - Iter(train) [73450/80000]  base_lr: 7.7681e-06 lr: 7.7681e-06  eta: 2:57:17  time: 1.6102  data_time: 0.0133  memory: 6599  grad_norm: 4.3815  loss: 0.3944  decode.loss_ce: 0.2746  decode.acc_seg: 88.5407  aux.loss_ce: 0.1198  aux.acc_seg: 90.7337
2024/10/28 21:56:17 - mmengine - INFO - Iter(train) [73500/80000]  base_lr: 7.6525e-06 lr: 7.6525e-06  eta: 2:55:56  time: 1.6090  data_time: 0.0129  memory: 6599  grad_norm: 2.9508  loss: 0.4186  decode.loss_ce: 0.2877  decode.acc_seg: 86.5409  aux.loss_ce: 0.1310  aux.acc_seg: 86.4889
2024/10/28 21:57:38 - mmengine - INFO - Iter(train) [73550/80000]  base_lr: 7.5378e-06 lr: 7.5378e-06  eta: 2:54:35  time: 1.6084  data_time: 0.0128  memory: 6600  grad_norm: 3.2373  loss: 0.4342  decode.loss_ce: 0.2926  decode.acc_seg: 91.4040  aux.loss_ce: 0.1416  aux.acc_seg: 91.9118
2024/10/28 21:58:59 - mmengine - INFO - Iter(train) [73600/80000]  base_lr: 7.4239e-06 lr: 7.4239e-06  eta: 2:53:13  time: 1.6097  data_time: 0.0127  memory: 6599  grad_norm: 4.0187  loss: 0.4141  decode.loss_ce: 0.2830  decode.acc_seg: 90.4663  aux.loss_ce: 0.1311  aux.acc_seg: 85.5267
2024/10/28 22:00:20 - mmengine - INFO - Iter(train) [73650/80000]  base_lr: 7.3107e-06 lr: 7.3107e-06  eta: 2:51:52  time: 1.6062  data_time: 0.0126  memory: 6599  grad_norm: 3.5934  loss: 0.3552  decode.loss_ce: 0.2471  decode.acc_seg: 92.7564  aux.loss_ce: 0.1082  aux.acc_seg: 92.6706
2024/10/28 22:01:41 - mmengine - INFO - Iter(train) [73700/80000]  base_lr: 7.1984e-06 lr: 7.1984e-06  eta: 2:50:31  time: 1.6084  data_time: 0.0124  memory: 6602  grad_norm: 4.5658  loss: 0.4684  decode.loss_ce: 0.3183  decode.acc_seg: 88.5084  aux.loss_ce: 0.1501  aux.acc_seg: 89.3555
2024/10/28 22:03:01 - mmengine - INFO - Iter(train) [73750/80000]  base_lr: 7.0869e-06 lr: 7.0869e-06  eta: 2:49:10  time: 1.6129  data_time: 0.0126  memory: 6599  grad_norm: 4.8233  loss: 0.3563  decode.loss_ce: 0.2446  decode.acc_seg: 86.0543  aux.loss_ce: 0.1117  aux.acc_seg: 86.5281
2024/10/28 22:04:25 - mmengine - INFO - Iter(train) [73800/80000]  base_lr: 6.9763e-06 lr: 6.9763e-06  eta: 2:47:49  time: 1.6076  data_time: 0.0124  memory: 6597  grad_norm: 3.6208  loss: 0.3852  decode.loss_ce: 0.2610  decode.acc_seg: 88.8238  aux.loss_ce: 0.1242  aux.acc_seg: 89.5034
2024/10/28 22:05:46 - mmengine - INFO - Iter(train) [73850/80000]  base_lr: 6.8664e-06 lr: 6.8664e-06  eta: 2:46:28  time: 1.6109  data_time: 0.0128  memory: 6599  grad_norm: 6.8130  loss: 0.3948  decode.loss_ce: 0.2744  decode.acc_seg: 80.9990  aux.loss_ce: 0.1204  aux.acc_seg: 81.7932
2024/10/28 22:07:06 - mmengine - INFO - Iter(train) [73900/80000]  base_lr: 6.7574e-06 lr: 6.7574e-06  eta: 2:45:06  time: 1.6099  data_time: 0.0126  memory: 6599  grad_norm: 3.6126  loss: 0.4138  decode.loss_ce: 0.2813  decode.acc_seg: 89.9654  aux.loss_ce: 0.1325  aux.acc_seg: 87.9513
2024/10/28 22:08:27 - mmengine - INFO - Iter(train) [73950/80000]  base_lr: 6.6491e-06 lr: 6.6491e-06  eta: 2:43:45  time: 1.6101  data_time: 0.0130  memory: 6601  grad_norm: 3.5203  loss: 0.4618  decode.loss_ce: 0.3145  decode.acc_seg: 91.3183  aux.loss_ce: 0.1473  aux.acc_seg: 91.6269
2024/10/28 22:09:48 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 22:09:48 - mmengine - INFO - Iter(train) [74000/80000]  base_lr: 6.5417e-06 lr: 6.5417e-06  eta: 2:42:24  time: 1.6087  data_time: 0.0126  memory: 6601  grad_norm: 3.0208  loss: 0.4116  decode.loss_ce: 0.2794  decode.acc_seg: 88.6171  aux.loss_ce: 0.1321  aux.acc_seg: 87.9553
2024/10/28 22:11:09 - mmengine - INFO - Iter(train) [74050/80000]  base_lr: 6.4352e-06 lr: 6.4352e-06  eta: 2:41:02  time: 1.6094  data_time: 0.0127  memory: 6599  grad_norm: 3.7813  loss: 0.3474  decode.loss_ce: 0.2413  decode.acc_seg: 91.8601  aux.loss_ce: 0.1061  aux.acc_seg: 89.9267
2024/10/28 22:12:29 - mmengine - INFO - Iter(train) [74100/80000]  base_lr: 6.3294e-06 lr: 6.3294e-06  eta: 2:39:41  time: 1.6132  data_time: 0.0131  memory: 6600  grad_norm: 3.8558  loss: 0.4043  decode.loss_ce: 0.2768  decode.acc_seg: 91.0646  aux.loss_ce: 0.1275  aux.acc_seg: 90.3917
2024/10/28 22:13:50 - mmengine - INFO - Iter(train) [74150/80000]  base_lr: 6.2245e-06 lr: 6.2245e-06  eta: 2:38:20  time: 1.6110  data_time: 0.0132  memory: 6599  grad_norm: 3.3622  loss: 0.4215  decode.loss_ce: 0.2825  decode.acc_seg: 91.0506  aux.loss_ce: 0.1390  aux.acc_seg: 90.5257
2024/10/28 22:15:11 - mmengine - INFO - Iter(train) [74200/80000]  base_lr: 6.1204e-06 lr: 6.1204e-06  eta: 2:36:59  time: 1.6108  data_time: 0.0129  memory: 6598  grad_norm: 4.3746  loss: 0.4020  decode.loss_ce: 0.2647  decode.acc_seg: 89.4164  aux.loss_ce: 0.1373  aux.acc_seg: 89.9221
2024/10/28 22:16:32 - mmengine - INFO - Iter(train) [74250/80000]  base_lr: 6.0172e-06 lr: 6.0172e-06  eta: 2:35:37  time: 1.6114  data_time: 0.0130  memory: 6598  grad_norm: 4.1278  loss: 0.4833  decode.loss_ce: 0.3245  decode.acc_seg: 83.3909  aux.loss_ce: 0.1588  aux.acc_seg: 80.2020
2024/10/28 22:17:53 - mmengine - INFO - Iter(train) [74300/80000]  base_lr: 5.9147e-06 lr: 5.9147e-06  eta: 2:34:16  time: 1.6109  data_time: 0.0127  memory: 6598  grad_norm: 4.1882  loss: 0.4007  decode.loss_ce: 0.2630  decode.acc_seg: 88.7800  aux.loss_ce: 0.1377  aux.acc_seg: 84.6582
2024/10/28 22:19:14 - mmengine - INFO - Iter(train) [74350/80000]  base_lr: 5.8131e-06 lr: 5.8131e-06  eta: 2:32:55  time: 1.6088  data_time: 0.0131  memory: 6598  grad_norm: 3.5447  loss: 0.4346  decode.loss_ce: 0.2978  decode.acc_seg: 91.2554  aux.loss_ce: 0.1367  aux.acc_seg: 91.9497
2024/10/28 22:20:35 - mmengine - INFO - Iter(train) [74400/80000]  base_lr: 5.7124e-06 lr: 5.7124e-06  eta: 2:31:34  time: 1.6101  data_time: 0.0129  memory: 6599  grad_norm: 3.3532  loss: 0.4060  decode.loss_ce: 0.2817  decode.acc_seg: 88.0404  aux.loss_ce: 0.1243  aux.acc_seg: 89.4793
2024/10/28 22:21:56 - mmengine - INFO - Iter(train) [74450/80000]  base_lr: 5.6125e-06 lr: 5.6125e-06  eta: 2:30:13  time: 1.6090  data_time: 0.0136  memory: 6599  grad_norm: 3.4822  loss: 0.4205  decode.loss_ce: 0.2768  decode.acc_seg: 87.4196  aux.loss_ce: 0.1437  aux.acc_seg: 84.4033
2024/10/28 22:23:16 - mmengine - INFO - Iter(train) [74500/80000]  base_lr: 5.5134e-06 lr: 5.5134e-06  eta: 2:28:51  time: 1.6087  data_time: 0.0126  memory: 6600  grad_norm: 5.0550  loss: 0.3763  decode.loss_ce: 0.2601  decode.acc_seg: 91.4430  aux.loss_ce: 0.1162  aux.acc_seg: 91.8713
2024/10/28 22:24:37 - mmengine - INFO - Iter(train) [74550/80000]  base_lr: 5.4151e-06 lr: 5.4151e-06  eta: 2:27:30  time: 1.6076  data_time: 0.0132  memory: 6600  grad_norm: 5.9225  loss: 0.4519  decode.loss_ce: 0.2965  decode.acc_seg: 90.8304  aux.loss_ce: 0.1554  aux.acc_seg: 90.1269
2024/10/28 22:25:57 - mmengine - INFO - Iter(train) [74600/80000]  base_lr: 5.3177e-06 lr: 5.3177e-06  eta: 2:26:09  time: 1.6092  data_time: 0.0131  memory: 6600  grad_norm: 3.4666  loss: 0.3762  decode.loss_ce: 0.2601  decode.acc_seg: 85.0458  aux.loss_ce: 0.1161  aux.acc_seg: 84.8995
2024/10/28 22:27:18 - mmengine - INFO - Iter(train) [74650/80000]  base_lr: 5.2212e-06 lr: 5.2212e-06  eta: 2:24:47  time: 1.6065  data_time: 0.0136  memory: 6599  grad_norm: 4.7468  loss: 0.4136  decode.loss_ce: 0.2803  decode.acc_seg: 88.4547  aux.loss_ce: 0.1333  aux.acc_seg: 88.1896
2024/10/28 22:28:39 - mmengine - INFO - Iter(train) [74700/80000]  base_lr: 5.1255e-06 lr: 5.1255e-06  eta: 2:23:26  time: 1.6090  data_time: 0.0133  memory: 6599  grad_norm: 6.9628  loss: 0.4329  decode.loss_ce: 0.2902  decode.acc_seg: 86.9061  aux.loss_ce: 0.1427  aux.acc_seg: 87.4677
2024/10/28 22:30:00 - mmengine - INFO - Iter(train) [74750/80000]  base_lr: 5.0306e-06 lr: 5.0306e-06  eta: 2:22:05  time: 1.6341  data_time: 0.0131  memory: 6600  grad_norm: 4.3196  loss: 0.4536  decode.loss_ce: 0.3172  decode.acc_seg: 85.5802  aux.loss_ce: 0.1364  aux.acc_seg: 84.1767
2024/10/28 22:31:20 - mmengine - INFO - Iter(train) [74800/80000]  base_lr: 4.9366e-06 lr: 4.9366e-06  eta: 2:20:44  time: 1.6067  data_time: 0.0129  memory: 6600  grad_norm: 3.0899  loss: 0.4124  decode.loss_ce: 0.2835  decode.acc_seg: 87.4009  aux.loss_ce: 0.1289  aux.acc_seg: 87.2699
2024/10/28 22:32:41 - mmengine - INFO - Iter(train) [74850/80000]  base_lr: 4.8434e-06 lr: 4.8434e-06  eta: 2:19:23  time: 1.6225  data_time: 0.0133  memory: 6598  grad_norm: 3.5740  loss: 0.3816  decode.loss_ce: 0.2516  decode.acc_seg: 88.9806  aux.loss_ce: 0.1300  aux.acc_seg: 89.0195
2024/10/28 22:34:02 - mmengine - INFO - Iter(train) [74900/80000]  base_lr: 4.7511e-06 lr: 4.7511e-06  eta: 2:18:01  time: 1.6104  data_time: 0.0133  memory: 6600  grad_norm: 3.2686  loss: 0.4538  decode.loss_ce: 0.3105  decode.acc_seg: 84.3682  aux.loss_ce: 0.1433  aux.acc_seg: 85.6007
2024/10/28 22:35:25 - mmengine - INFO - Iter(train) [74950/80000]  base_lr: 4.6596e-06 lr: 4.6596e-06  eta: 2:16:40  time: 1.6118  data_time: 0.0139  memory: 6598  grad_norm: 3.2874  loss: 0.3980  decode.loss_ce: 0.2701  decode.acc_seg: 91.2253  aux.loss_ce: 0.1279  aux.acc_seg: 90.1612
2024/10/28 22:36:45 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 22:36:45 - mmengine - INFO - Iter(train) [75000/80000]  base_lr: 4.5690e-06 lr: 4.5690e-06  eta: 2:15:19  time: 1.6118  data_time: 0.0135  memory: 6600  grad_norm: 3.8522  loss: 0.4549  decode.loss_ce: 0.3017  decode.acc_seg: 85.7579  aux.loss_ce: 0.1531  aux.acc_seg: 80.5450
2024/10/28 22:38:06 - mmengine - INFO - Iter(train) [75050/80000]  base_lr: 4.4793e-06 lr: 4.4793e-06  eta: 2:13:58  time: 1.6087  data_time: 0.0131  memory: 6599  grad_norm: 3.6250  loss: 0.4688  decode.loss_ce: 0.3137  decode.acc_seg: 82.1352  aux.loss_ce: 0.1550  aux.acc_seg: 80.2575
2024/10/28 22:39:27 - mmengine - INFO - Iter(train) [75100/80000]  base_lr: 4.3904e-06 lr: 4.3904e-06  eta: 2:12:37  time: 1.6104  data_time: 0.0138  memory: 6598  grad_norm: 3.8850  loss: 0.4639  decode.loss_ce: 0.3119  decode.acc_seg: 90.7791  aux.loss_ce: 0.1519  aux.acc_seg: 90.3462
2024/10/28 22:40:48 - mmengine - INFO - Iter(train) [75150/80000]  base_lr: 4.3023e-06 lr: 4.3023e-06  eta: 2:11:15  time: 1.6151  data_time: 0.0143  memory: 6598  grad_norm: 3.6941  loss: 0.4260  decode.loss_ce: 0.2926  decode.acc_seg: 86.8116  aux.loss_ce: 0.1334  aux.acc_seg: 87.5661
2024/10/28 22:42:08 - mmengine - INFO - Iter(train) [75200/80000]  base_lr: 4.2151e-06 lr: 4.2151e-06  eta: 2:09:54  time: 1.6110  data_time: 0.0134  memory: 6598  grad_norm: 3.1815  loss: 0.4190  decode.loss_ce: 0.2759  decode.acc_seg: 81.9130  aux.loss_ce: 0.1431  aux.acc_seg: 68.5477
2024/10/28 22:43:29 - mmengine - INFO - Iter(train) [75250/80000]  base_lr: 4.1288e-06 lr: 4.1288e-06  eta: 2:08:33  time: 1.6072  data_time: 0.0129  memory: 6599  grad_norm: 2.4300  loss: 0.3533  decode.loss_ce: 0.2457  decode.acc_seg: 89.4437  aux.loss_ce: 0.1076  aux.acc_seg: 88.2226
2024/10/28 22:44:51 - mmengine - INFO - Iter(train) [75300/80000]  base_lr: 4.0434e-06 lr: 4.0434e-06  eta: 2:07:12  time: 1.6127  data_time: 0.0133  memory: 6598  grad_norm: 2.8303  loss: 0.4378  decode.loss_ce: 0.2990  decode.acc_seg: 89.1662  aux.loss_ce: 0.1387  aux.acc_seg: 84.9654
2024/10/28 22:46:11 - mmengine - INFO - Iter(train) [75350/80000]  base_lr: 3.9588e-06 lr: 3.9588e-06  eta: 2:05:50  time: 1.6114  data_time: 0.0134  memory: 6599  grad_norm: 3.7823  loss: 0.3899  decode.loss_ce: 0.2660  decode.acc_seg: 87.3551  aux.loss_ce: 0.1239  aux.acc_seg: 86.9299
2024/10/28 22:47:32 - mmengine - INFO - Iter(train) [75400/80000]  base_lr: 3.8750e-06 lr: 3.8750e-06  eta: 2:04:29  time: 1.6097  data_time: 0.0135  memory: 6599  grad_norm: 4.0549  loss: 0.4317  decode.loss_ce: 0.2885  decode.acc_seg: 89.6702  aux.loss_ce: 0.1432  aux.acc_seg: 89.1054
2024/10/28 22:48:53 - mmengine - INFO - Iter(train) [75450/80000]  base_lr: 3.7922e-06 lr: 3.7922e-06  eta: 2:03:08  time: 1.6076  data_time: 0.0136  memory: 6599  grad_norm: 3.6978  loss: 0.4307  decode.loss_ce: 0.2959  decode.acc_seg: 89.0882  aux.loss_ce: 0.1348  aux.acc_seg: 88.6942
2024/10/28 22:50:14 - mmengine - INFO - Iter(train) [75500/80000]  base_lr: 3.7102e-06 lr: 3.7102e-06  eta: 2:01:47  time: 1.6241  data_time: 0.0135  memory: 6600  grad_norm: 4.0439  loss: 0.4487  decode.loss_ce: 0.3110  decode.acc_seg: 84.8510  aux.loss_ce: 0.1377  aux.acc_seg: 83.4579
2024/10/28 22:51:35 - mmengine - INFO - Iter(train) [75550/80000]  base_lr: 3.6290e-06 lr: 3.6290e-06  eta: 2:00:26  time: 1.6102  data_time: 0.0132  memory: 6598  grad_norm: 3.3803  loss: 0.3867  decode.loss_ce: 0.2617  decode.acc_seg: 91.4417  aux.loss_ce: 0.1250  aux.acc_seg: 92.6685
2024/10/28 22:52:55 - mmengine - INFO - Iter(train) [75600/80000]  base_lr: 3.5488e-06 lr: 3.5488e-06  eta: 1:59:04  time: 1.6152  data_time: 0.0138  memory: 6599  grad_norm: 3.0753  loss: 0.3594  decode.loss_ce: 0.2503  decode.acc_seg: 85.3459  aux.loss_ce: 0.1091  aux.acc_seg: 86.1486
2024/10/28 22:54:16 - mmengine - INFO - Iter(train) [75650/80000]  base_lr: 3.4694e-06 lr: 3.4694e-06  eta: 1:57:43  time: 1.6105  data_time: 0.0136  memory: 6600  grad_norm: 3.1775  loss: 0.4449  decode.loss_ce: 0.3005  decode.acc_seg: 86.3428  aux.loss_ce: 0.1445  aux.acc_seg: 86.6447
2024/10/28 22:55:37 - mmengine - INFO - Iter(train) [75700/80000]  base_lr: 3.3908e-06 lr: 3.3908e-06  eta: 1:56:22  time: 1.6082  data_time: 0.0134  memory: 6598  grad_norm: 3.7403  loss: 0.4166  decode.loss_ce: 0.2835  decode.acc_seg: 85.6058  aux.loss_ce: 0.1331  aux.acc_seg: 87.0843
2024/10/28 22:56:58 - mmengine - INFO - Iter(train) [75750/80000]  base_lr: 3.3132e-06 lr: 3.3132e-06  eta: 1:55:01  time: 1.6120  data_time: 0.0137  memory: 6600  grad_norm: 3.6150  loss: 0.4053  decode.loss_ce: 0.2660  decode.acc_seg: 91.8835  aux.loss_ce: 0.1393  aux.acc_seg: 92.4403
2024/10/28 22:58:19 - mmengine - INFO - Iter(train) [75800/80000]  base_lr: 3.2364e-06 lr: 3.2364e-06  eta: 1:53:39  time: 1.6097  data_time: 0.0139  memory: 6600  grad_norm: 3.5990  loss: 0.3749  decode.loss_ce: 0.2534  decode.acc_seg: 91.6874  aux.loss_ce: 0.1215  aux.acc_seg: 90.2972
2024/10/28 22:59:39 - mmengine - INFO - Iter(train) [75850/80000]  base_lr: 3.1605e-06 lr: 3.1605e-06  eta: 1:52:18  time: 1.6110  data_time: 0.0135  memory: 6600  grad_norm: 3.4817  loss: 0.4108  decode.loss_ce: 0.2843  decode.acc_seg: 86.3637  aux.loss_ce: 0.1265  aux.acc_seg: 87.3457
2024/10/28 23:01:00 - mmengine - INFO - Iter(train) [75900/80000]  base_lr: 3.0855e-06 lr: 3.0855e-06  eta: 1:50:57  time: 1.6077  data_time: 0.0130  memory: 6599  grad_norm: 4.3596  loss: 0.4061  decode.loss_ce: 0.2785  decode.acc_seg: 84.4445  aux.loss_ce: 0.1276  aux.acc_seg: 88.9529
2024/10/28 23:02:21 - mmengine - INFO - Iter(train) [75950/80000]  base_lr: 3.0113e-06 lr: 3.0113e-06  eta: 1:49:36  time: 1.6072  data_time: 0.0128  memory: 6599  grad_norm: 3.3081  loss: 0.3967  decode.loss_ce: 0.2682  decode.acc_seg: 89.5401  aux.loss_ce: 0.1285  aux.acc_seg: 88.5145
2024/10/28 23:03:42 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 23:03:42 - mmengine - INFO - Iter(train) [76000/80000]  base_lr: 2.9381e-06 lr: 2.9381e-06  eta: 1:48:15  time: 1.6286  data_time: 0.0135  memory: 6599  grad_norm: 6.9235  loss: 0.4991  decode.loss_ce: 0.3433  decode.acc_seg: 77.1644  aux.loss_ce: 0.1558  aux.acc_seg: 76.3142
2024/10/28 23:05:02 - mmengine - INFO - Iter(train) [76050/80000]  base_lr: 2.8657e-06 lr: 2.8657e-06  eta: 1:46:53  time: 1.6098  data_time: 0.0135  memory: 6600  grad_norm: 3.6110  loss: 0.3938  decode.loss_ce: 0.2704  decode.acc_seg: 85.7971  aux.loss_ce: 0.1234  aux.acc_seg: 87.4561
2024/10/28 23:06:25 - mmengine - INFO - Iter(train) [76100/80000]  base_lr: 2.7942e-06 lr: 2.7942e-06  eta: 1:45:32  time: 1.6207  data_time: 0.0129  memory: 6599  grad_norm: 4.0247  loss: 0.4209  decode.loss_ce: 0.2893  decode.acc_seg: 86.9292  aux.loss_ce: 0.1315  aux.acc_seg: 87.0682
2024/10/28 23:07:46 - mmengine - INFO - Iter(train) [76150/80000]  base_lr: 2.7235e-06 lr: 2.7235e-06  eta: 1:44:11  time: 1.6097  data_time: 0.0133  memory: 6598  grad_norm: 3.2484  loss: 0.4047  decode.loss_ce: 0.2787  decode.acc_seg: 82.1590  aux.loss_ce: 0.1260  aux.acc_seg: 77.8865
2024/10/28 23:09:07 - mmengine - INFO - Iter(train) [76200/80000]  base_lr: 2.6538e-06 lr: 2.6538e-06  eta: 1:42:50  time: 1.6118  data_time: 0.0137  memory: 6600  grad_norm: 4.0856  loss: 0.4834  decode.loss_ce: 0.3254  decode.acc_seg: 89.7267  aux.loss_ce: 0.1580  aux.acc_seg: 90.5081
2024/10/28 23:10:27 - mmengine - INFO - Iter(train) [76250/80000]  base_lr: 2.5849e-06 lr: 2.5849e-06  eta: 1:41:29  time: 1.6122  data_time: 0.0136  memory: 6600  grad_norm: 3.5217  loss: 0.3584  decode.loss_ce: 0.2390  decode.acc_seg: 87.4344  aux.loss_ce: 0.1194  aux.acc_seg: 87.9165
2024/10/28 23:11:48 - mmengine - INFO - Iter(train) [76300/80000]  base_lr: 2.5170e-06 lr: 2.5170e-06  eta: 1:40:07  time: 1.6119  data_time: 0.0136  memory: 6600  grad_norm: 3.5333  loss: 0.4284  decode.loss_ce: 0.2884  decode.acc_seg: 88.0906  aux.loss_ce: 0.1400  aux.acc_seg: 84.3272
2024/10/28 23:13:09 - mmengine - INFO - Iter(train) [76350/80000]  base_lr: 2.4499e-06 lr: 2.4499e-06  eta: 1:38:46  time: 1.6106  data_time: 0.0137  memory: 6598  grad_norm: 3.2247  loss: 0.4059  decode.loss_ce: 0.2809  decode.acc_seg: 85.1231  aux.loss_ce: 0.1250  aux.acc_seg: 86.1287
2024/10/28 23:14:30 - mmengine - INFO - Iter(train) [76400/80000]  base_lr: 2.3837e-06 lr: 2.3837e-06  eta: 1:37:25  time: 1.6084  data_time: 0.0133  memory: 6599  grad_norm: 3.1246  loss: 0.4633  decode.loss_ce: 0.3081  decode.acc_seg: 87.9524  aux.loss_ce: 0.1552  aux.acc_seg: 87.1163
2024/10/28 23:15:51 - mmengine - INFO - Iter(train) [76450/80000]  base_lr: 2.3184e-06 lr: 2.3184e-06  eta: 1:36:04  time: 1.6094  data_time: 0.0133  memory: 6600  grad_norm: 3.8504  loss: 0.3807  decode.loss_ce: 0.2578  decode.acc_seg: 86.8967  aux.loss_ce: 0.1228  aux.acc_seg: 86.6027
2024/10/28 23:17:12 - mmengine - INFO - Iter(train) [76500/80000]  base_lr: 2.2540e-06 lr: 2.2540e-06  eta: 1:34:43  time: 1.6091  data_time: 0.0135  memory: 6599  grad_norm: 2.6056  loss: 0.3586  decode.loss_ce: 0.2434  decode.acc_seg: 89.0203  aux.loss_ce: 0.1152  aux.acc_seg: 88.6884
2024/10/28 23:18:32 - mmengine - INFO - Iter(train) [76550/80000]  base_lr: 2.1904e-06 lr: 2.1904e-06  eta: 1:33:21  time: 1.6113  data_time: 0.0132  memory: 6600  grad_norm: 4.8180  loss: 0.4096  decode.loss_ce: 0.2796  decode.acc_seg: 93.3021  aux.loss_ce: 0.1300  aux.acc_seg: 94.0119
2024/10/28 23:19:53 - mmengine - INFO - Iter(train) [76600/80000]  base_lr: 2.1278e-06 lr: 2.1278e-06  eta: 1:32:00  time: 1.6108  data_time: 0.0132  memory: 6599  grad_norm: 3.6639  loss: 0.4226  decode.loss_ce: 0.2900  decode.acc_seg: 89.3707  aux.loss_ce: 0.1326  aux.acc_seg: 90.3591
2024/10/28 23:21:14 - mmengine - INFO - Iter(train) [76650/80000]  base_lr: 2.0661e-06 lr: 2.0661e-06  eta: 1:30:39  time: 1.6108  data_time: 0.0132  memory: 6599  grad_norm: 3.6395  loss: 0.3593  decode.loss_ce: 0.2431  decode.acc_seg: 87.5759  aux.loss_ce: 0.1162  aux.acc_seg: 87.1221
2024/10/28 23:22:34 - mmengine - INFO - Iter(train) [76700/80000]  base_lr: 2.0052e-06 lr: 2.0052e-06  eta: 1:29:18  time: 1.6079  data_time: 0.0128  memory: 6599  grad_norm: 3.0235  loss: 0.3961  decode.loss_ce: 0.2744  decode.acc_seg: 84.3425  aux.loss_ce: 0.1217  aux.acc_seg: 84.5440
2024/10/28 23:23:55 - mmengine - INFO - Iter(train) [76750/80000]  base_lr: 1.9452e-06 lr: 1.9452e-06  eta: 1:27:56  time: 1.6247  data_time: 0.0138  memory: 6599  grad_norm: 3.9981  loss: 0.4154  decode.loss_ce: 0.2846  decode.acc_seg: 92.9363  aux.loss_ce: 0.1308  aux.acc_seg: 92.3354
2024/10/28 23:25:16 - mmengine - INFO - Iter(train) [76800/80000]  base_lr: 1.8862e-06 lr: 1.8862e-06  eta: 1:26:35  time: 1.6130  data_time: 0.0138  memory: 6599  grad_norm: 3.1070  loss: 0.3907  decode.loss_ce: 0.2632  decode.acc_seg: 84.4990  aux.loss_ce: 0.1275  aux.acc_seg: 86.1249
2024/10/28 23:26:37 - mmengine - INFO - Iter(train) [76850/80000]  base_lr: 1.8280e-06 lr: 1.8280e-06  eta: 1:25:14  time: 1.6100  data_time: 0.0136  memory: 6598  grad_norm: 3.0214  loss: 0.3773  decode.loss_ce: 0.2489  decode.acc_seg: 90.9773  aux.loss_ce: 0.1284  aux.acc_seg: 89.0917
2024/10/28 23:27:57 - mmengine - INFO - Iter(train) [76900/80000]  base_lr: 1.7707e-06 lr: 1.7707e-06  eta: 1:23:53  time: 1.6080  data_time: 0.0132  memory: 6599  grad_norm: 4.6369  loss: 0.4201  decode.loss_ce: 0.2836  decode.acc_seg: 89.7197  aux.loss_ce: 0.1365  aux.acc_seg: 89.5535
2024/10/28 23:29:19 - mmengine - INFO - Iter(train) [76950/80000]  base_lr: 1.7144e-06 lr: 1.7144e-06  eta: 1:22:32  time: 1.6124  data_time: 0.0134  memory: 6600  grad_norm: 3.7180  loss: 0.4442  decode.loss_ce: 0.3032  decode.acc_seg: 88.1515  aux.loss_ce: 0.1409  aux.acc_seg: 89.9613
2024/10/28 23:30:39 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 23:30:39 - mmengine - INFO - Iter(train) [77000/80000]  base_lr: 1.6589e-06 lr: 1.6589e-06  eta: 1:21:10  time: 1.6097  data_time: 0.0136  memory: 6599  grad_norm: 4.4406  loss: 0.3878  decode.loss_ce: 0.2633  decode.acc_seg: 89.9257  aux.loss_ce: 0.1245  aux.acc_seg: 88.5587
2024/10/28 23:32:00 - mmengine - INFO - Iter(train) [77050/80000]  base_lr: 1.6043e-06 lr: 1.6043e-06  eta: 1:19:49  time: 1.6098  data_time: 0.0135  memory: 6600  grad_norm: 3.0913  loss: 0.3522  decode.loss_ce: 0.2390  decode.acc_seg: 90.3952  aux.loss_ce: 0.1132  aux.acc_seg: 82.0012
2024/10/28 23:33:21 - mmengine - INFO - Iter(train) [77100/80000]  base_lr: 1.5507e-06 lr: 1.5507e-06  eta: 1:18:28  time: 1.6084  data_time: 0.0134  memory: 6600  grad_norm: 4.1091  loss: 0.3502  decode.loss_ce: 0.2393  decode.acc_seg: 90.0399  aux.loss_ce: 0.1109  aux.acc_seg: 90.2448
2024/10/28 23:34:41 - mmengine - INFO - Iter(train) [77150/80000]  base_lr: 1.4979e-06 lr: 1.4979e-06  eta: 1:17:07  time: 1.6148  data_time: 0.0138  memory: 6602  grad_norm: 4.3487  loss: 0.5222  decode.loss_ce: 0.3464  decode.acc_seg: 90.6852  aux.loss_ce: 0.1759  aux.acc_seg: 91.5594
2024/10/28 23:36:02 - mmengine - INFO - Iter(train) [77200/80000]  base_lr: 1.4460e-06 lr: 1.4460e-06  eta: 1:15:46  time: 1.6090  data_time: 0.0132  memory: 6598  grad_norm: 3.8129  loss: 0.3830  decode.loss_ce: 0.2665  decode.acc_seg: 86.3117  aux.loss_ce: 0.1165  aux.acc_seg: 86.6561
2024/10/28 23:37:27 - mmengine - INFO - Iter(train) [77250/80000]  base_lr: 1.3951e-06 lr: 1.3951e-06  eta: 1:14:25  time: 1.6141  data_time: 0.0136  memory: 6600  grad_norm: 4.0110  loss: 0.3996  decode.loss_ce: 0.2663  decode.acc_seg: 88.9289  aux.loss_ce: 0.1333  aux.acc_seg: 87.4005
2024/10/28 23:38:47 - mmengine - INFO - Iter(train) [77300/80000]  base_lr: 1.3450e-06 lr: 1.3450e-06  eta: 1:13:03  time: 1.6118  data_time: 0.0134  memory: 6599  grad_norm: 2.7757  loss: 0.3798  decode.loss_ce: 0.2591  decode.acc_seg: 91.3379  aux.loss_ce: 0.1206  aux.acc_seg: 88.3516
2024/10/28 23:40:08 - mmengine - INFO - Iter(train) [77350/80000]  base_lr: 1.2958e-06 lr: 1.2958e-06  eta: 1:11:42  time: 1.6101  data_time: 0.0133  memory: 6599  grad_norm: 5.0247  loss: 0.4527  decode.loss_ce: 0.3086  decode.acc_seg: 90.3349  aux.loss_ce: 0.1441  aux.acc_seg: 89.9403
2024/10/28 23:41:29 - mmengine - INFO - Iter(train) [77400/80000]  base_lr: 1.2476e-06 lr: 1.2476e-06  eta: 1:10:21  time: 1.6104  data_time: 0.0134  memory: 6599  grad_norm: 3.9533  loss: 0.4069  decode.loss_ce: 0.2691  decode.acc_seg: 87.8886  aux.loss_ce: 0.1378  aux.acc_seg: 84.1531
2024/10/28 23:42:50 - mmengine - INFO - Iter(train) [77450/80000]  base_lr: 1.2002e-06 lr: 1.2002e-06  eta: 1:09:00  time: 1.6109  data_time: 0.0136  memory: 6601  grad_norm: 3.7750  loss: 0.4265  decode.loss_ce: 0.2939  decode.acc_seg: 86.5520  aux.loss_ce: 0.1326  aux.acc_seg: 88.2827
2024/10/28 23:44:10 - mmengine - INFO - Iter(train) [77500/80000]  base_lr: 1.1538e-06 lr: 1.1538e-06  eta: 1:07:39  time: 1.6088  data_time: 0.0131  memory: 6599  grad_norm: 5.9322  loss: 0.4331  decode.loss_ce: 0.2949  decode.acc_seg: 87.9195  aux.loss_ce: 0.1383  aux.acc_seg: 87.1718
2024/10/28 23:45:31 - mmengine - INFO - Iter(train) [77550/80000]  base_lr: 1.1083e-06 lr: 1.1083e-06  eta: 1:06:17  time: 1.6107  data_time: 0.0132  memory: 6599  grad_norm: 3.5312  loss: 0.3435  decode.loss_ce: 0.2339  decode.acc_seg: 90.5201  aux.loss_ce: 0.1096  aux.acc_seg: 91.0168
2024/10/28 23:46:51 - mmengine - INFO - Iter(train) [77600/80000]  base_lr: 1.0636e-06 lr: 1.0636e-06  eta: 1:04:56  time: 1.6083  data_time: 0.0132  memory: 6599  grad_norm: 5.6034  loss: 0.4203  decode.loss_ce: 0.2823  decode.acc_seg: 92.2805  aux.loss_ce: 0.1380  aux.acc_seg: 92.1395
2024/10/28 23:48:12 - mmengine - INFO - Iter(train) [77650/80000]  base_lr: 1.0199e-06 lr: 1.0199e-06  eta: 1:03:35  time: 1.6118  data_time: 0.0136  memory: 6598  grad_norm: 3.7064  loss: 0.4810  decode.loss_ce: 0.3099  decode.acc_seg: 90.7052  aux.loss_ce: 0.1710  aux.acc_seg: 84.5491
2024/10/28 23:49:33 - mmengine - INFO - Iter(train) [77700/80000]  base_lr: 9.7713e-07 lr: 9.7713e-07  eta: 1:02:14  time: 1.6117  data_time: 0.0134  memory: 6599  grad_norm: 3.1697  loss: 0.3760  decode.loss_ce: 0.2575  decode.acc_seg: 86.7413  aux.loss_ce: 0.1185  aux.acc_seg: 86.5264
2024/10/28 23:50:53 - mmengine - INFO - Iter(train) [77750/80000]  base_lr: 9.3523e-07 lr: 9.3523e-07  eta: 1:00:53  time: 1.6100  data_time: 0.0135  memory: 6602  grad_norm: 4.6219  loss: 0.3857  decode.loss_ce: 0.2638  decode.acc_seg: 86.3926  aux.loss_ce: 0.1219  aux.acc_seg: 85.2448
2024/10/28 23:52:14 - mmengine - INFO - Iter(train) [77800/80000]  base_lr: 8.9425e-07 lr: 8.9425e-07  eta: 0:59:31  time: 1.6103  data_time: 0.0134  memory: 6598  grad_norm: 3.1734  loss: 0.4126  decode.loss_ce: 0.2779  decode.acc_seg: 83.4657  aux.loss_ce: 0.1347  aux.acc_seg: 77.7872
2024/10/28 23:53:35 - mmengine - INFO - Iter(train) [77850/80000]  base_lr: 8.5418e-07 lr: 8.5418e-07  eta: 0:58:10  time: 1.6093  data_time: 0.0132  memory: 6600  grad_norm: 2.8612  loss: 0.3680  decode.loss_ce: 0.2532  decode.acc_seg: 84.6733  aux.loss_ce: 0.1149  aux.acc_seg: 83.7903
2024/10/28 23:54:55 - mmengine - INFO - Iter(train) [77900/80000]  base_lr: 8.1502e-07 lr: 8.1502e-07  eta: 0:56:49  time: 1.6081  data_time: 0.0130  memory: 6599  grad_norm: 3.8115  loss: 0.3853  decode.loss_ce: 0.2640  decode.acc_seg: 84.6878  aux.loss_ce: 0.1213  aux.acc_seg: 85.7212
2024/10/28 23:56:16 - mmengine - INFO - Iter(train) [77950/80000]  base_lr: 7.7677e-07 lr: 7.7677e-07  eta: 0:55:28  time: 1.6213  data_time: 0.0122  memory: 6600  grad_norm: 3.3244  loss: 0.3983  decode.loss_ce: 0.2678  decode.acc_seg: 89.2629  aux.loss_ce: 0.1305  aux.acc_seg: 88.2675
2024/10/28 23:57:37 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/28 23:57:37 - mmengine - INFO - Iter(train) [78000/80000]  base_lr: 7.3944e-07 lr: 7.3944e-07  eta: 0:54:07  time: 1.6110  data_time: 0.0121  memory: 6598  grad_norm: 3.1842  loss: 0.3419  decode.loss_ce: 0.2309  decode.acc_seg: 89.5997  aux.loss_ce: 0.1110  aux.acc_seg: 89.0390
2024/10/28 23:58:57 - mmengine - INFO - Iter(train) [78050/80000]  base_lr: 7.0302e-07 lr: 7.0302e-07  eta: 0:52:45  time: 1.6078  data_time: 0.0120  memory: 6600  grad_norm: 3.8476  loss: 0.3729  decode.loss_ce: 0.2554  decode.acc_seg: 89.4747  aux.loss_ce: 0.1175  aux.acc_seg: 87.7231
2024/10/29 00:00:18 - mmengine - INFO - Iter(train) [78100/80000]  base_lr: 6.6751e-07 lr: 6.6751e-07  eta: 0:51:24  time: 1.6073  data_time: 0.0125  memory: 6600  grad_norm: 3.5703  loss: 0.4352  decode.loss_ce: 0.3030  decode.acc_seg: 88.0895  aux.loss_ce: 0.1322  aux.acc_seg: 85.6308
2024/10/29 00:01:39 - mmengine - INFO - Iter(train) [78150/80000]  base_lr: 6.3292e-07 lr: 6.3292e-07  eta: 0:50:03  time: 1.6100  data_time: 0.0121  memory: 6598  grad_norm: 3.1210  loss: 0.3978  decode.loss_ce: 0.2725  decode.acc_seg: 88.2569  aux.loss_ce: 0.1253  aux.acc_seg: 87.9552
2024/10/29 00:02:59 - mmengine - INFO - Iter(train) [78200/80000]  base_lr: 5.9924e-07 lr: 5.9924e-07  eta: 0:48:42  time: 1.6083  data_time: 0.0123  memory: 6598  grad_norm: 3.5193  loss: 0.3737  decode.loss_ce: 0.2582  decode.acc_seg: 83.9674  aux.loss_ce: 0.1154  aux.acc_seg: 87.5472
2024/10/29 00:04:20 - mmengine - INFO - Iter(train) [78250/80000]  base_lr: 5.6649e-07 lr: 5.6649e-07  eta: 0:47:21  time: 1.6067  data_time: 0.0124  memory: 6599  grad_norm: 3.3026  loss: 0.4337  decode.loss_ce: 0.2927  decode.acc_seg: 87.2453  aux.loss_ce: 0.1410  aux.acc_seg: 88.8893
2024/10/29 00:05:40 - mmengine - INFO - Iter(train) [78300/80000]  base_lr: 5.3464e-07 lr: 5.3464e-07  eta: 0:45:59  time: 1.6067  data_time: 0.0122  memory: 6600  grad_norm: 3.5565  loss: 0.4802  decode.loss_ce: 0.3199  decode.acc_seg: 83.4877  aux.loss_ce: 0.1603  aux.acc_seg: 83.2718
2024/10/29 00:07:01 - mmengine - INFO - Iter(train) [78350/80000]  base_lr: 5.0372e-07 lr: 5.0372e-07  eta: 0:44:38  time: 1.6080  data_time: 0.0118  memory: 6599  grad_norm: 3.7756  loss: 0.4067  decode.loss_ce: 0.2753  decode.acc_seg: 85.6049  aux.loss_ce: 0.1314  aux.acc_seg: 83.0895
2024/10/29 00:08:22 - mmengine - INFO - Iter(train) [78400/80000]  base_lr: 4.7371e-07 lr: 4.7371e-07  eta: 0:43:17  time: 1.6068  data_time: 0.0120  memory: 6599  grad_norm: 3.8163  loss: 0.4372  decode.loss_ce: 0.2931  decode.acc_seg: 87.4320  aux.loss_ce: 0.1441  aux.acc_seg: 86.3331
2024/10/29 00:09:43 - mmengine - INFO - Iter(train) [78450/80000]  base_lr: 4.4462e-07 lr: 4.4462e-07  eta: 0:41:56  time: 1.6092  data_time: 0.0115  memory: 6602  grad_norm: 3.8131  loss: 0.3911  decode.loss_ce: 0.2586  decode.acc_seg: 87.2216  aux.loss_ce: 0.1325  aux.acc_seg: 84.3327
2024/10/29 00:11:03 - mmengine - INFO - Iter(train) [78500/80000]  base_lr: 4.1645e-07 lr: 4.1645e-07  eta: 0:40:35  time: 1.6112  data_time: 0.0117  memory: 6600  grad_norm: 4.1973  loss: 0.3894  decode.loss_ce: 0.2608  decode.acc_seg: 91.6255  aux.loss_ce: 0.1286  aux.acc_seg: 87.5838
2024/10/29 00:12:26 - mmengine - INFO - Iter(train) [78550/80000]  base_lr: 3.8919e-07 lr: 3.8919e-07  eta: 0:39:14  time: 1.6103  data_time: 0.0119  memory: 6602  grad_norm: 4.5198  loss: 0.4329  decode.loss_ce: 0.2935  decode.acc_seg: 90.6320  aux.loss_ce: 0.1394  aux.acc_seg: 91.2435
2024/10/29 00:13:48 - mmengine - INFO - Iter(train) [78600/80000]  base_lr: 3.6286e-07 lr: 3.6286e-07  eta: 0:37:52  time: 1.6074  data_time: 0.0127  memory: 6598  grad_norm: 2.8887  loss: 0.3966  decode.loss_ce: 0.2731  decode.acc_seg: 90.1800  aux.loss_ce: 0.1235  aux.acc_seg: 91.2586
2024/10/29 00:15:08 - mmengine - INFO - Iter(train) [78650/80000]  base_lr: 3.3745e-07 lr: 3.3745e-07  eta: 0:36:31  time: 1.6093  data_time: 0.0120  memory: 6598  grad_norm: 3.9391  loss: 0.4194  decode.loss_ce: 0.2795  decode.acc_seg: 89.7132  aux.loss_ce: 0.1399  aux.acc_seg: 87.2165
2024/10/29 00:16:29 - mmengine - INFO - Iter(train) [78700/80000]  base_lr: 3.1295e-07 lr: 3.1295e-07  eta: 0:35:10  time: 1.6076  data_time: 0.0117  memory: 6598  grad_norm: 4.8869  loss: 0.4889  decode.loss_ce: 0.3164  decode.acc_seg: 88.4050  aux.loss_ce: 0.1725  aux.acc_seg: 89.2556
2024/10/29 00:17:49 - mmengine - INFO - Iter(train) [78750/80000]  base_lr: 2.8938e-07 lr: 2.8938e-07  eta: 0:33:49  time: 1.6084  data_time: 0.0118  memory: 6598  grad_norm: 5.6007  loss: 0.4429  decode.loss_ce: 0.3033  decode.acc_seg: 85.3207  aux.loss_ce: 0.1397  aux.acc_seg: 83.6062
2024/10/29 00:19:10 - mmengine - INFO - Iter(train) [78800/80000]  base_lr: 2.6673e-07 lr: 2.6673e-07  eta: 0:32:28  time: 1.6089  data_time: 0.0120  memory: 6599  grad_norm: 3.5501  loss: 0.3761  decode.loss_ce: 0.2523  decode.acc_seg: 86.4908  aux.loss_ce: 0.1239  aux.acc_seg: 83.4110
2024/10/29 00:20:31 - mmengine - INFO - Iter(train) [78850/80000]  base_lr: 2.4499e-07 lr: 2.4499e-07  eta: 0:31:06  time: 1.6103  data_time: 0.0116  memory: 6599  grad_norm: 4.8286  loss: 0.4127  decode.loss_ce: 0.2841  decode.acc_seg: 84.8741  aux.loss_ce: 0.1286  aux.acc_seg: 84.7595
2024/10/29 00:21:52 - mmengine - INFO - Iter(train) [78900/80000]  base_lr: 2.2418e-07 lr: 2.2418e-07  eta: 0:29:45  time: 1.6093  data_time: 0.0117  memory: 6600  grad_norm: 5.7459  loss: 0.3834  decode.loss_ce: 0.2597  decode.acc_seg: 87.4378  aux.loss_ce: 0.1237  aux.acc_seg: 86.8639
2024/10/29 00:23:12 - mmengine - INFO - Iter(train) [78950/80000]  base_lr: 2.0430e-07 lr: 2.0430e-07  eta: 0:28:24  time: 1.6118  data_time: 0.0140  memory: 6600  grad_norm: 4.5900  loss: 0.3845  decode.loss_ce: 0.2602  decode.acc_seg: 91.6284  aux.loss_ce: 0.1243  aux.acc_seg: 89.7180
2024/10/29 00:24:33 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/29 00:24:33 - mmengine - INFO - Iter(train) [79000/80000]  base_lr: 1.8533e-07 lr: 1.8533e-07  eta: 0:27:03  time: 1.6102  data_time: 0.0137  memory: 6600  grad_norm: 3.3481  loss: 0.4058  decode.loss_ce: 0.2758  decode.acc_seg: 88.8087  aux.loss_ce: 0.1301  aux.acc_seg: 89.0965
2024/10/29 00:25:54 - mmengine - INFO - Iter(train) [79050/80000]  base_lr: 1.6729e-07 lr: 1.6729e-07  eta: 0:25:42  time: 1.6093  data_time: 0.0134  memory: 6598  grad_norm: 5.7469  loss: 0.3502  decode.loss_ce: 0.2450  decode.acc_seg: 87.7496  aux.loss_ce: 0.1052  aux.acc_seg: 88.2955
2024/10/29 00:27:14 - mmengine - INFO - Iter(train) [79100/80000]  base_lr: 1.5017e-07 lr: 1.5017e-07  eta: 0:24:21  time: 1.6094  data_time: 0.0135  memory: 6599  grad_norm: 2.9042  loss: 0.4072  decode.loss_ce: 0.2811  decode.acc_seg: 86.5238  aux.loss_ce: 0.1261  aux.acc_seg: 81.3799
2024/10/29 00:28:35 - mmengine - INFO - Iter(train) [79150/80000]  base_lr: 1.3397e-07 lr: 1.3397e-07  eta: 0:22:59  time: 1.6087  data_time: 0.0136  memory: 6599  grad_norm: 2.8731  loss: 0.4592  decode.loss_ce: 0.3118  decode.acc_seg: 87.0505  aux.loss_ce: 0.1474  aux.acc_seg: 87.8481
2024/10/29 00:29:56 - mmengine - INFO - Iter(train) [79200/80000]  base_lr: 1.1869e-07 lr: 1.1869e-07  eta: 0:21:38  time: 1.6238  data_time: 0.0137  memory: 6599  grad_norm: 3.3657  loss: 0.4279  decode.loss_ce: 0.2934  decode.acc_seg: 86.8413  aux.loss_ce: 0.1345  aux.acc_seg: 86.8457
2024/10/29 00:31:17 - mmengine - INFO - Iter(train) [79250/80000]  base_lr: 1.0434e-07 lr: 1.0434e-07  eta: 0:20:17  time: 1.6090  data_time: 0.0132  memory: 6600  grad_norm: 3.2157  loss: 0.3851  decode.loss_ce: 0.2664  decode.acc_seg: 91.7117  aux.loss_ce: 0.1187  aux.acc_seg: 88.1323
2024/10/29 00:32:38 - mmengine - INFO - Iter(train) [79300/80000]  base_lr: 9.0913e-08 lr: 9.0913e-08  eta: 0:18:56  time: 1.6096  data_time: 0.0136  memory: 6599  grad_norm: 6.0472  loss: 0.4295  decode.loss_ce: 0.2894  decode.acc_seg: 88.5763  aux.loss_ce: 0.1401  aux.acc_seg: 76.9893
2024/10/29 00:33:58 - mmengine - INFO - Iter(train) [79350/80000]  base_lr: 7.8409e-08 lr: 7.8409e-08  eta: 0:17:35  time: 1.6115  data_time: 0.0135  memory: 6598  grad_norm: 3.0934  loss: 0.4014  decode.loss_ce: 0.2710  decode.acc_seg: 85.4736  aux.loss_ce: 0.1304  aux.acc_seg: 83.0308
2024/10/29 00:35:19 - mmengine - INFO - Iter(train) [79400/80000]  base_lr: 6.6830e-08 lr: 6.6830e-08  eta: 0:16:13  time: 1.6131  data_time: 0.0137  memory: 6599  grad_norm: 2.9250  loss: 0.3910  decode.loss_ce: 0.2635  decode.acc_seg: 90.1303  aux.loss_ce: 0.1276  aux.acc_seg: 87.0028
2024/10/29 00:36:41 - mmengine - INFO - Iter(train) [79450/80000]  base_lr: 5.6174e-08 lr: 5.6174e-08  eta: 0:14:52  time: 1.6107  data_time: 0.0137  memory: 6599  grad_norm: 3.8612  loss: 0.3931  decode.loss_ce: 0.2606  decode.acc_seg: 91.8506  aux.loss_ce: 0.1325  aux.acc_seg: 91.6704
2024/10/29 00:38:01 - mmengine - INFO - Iter(train) [79500/80000]  base_lr: 4.6443e-08 lr: 4.6443e-08  eta: 0:13:31  time: 1.6128  data_time: 0.0139  memory: 6599  grad_norm: 3.8518  loss: 0.4243  decode.loss_ce: 0.2857  decode.acc_seg: 87.3426  aux.loss_ce: 0.1386  aux.acc_seg: 88.0610
2024/10/29 00:39:27 - mmengine - INFO - Iter(train) [79550/80000]  base_lr: 3.7636e-08 lr: 3.7636e-08  eta: 0:12:10  time: 1.6083  data_time: 0.0125  memory: 6599  grad_norm: 3.5769  loss: 0.3508  decode.loss_ce: 0.2427  decode.acc_seg: 89.0867  aux.loss_ce: 0.1081  aux.acc_seg: 89.1743
2024/10/29 00:40:47 - mmengine - INFO - Iter(train) [79600/80000]  base_lr: 2.9755e-08 lr: 2.9755e-08  eta: 0:10:49  time: 1.6115  data_time: 0.0126  memory: 6598  grad_norm: 3.1076  loss: 0.4551  decode.loss_ce: 0.3017  decode.acc_seg: 90.5606  aux.loss_ce: 0.1534  aux.acc_seg: 90.1264
2024/10/29 00:42:08 - mmengine - INFO - Iter(train) [79650/80000]  base_lr: 2.2798e-08 lr: 2.2798e-08  eta: 0:09:28  time: 1.6073  data_time: 0.0130  memory: 6599  grad_norm: 4.3158  loss: 0.3785  decode.loss_ce: 0.2567  decode.acc_seg: 84.9481  aux.loss_ce: 0.1218  aux.acc_seg: 82.6528
2024/10/29 00:43:29 - mmengine - INFO - Iter(train) [79700/80000]  base_lr: 1.6765e-08 lr: 1.6765e-08  eta: 0:08:07  time: 1.6101  data_time: 0.0133  memory: 6600  grad_norm: 3.8838  loss: 0.4443  decode.loss_ce: 0.3018  decode.acc_seg: 89.1012  aux.loss_ce: 0.1425  aux.acc_seg: 88.4174
2024/10/29 00:44:50 - mmengine - INFO - Iter(train) [79750/80000]  base_lr: 1.1658e-08 lr: 1.1658e-08  eta: 0:06:45  time: 1.6113  data_time: 0.0136  memory: 6601  grad_norm: 3.5672  loss: 0.3944  decode.loss_ce: 0.2662  decode.acc_seg: 91.3300  aux.loss_ce: 0.1282  aux.acc_seg: 90.8645
2024/10/29 00:46:11 - mmengine - INFO - Iter(train) [79800/80000]  base_lr: 7.4763e-09 lr: 7.4763e-09  eta: 0:05:24  time: 1.6141  data_time: 0.0145  memory: 6599  grad_norm: 3.2889  loss: 0.4442  decode.loss_ce: 0.2979  decode.acc_seg: 90.2298  aux.loss_ce: 0.1463  aux.acc_seg: 89.8177
2024/10/29 00:47:32 - mmengine - INFO - Iter(train) [79850/80000]  base_lr: 4.2194e-09 lr: 4.2194e-09  eta: 0:04:03  time: 1.6119  data_time: 0.0132  memory: 6600  grad_norm: 4.4256  loss: 0.3676  decode.loss_ce: 0.2586  decode.acc_seg: 89.9699  aux.loss_ce: 0.1090  aux.acc_seg: 90.1396
2024/10/29 00:48:53 - mmengine - INFO - Iter(train) [79900/80000]  base_lr: 1.8877e-09 lr: 1.8877e-09  eta: 0:02:42  time: 1.6111  data_time: 0.0137  memory: 6598  grad_norm: 3.3106  loss: 0.4430  decode.loss_ce: 0.2960  decode.acc_seg: 85.9900  aux.loss_ce: 0.1471  aux.acc_seg: 86.5040
2024/10/29 00:50:13 - mmengine - INFO - Iter(train) [79950/80000]  base_lr: 4.8133e-10 lr: 4.8133e-10  eta: 0:01:21  time: 1.6125  data_time: 0.0140  memory: 6598  grad_norm: 2.9393  loss: 0.4025  decode.loss_ce: 0.2782  decode.acc_seg: 85.4469  aux.loss_ce: 0.1243  aux.acc_seg: 82.0443
2024/10/29 00:51:34 - mmengine - INFO - Exp name: pspnet_mobilemamba_b4-80k_ade20k-512x512_20241027_233216
2024/10/29 00:51:34 - mmengine - INFO - Iter(train) [80000/80000]  base_lr: 1.8506e-13 lr: 1.8506e-13  eta: 0:00:00  time: 1.6075  data_time: 0.0131  memory: 6598  grad_norm: 4.2761  loss: 0.3616  decode.loss_ce: 0.2432  decode.acc_seg: 92.8187  aux.loss_ce: 0.1184  aux.acc_seg: 93.2524
2024/10/29 00:51:34 - mmengine - INFO - Saving checkpoint at 80000 iterations
2024/10/29 00:51:39 - mmengine - INFO - Iter(val) [ 50/500]    eta: 0:00:13  time: 0.0286  data_time: 0.0015  memory: 1007  
2024/10/29 00:51:41 - mmengine - INFO - Iter(val) [100/500]    eta: 0:00:11  time: 0.0288  data_time: 0.0014  memory: 1077  
2024/10/29 00:51:42 - mmengine - INFO - Iter(val) [150/500]    eta: 0:00:10  time: 0.0293  data_time: 0.0014  memory: 792  
2024/10/29 00:51:44 - mmengine - INFO - Iter(val) [200/500]    eta: 0:00:08  time: 0.0290  data_time: 0.0014  memory: 825  
2024/10/29 00:51:45 - mmengine - INFO - Iter(val) [250/500]    eta: 0:00:07  time: 0.0289  data_time: 0.0015  memory: 865  
2024/10/29 00:51:47 - mmengine - INFO - Iter(val) [300/500]    eta: 0:00:05  time: 0.0292  data_time: 0.0016  memory: 1988  
2024/10/29 00:51:48 - mmengine - INFO - Iter(val) [350/500]    eta: 0:00:04  time: 0.0283  data_time: 0.0013  memory: 791  
2024/10/29 00:51:50 - mmengine - INFO - Iter(val) [400/500]    eta: 0:00:02  time: 0.0286  data_time: 0.0013  memory: 863  
2024/10/29 00:51:51 - mmengine - INFO - Iter(val) [450/500]    eta: 0:00:01  time: 0.0285  data_time: 0.0012  memory: 798  
2024/10/29 00:51:52 - mmengine - INFO - Iter(val) [500/500]    eta: 0:00:00  time: 0.0287  data_time: 0.0012  memory: 847  
2024/10/29 00:51:55 - mmengine - INFO - per class results:
2024/10/29 00:51:55 - mmengine - INFO - 
+---------------------+-------+-------+
|        Class        |  IoU  |  Acc  |
+---------------------+-------+-------+
|         wall        | 66.64 |  84.3 |
|       building      | 76.73 | 89.56 |
|         sky         | 89.35 | 94.86 |
|        floor        | 70.49 | 86.04 |
|         tree        | 65.85 | 82.46 |
|       ceiling       | 77.14 | 86.83 |
|         road        | 78.82 |  86.3 |
|         bed         | 78.71 | 87.74 |
|      windowpane     | 52.12 | 66.52 |
|        grass        | 56.06 | 71.69 |
|       cabinet       | 50.64 | 63.97 |
|       sidewalk      | 59.21 | 75.33 |
|        person       | 60.67 | 79.17 |
|        earth        | 29.56 | 44.26 |
|         door        | 35.14 | 50.38 |
|        table        | 46.26 | 63.65 |
|       mountain      | 53.08 | 67.99 |
|        plant        | 42.67 | 53.42 |
|       curtain       |  55.7 | 70.58 |
|        chair        | 40.16 | 52.72 |
|         car         | 71.53 | 84.08 |
|        water        | 45.33 | 56.39 |
|       painting      | 52.11 | 67.42 |
|         sofa        | 55.67 | 73.31 |
|        shelf        | 30.86 | 44.76 |
|        house        | 42.18 | 54.66 |
|         sea         | 50.42 | 74.71 |
|        mirror       | 55.63 | 65.36 |
|         rug         | 48.95 | 61.82 |
|        field        | 21.92 | 40.94 |
|       armchair      | 38.12 | 56.63 |
|         seat        |  59.8 | 75.62 |
|        fence        | 34.41 | 50.56 |
|         desk        | 43.31 |  58.0 |
|         rock        | 31.86 | 48.49 |
|       wardrobe      | 42.51 |  65.0 |
|         lamp        | 31.97 | 40.83 |
|       bathtub       | 67.93 | 75.31 |
|       railing       | 23.81 | 32.78 |
|       cushion       | 36.76 | 46.67 |
|         base        | 10.93 | 15.06 |
|         box         | 13.55 | 19.24 |
|        column       | 23.66 |  32.7 |
|      signboard      | 18.16 |  24.3 |
|   chest of drawers  | 34.93 | 50.98 |
|       counter       | 26.46 | 33.61 |
|         sand        |  40.6 | 59.17 |
|         sink        | 52.91 | 64.91 |
|      skyscraper     | 47.98 | 54.06 |
|      fireplace      | 63.59 | 76.75 |
|     refrigerator    | 59.81 | 72.53 |
|      grandstand     | 39.22 | 78.94 |
|         path        | 17.16 | 28.57 |
|        stairs       | 26.87 | 34.07 |
|        runway       |  66.2 | 89.98 |
|         case        | 41.78 | 60.34 |
|      pool table     |  69.9 | 79.19 |
|        pillow       | 41.57 | 52.32 |
|     screen door     | 61.64 |  68.8 |
|       stairway      | 25.25 | 34.38 |
|        river        | 11.65 |  31.1 |
|        bridge       | 29.66 | 33.57 |
|       bookcase      | 31.52 | 46.91 |
|        blind        | 34.95 | 41.69 |
|     coffee table    | 45.58 | 64.35 |
|        toilet       | 65.47 | 76.64 |
|        flower       | 23.66 | 40.06 |
|         book        | 30.55 | 49.11 |
|         hill        | 10.78 | 18.83 |
|        bench        | 35.96 | 44.74 |
|      countertop     | 44.43 |  58.8 |
|        stove        | 60.88 |  69.5 |
|         palm        | 39.16 | 56.66 |
|    kitchen island   | 27.59 | 53.09 |
|       computer      | 46.77 | 55.29 |
|     swivel chair    | 32.83 | 44.25 |
|         boat        | 52.59 | 74.98 |
|         bar         | 43.39 | 55.72 |
|    arcade machine   | 47.96 | 52.83 |
|        hovel        | 23.34 | 27.35 |
|         bus         | 72.06 | 78.19 |
|        towel        | 35.89 | 46.74 |
|        light        |  9.87 | 10.85 |
|        truck        | 21.18 | 26.29 |
|        tower        | 31.92 | 57.02 |
|      chandelier     | 42.75 | 52.53 |
|        awning       | 11.99 | 13.83 |
|     streetlight     |  4.53 |  5.37 |
|        booth        | 45.95 | 48.87 |
| television receiver | 54.87 | 64.79 |
|       airplane      | 34.13 | 51.04 |
|      dirt track     |  5.42 | 25.47 |
|       apparel       | 22.94 | 32.78 |
|         pole        |  5.49 | 10.21 |
|         land        |  0.22 |  0.34 |
|      bannister      |  2.61 |  3.25 |
|      escalator      | 16.65 | 21.31 |
|       ottoman       | 27.96 | 38.36 |
|        bottle       | 19.33 | 29.41 |
|        buffet       | 37.03 | 41.03 |
|        poster       | 24.27 | 30.41 |
|        stage        |  13.1 | 23.46 |
|         van         | 24.07 | 32.29 |
|         ship        | 35.46 | 49.81 |
|       fountain      | 20.06 | 20.57 |
|    conveyer belt    | 62.36 | 74.76 |
|        canopy       | 18.82 | 25.08 |
|        washer       | 60.16 | 61.94 |
|      plaything      | 10.52 | 16.64 |
|    swimming pool    | 43.85 | 60.56 |
|        stool        | 22.59 | 33.15 |
|        barrel       | 30.58 | 64.94 |
|        basket       | 14.37 | 18.59 |
|      waterfall      | 38.37 | 56.49 |
|         tent        | 77.89 |  93.0 |
|         bag         |  9.4  | 12.94 |
|       minibike      | 53.27 | 65.02 |
|        cradle       | 67.35 | 89.37 |
|         oven        | 23.11 |  45.6 |
|         ball        |  40.0 | 52.44 |
|         food        | 33.83 | 43.05 |
|         step        |  7.65 |  8.63 |
|         tank        |  47.7 | 51.63 |
|      trade name     | 13.32 | 15.34 |
|      microwave      | 32.05 | 35.65 |
|         pot         |  20.8 | 24.06 |
|        animal       | 37.69 |  46.6 |
|       bicycle       | 36.48 | 52.57 |
|         lake        | 62.79 | 67.55 |
|      dishwasher     | 52.71 | 64.08 |
|        screen       | 55.48 | 74.89 |
|       blanket       |  5.63 |  6.19 |
|      sculpture      | 45.05 | 57.18 |
|         hood        | 41.62 | 50.86 |
|        sconce       | 17.08 | 18.74 |
|         vase        | 14.71 | 20.53 |
|    traffic light    | 16.28 | 20.97 |
|         tray        |  1.75 |  3.27 |
|        ashcan       |  23.7 | 31.35 |
|         fan         | 28.26 | 35.39 |
|         pier        | 27.78 | 36.67 |
|      crt screen     |  7.55 | 20.98 |
|        plate        | 30.54 | 42.54 |
|       monitor       |  2.46 |  3.39 |
|    bulletin board   | 27.76 | 36.46 |
|        shower       |  0.0  |  0.0  |
|       radiator      | 31.99 | 36.95 |
|        glass        |  2.75 |  3.12 |
|        clock        |  4.2  |  6.18 |
|         flag        | 26.02 | 26.87 |
+---------------------+-------+-------+
2024/10/29 00:51:55 - mmengine - INFO - Iter(val) [500/500]    aAcc: 76.1500  mIoU: 36.9300  mAcc: 47.8900  data_time: 0.0014  time: 0.0288
